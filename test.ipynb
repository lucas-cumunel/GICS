{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af2bfca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading lxml-6.0.2-cp313-cp313-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
      "Downloading lxml-6.0.2-cp313-cp313-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "Successfully installed lxml-6.0.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lxml\n",
    "#%pip install rdflib\n",
    "import os\n",
    "import s3fs\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = '1J9SZCURG0IZM0VVX37D'\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = '9CKCagFEDjzIKptrZy1sBOI2+C8+94ojH+LONi54'\n",
    "os.environ[\"AWS_SESSION_TOKEN\"] = 'eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NLZXkiOiIxSjlTWkNVUkcwSVpNMFZWWDM3RCIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sImF1ZCI6WyJtaW5pby1kYXRhbm9kZSIsIm9ueXhpYSIsImFjY291bnQiXSwiYXV0aF90aW1lIjoxNzYxNjM5MDM3LCJhenAiOiJvbnl4aWEiLCJlbWFpbCI6Imx1Y2FzLmN1bXVuZWxAZW5zYWUuZnIiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZXhwIjoxNzYyMjQzODYwLCJmYW1pbHlfbmFtZSI6IkN1bXVuZWwiLCJnaXZlbl9uYW1lIjoiTHVjYXMiLCJncm91cHMiOlsiVVNFUl9PTllYSUEiLCJzdGF0YXBwLXNlZ21lZGljIl0sImlhdCI6MTc2MTYzOTA2MCwiaXNzIjoiaHR0cHM6Ly9hdXRoLmxhYi5zc3BjbG91ZC5mci9hdXRoL3JlYWxtcy9zc3BjbG91ZCIsImp0aSI6Im9ucnRydDo4NzNjZTViNy04ZDQ3LWQ0NGItNDk3NC04NWNjNDA3NWJkZWUiLCJuYW1lIjoiTHVjYXMgQ3VtdW5lbCIsInBvbGljeSI6InN0c29ubHkiLCJwcmVmZXJyZWRfdXNlcm5hbWUiOiJsYWIiLCJyZWFsbV9hY2Nlc3MiOnsicm9sZXMiOlsib2ZmbGluZV9hY2Nlc3MiLCJ1bWFfYXV0aG9yaXphdGlvbiIsImRlZmF1bHQtcm9sZXMtc3NwY2xvdWQiXX0sInJlc291cmNlX2FjY2VzcyI6eyJhY2NvdW50Ijp7InJvbGVzIjpbIm1hbmFnZS1hY2NvdW50IiwibWFuYWdlLWFjY291bnQtbGlua3MiLCJ2aWV3LXByb2ZpbGUiXX19LCJyb2xlcyI6WyJvZmZsaW5lX2FjY2VzcyIsInVtYV9hdXRob3JpemF0aW9uIiwiZGVmYXVsdC1yb2xlcy1zc3BjbG91ZCJdLCJzY29wZSI6Im9wZW5pZCBwcm9maWxlIGdyb3VwcyBlbWFpbCIsInNpZCI6IjdlMzg4NmFiLWUxYWEtNDZiNS04MGE2LTRkNDRiYzk0NzJkZiIsInN1YiI6ImUyZDc4NjRjLTcwMzItNDI0ZC04OTA2LWU0ZjhiNDFjYzAwMyIsInR5cCI6IkJlYXJlciJ9.oBZKGdOLRwmoT9SUMM2H5RfIPMoP22e8cotzbdlOdtscV3mC6HL1vp72nuBvp6kMECQOlsOeqVY7rSfNnMm8Jw'\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = 'us-east-1'\n",
    "fs = s3fs.S3FileSystem(\n",
    "    client_kwargs={'endpoint_url': 'https://'+'minio.lab.sspcloud.fr'},\n",
    "    key = os.environ[\"AWS_ACCESS_KEY_ID\"], \n",
    "    secret = os.environ[\"AWS_SECRET_ACCESS_KEY\"], \n",
    "    token = os.environ[\"AWS_SESSION_TOKEN\"])\n",
    "\n",
    "path = \"lab/dblp (1).xml.gz\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52a0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 9\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "# Tags we want to process\n",
    "tags = [\"inproceedings\", \"article\"]\n",
    "\n",
    "with fs.open(path, 'rb') as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        # iterparse supports only one tag at a time, so we'll parse for both sequentially\n",
    "        for tag in tags:\n",
    "            context = etree.iterparse(gz, events=(\"end\",), tag=tag, recover=True)\n",
    "            for event, elem in context:\n",
    "                title = elem.findtext(\"title\")\n",
    "\n",
    "                # Extract DOIs from <ee> elements\n",
    "                dois = [ee.text for ee in elem.findall(\".//ee\") if ee.text and \"doi.org\" in ee.text]\n",
    "                doi_str = \"; \".join(dois) if dois else None\n",
    "\n",
    "                if title and doi_str:  # keep only entries that have both\n",
    "                    records.append({\n",
    "                        \"title\": title,\n",
    "                        \"dois\": doi_str\n",
    "                    })\n",
    "\n",
    "                elem.clear()\n",
    "            # Reset the file pointer for the next tag\n",
    "            gz.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e469ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "\n",
    "with fs.open(path, 'rb') as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        #parser = etree.XMLParser(recover=True, resolve_entities=True)\n",
    "        context = etree.iterparse(gz, events=(\"end\",), tag=\"article\", recover=True)\n",
    "        \n",
    "        for event, elem in context:\n",
    "            title = elem.findtext(\"title\")\n",
    "            journal = elem.findtext(\"journal\")\n",
    "            pub_date = elem.findtext(\"year\")\n",
    "            doi = elem.findtext(\"ee\")\n",
    "            \n",
    "\n",
    "            authors = [a.text for a in elem.findall(\".//author\")]\n",
    "            authors_str = \"; \".join([a for a in authors if a])\n",
    "\n",
    "            articles.append({\n",
    "                \"title\": title,\n",
    "                \"journal\": journal,\n",
    "                \"year\": pub_date,\n",
    "                \"authors\": authors_str,\n",
    "                \"doi\":doi\n",
    "            })\n",
    "\n",
    "            elem.clear()\n",
    "\n",
    "df = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f95077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpro = []\n",
    "\n",
    "with fs.open(path, 'rb') as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        #parser = etree.XMLParser(recover=True, resolve_entities=True)\n",
    "        context = etree.iterparse(gz, events=(\"end\",), tag=\"inproceedings\", recover=True)\n",
    "        \n",
    "        for event, elem in context:\n",
    "            title = elem.findtext(\"title\")\n",
    "            conf = elem.findtext(\"booktitle\")\n",
    "            pub_date = elem.findtext(\"year\")\n",
    "            doi = elem.findtext(\"ee\")\n",
    "\n",
    "            authors = [a.text for a in elem.findall(\".//author\")]\n",
    "            authors_str = \"; \".join([a for a in authors if a])\n",
    "\n",
    "            inpro.append({\n",
    "                \"title\": title,\n",
    "                \"conf\": conf,\n",
    "                \"year\": pub_date,\n",
    "                \"authors\": authors_str,\n",
    "                \"doi\":doi\n",
    "            })\n",
    "\n",
    "            elem.clear()\n",
    "\n",
    "df = pd.DataFrame(inpro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aafcd72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>conf</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Future of Classic Data Administration: Obj...</td>\n",
       "      <td>SWEE</td>\n",
       "      <td>1998</td>\n",
       "      <td>Arnon Rosenthal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Some Patterns of Convincing Software Engineeri...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>Lutz Prechelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Static Worst-Case Analyses and Their Validatio...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>Peter Wgemann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crossing Disciplinary Borders to Improve Requi...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>Anne Hess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What You See Is What You Get: Practical Effect...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jonathan Immanuel Brachthuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749504</th>\n",
       "      <td>Machine Intentionality, the Moral Status of Ma...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>David Leech Anderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749509</th>\n",
       "      <td>Practical Introspection as Inspiration for AI.</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>Sam Freed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749510</th>\n",
       "      <td>\"Computational Ontology and Deontology\".</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>Raffaela Giovagnoli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749512</th>\n",
       "      <td>Emotional Control-Conditio Sine Qua Non for Ad...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>Claudius Gros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749513</th>\n",
       "      <td>Becoming Digital: Reconciling Theories of Digi...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>Harry Halpin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284765 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title          conf  \\\n",
       "0        The Future of Classic Data Administration: Obj...          SWEE   \n",
       "1        Some Patterns of Convincing Software Engineeri...  Denert Award   \n",
       "2        Static Worst-Case Analyses and Their Validatio...  Denert Award   \n",
       "3        Crossing Disciplinary Borders to Improve Requi...  Denert Award   \n",
       "4        What You See Is What You Get: Practical Effect...  Denert Award   \n",
       "...                                                    ...           ...   \n",
       "3749504  Machine Intentionality, the Moral Status of Ma...         PT-AI   \n",
       "3749509     Practical Introspection as Inspiration for AI.         PT-AI   \n",
       "3749510           \"Computational Ontology and Deontology\".         PT-AI   \n",
       "3749512  Emotional Control-Conditio Sine Qua Non for Ad...         PT-AI   \n",
       "3749513  Becoming Digital: Reconciling Theories of Digi...         PT-AI   \n",
       "\n",
       "         year                        authors  \n",
       "0        1998                Arnon Rosenthal  \n",
       "1        2020                  Lutz Prechelt  \n",
       "2        2020                  Peter Wgemann  \n",
       "3        2020                      Anne Hess  \n",
       "4        2020  Jonathan Immanuel Brachthuser  \n",
       "...       ...                            ...  \n",
       "3749504  2011           David Leech Anderson  \n",
       "3749509  2011                      Sam Freed  \n",
       "3749510  2011            Raffaela Giovagnoli  \n",
       "3749512  2011                  Claudius Gros  \n",
       "3749513  2011                   Harry Halpin  \n",
       "\n",
       "[284765 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "df[df[\"authors\"].apply(lambda x: bool(re.compile(r\"^[A-Za-z\\s-]+$\").search(str(x))))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18043c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['author', 'booktitle', 'cdrom', 'cite', 'crossref', 'editor', 'ee', 'month', 'note', 'number', 'pages', 'publnr', 'stream', 'title', 'url', 'volume', 'year']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import gzip\n",
    "\n",
    "direct_set = set()\n",
    "\n",
    "with fs.open(path, \"rb\") as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        context = etree.iterparse(gz, events=(\"end\",), tag=\"inproceedings\", recover=True)\n",
    "        for event, elem in context:\n",
    "            # collect child tags\n",
    "            for child in elem:\n",
    "                if child.tag is not None:\n",
    "                    direct_set.add(child.tag)\n",
    "\n",
    "            # clear memory: remove element and its previous siblings\n",
    "            elem.clear()\n",
    "            while elem.getprevious() is not None:\n",
    "                del elem.getparent()[0]\n",
    "\n",
    "print(sorted(direct_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63b4a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "n_chunks = 50\n",
    "chunk_size = len(df) // n_chunks\n",
    "\n",
    "for i in range(n_chunks):\n",
    "    start = i * chunk_size\n",
    "    end = (i + 1) * chunk_size if i < n_chunks - 1 else len(df)  # last chunk includes remainder\n",
    "    \n",
    "    chunk = df.iloc[start:end].copy()\n",
    "    \n",
    "    # Split authors column into multiple columns\n",
    "    #authors_df = chunk['authors'].str.split(';', expand=True)\n",
    "    #authors_df.columns = [f'author{i+1}' for i in range(authors_df.shape[1])]\n",
    "    \n",
    "    # Combine with original chunk\n",
    "    #chunk = pd.concat([chunk.drop(columns=['authors']), authors_df], axis=1)\n",
    "    \n",
    "    chunk.to_parquet(f\"inpro/inproceedings_chunk_{i}.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a780155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "\n",
    "ego_data = defaultdict(lambda: {\"publications\": []}) #set permet de créer des clefs si absentes et de les actualiser si présentes (en définissant la classe des clefs)\n",
    "\n",
    "chunk_files = glob.glob(\"inpro/inproceedings_chunk_*.parquet\")\n",
    "\n",
    "for file in chunk_files:\n",
    "    df_chunk = pd.read_parquet(file)\n",
    "    for _, row in df_chunk.iterrows():\n",
    "        authors = row['authors'].split(';')\n",
    "        authors = [a for a in authors if not re.compile(r\"\\d\").search(a)]\n",
    "        for ego in authors:\n",
    "            coauthors = set(authors) - {ego}\n",
    "            \n",
    "            ego_data[ego][\"publications\"].append({\n",
    "                \"coauthors\": list(coauthors),\n",
    "                \"journal\": row.get(\"conf\"),\n",
    "                \"year\": row.get(\"year\"),\n",
    "                \"title\": row.get(\"title\")\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f903d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ego_df = pd.DataFrame([\n",
    "    {'ego': ego, **data[\"publications\"]} #récup paries ego - alter et trie dans l'ordre alphabétique\n",
    "    for ego, data in ego_data.items()\n",
    "])\"\"\"\n",
    "rows = []\n",
    "for ego, data in ego_data.items():\n",
    "    for pub in data[\"publications\"]:\n",
    "        rows.append({\n",
    "            \"ego\": ego,\n",
    "            \"coauthors\": \",\".join(sorted(pub[\"coauthors\"])),\n",
    "            \"journal\": pub.get(\"journal\"),\n",
    "            \"year\": pub.get(\"year\"),\n",
    "            \"title\": pub.get(\"title\")\n",
    "        })\n",
    "\n",
    "inp_df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07d2b871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ego</th>\n",
       "      <th>coauthors</th>\n",
       "      <th>journal</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sanish Rai</td>\n",
       "      <td></td>\n",
       "      <td>SpringSim (TMS)</td>\n",
       "      <td>2018</td>\n",
       "      <td>Hybrid agent-based and graph-based modeling fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sanish Rai</td>\n",
       "      <td></td>\n",
       "      <td>IAT</td>\n",
       "      <td>2013</td>\n",
       "      <td>Behavior Pattern Detection for Data Assimilati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sanish Rai</td>\n",
       "      <td>Minghao Wang</td>\n",
       "      <td>SpringSim (ADS)</td>\n",
       "      <td>2015</td>\n",
       "      <td>A graph-based agent-oriented model for buildin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sanish Rai</td>\n",
       "      <td></td>\n",
       "      <td>WSC</td>\n",
       "      <td>2017</td>\n",
       "      <td>Data assimilation with sensor-informed resampl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sanish Rai</td>\n",
       "      <td></td>\n",
       "      <td>COMPSAC</td>\n",
       "      <td>2016</td>\n",
       "      <td>Graph Based Agent Oriented Model for Tunnel Si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11784249</th>\n",
       "      <td>Juan Gutierrez</td>\n",
       "      <td>Ashley Houston-King, Cliff Freeman, Eli Tucke...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11784250</th>\n",
       "      <td>Ashley Houston-King</td>\n",
       "      <td>Cliff Freeman, Eli Tucker-Raymond, Katherine ...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11784251</th>\n",
       "      <td>Cliff Freeman</td>\n",
       "      <td>Ashley Houston-King, Eli Tucker-Raymond, Kath...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11784252</th>\n",
       "      <td>Katherine K. Frankel</td>\n",
       "      <td>Ashley Houston-King, Cliff Freeman, Eli Tucke...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11784253</th>\n",
       "      <td>Ryan Cain</td>\n",
       "      <td>Victor R. Lee</td>\n",
       "      <td>FabLearn</td>\n",
       "      <td>2016</td>\n",
       "      <td>Measuring Electrodermal Activity to Capture En...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11784254 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ego  \\\n",
       "0                    Sanish Rai   \n",
       "1                    Sanish Rai   \n",
       "2                    Sanish Rai   \n",
       "3                    Sanish Rai   \n",
       "4                    Sanish Rai   \n",
       "...                         ...   \n",
       "11784249         Juan Gutierrez   \n",
       "11784250    Ashley Houston-King   \n",
       "11784251          Cliff Freeman   \n",
       "11784252   Katherine K. Frankel   \n",
       "11784253              Ryan Cain   \n",
       "\n",
       "                                                  coauthors  \\\n",
       "0                                                             \n",
       "1                                                             \n",
       "2                                              Minghao Wang   \n",
       "3                                                             \n",
       "4                                                             \n",
       "...                                                     ...   \n",
       "11784249   Ashley Houston-King, Cliff Freeman, Eli Tucke...   \n",
       "11784250   Cliff Freeman, Eli Tucker-Raymond, Katherine ...   \n",
       "11784251   Ashley Houston-King, Eli Tucker-Raymond, Kath...   \n",
       "11784252   Ashley Houston-King, Cliff Freeman, Eli Tucke...   \n",
       "11784253                                      Victor R. Lee   \n",
       "\n",
       "                           journal  year  \\\n",
       "0                  SpringSim (TMS)  2018   \n",
       "1                              IAT  2013   \n",
       "2                  SpringSim (ADS)  2015   \n",
       "3                              WSC  2017   \n",
       "4                          COMPSAC  2016   \n",
       "...                            ...   ...   \n",
       "11784249  FabLearn/Constructionism  2023   \n",
       "11784250  FabLearn/Constructionism  2023   \n",
       "11784251  FabLearn/Constructionism  2023   \n",
       "11784252  FabLearn/Constructionism  2023   \n",
       "11784253                  FabLearn  2016   \n",
       "\n",
       "                                                      title  \n",
       "0         Hybrid agent-based and graph-based modeling fo...  \n",
       "1         Behavior Pattern Detection for Data Assimilati...  \n",
       "2         A graph-based agent-oriented model for buildin...  \n",
       "3         Data assimilation with sensor-informed resampl...  \n",
       "4         Graph Based Agent Oriented Model for Tunnel Si...  \n",
       "...                                                     ...  \n",
       "11784249  Youth Pedagogical Development in Youth Teachin...  \n",
       "11784250  Youth Pedagogical Development in Youth Teachin...  \n",
       "11784251  Youth Pedagogical Development in Youth Teachin...  \n",
       "11784252  Youth Pedagogical Development in Youth Teachin...  \n",
       "11784253  Measuring Electrodermal Activity to Capture En...  \n",
       "\n",
       "[11784254 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75f29d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ego</th>\n",
       "      <th>coauthors</th>\n",
       "      <th>journal</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kodai Shimosato</td>\n",
       "      <td>Norimichi Ukita</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2024</td>\n",
       "      <td>Inpainting-Driven Mask Optimization for Object...</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kodai Shimosato</td>\n",
       "      <td>Norimichi Ukita</td>\n",
       "      <td>IEEE Access</td>\n",
       "      <td>2021</td>\n",
       "      <td>Multi-Modal Data Fusion for Land-Subsidence Im...</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norimichi Ukita</td>\n",
       "      <td>Kodai Shimosato</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2024</td>\n",
       "      <td>Inpainting-Driven Mask Optimization for Object...</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norimichi Ukita</td>\n",
       "      <td>Arnau Raventos, Aryan Esfandiari, C. Victor J...</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2020</td>\n",
       "      <td>AIM 2020 Challenge on Video Extreme Super-Reso...</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norimichi Ukita</td>\n",
       "      <td>Kazutoshi Akita,Kyotaro Tokoro</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2024</td>\n",
       "      <td>Burst Super-Resolution with Diffusion Models f...</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24241368</th>\n",
       "      <td>Juan Gutierrez</td>\n",
       "      <td>Ashley Houston-King, Cliff Freeman, Eli Tucke...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "      <td>inp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24241369</th>\n",
       "      <td>Ashley Houston-King</td>\n",
       "      <td>Cliff Freeman, Eli Tucker-Raymond, Katherine ...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "      <td>inp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24241370</th>\n",
       "      <td>Cliff Freeman</td>\n",
       "      <td>Ashley Houston-King, Eli Tucker-Raymond, Kath...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "      <td>inp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24241371</th>\n",
       "      <td>Katherine K. Frankel</td>\n",
       "      <td>Ashley Houston-King, Cliff Freeman, Eli Tucke...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "      <td>inp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24241372</th>\n",
       "      <td>Ryan Cain</td>\n",
       "      <td>Victor R. Lee</td>\n",
       "      <td>FabLearn</td>\n",
       "      <td>2016</td>\n",
       "      <td>Measuring Electrodermal Activity to Capture En...</td>\n",
       "      <td>inp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24241373 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ego  \\\n",
       "0               Kodai Shimosato   \n",
       "1               Kodai Shimosato   \n",
       "2               Norimichi Ukita   \n",
       "3               Norimichi Ukita   \n",
       "4               Norimichi Ukita   \n",
       "...                         ...   \n",
       "24241368         Juan Gutierrez   \n",
       "24241369    Ashley Houston-King   \n",
       "24241370          Cliff Freeman   \n",
       "24241371   Katherine K. Frankel   \n",
       "24241372              Ryan Cain   \n",
       "\n",
       "                                                  coauthors  \\\n",
       "0                                           Norimichi Ukita   \n",
       "1                                           Norimichi Ukita   \n",
       "2                                           Kodai Shimosato   \n",
       "3          Arnau Raventos, Aryan Esfandiari, C. Victor J...   \n",
       "4                            Kazutoshi Akita,Kyotaro Tokoro   \n",
       "...                                                     ...   \n",
       "24241368   Ashley Houston-King, Cliff Freeman, Eli Tucke...   \n",
       "24241369   Cliff Freeman, Eli Tucker-Raymond, Katherine ...   \n",
       "24241370   Ashley Houston-King, Eli Tucker-Raymond, Kath...   \n",
       "24241371   Ashley Houston-King, Cliff Freeman, Eli Tucke...   \n",
       "24241372                                      Victor R. Lee   \n",
       "\n",
       "                           journal  year  \\\n",
       "0                             CoRR  2024   \n",
       "1                      IEEE Access  2021   \n",
       "2                             CoRR  2024   \n",
       "3                             CoRR  2020   \n",
       "4                             CoRR  2024   \n",
       "...                            ...   ...   \n",
       "24241368  FabLearn/Constructionism  2023   \n",
       "24241369  FabLearn/Constructionism  2023   \n",
       "24241370  FabLearn/Constructionism  2023   \n",
       "24241371  FabLearn/Constructionism  2023   \n",
       "24241372                  FabLearn  2016   \n",
       "\n",
       "                                                      title Type  \n",
       "0         Inpainting-Driven Mask Optimization for Object...  art  \n",
       "1         Multi-Modal Data Fusion for Land-Subsidence Im...  art  \n",
       "2         Inpainting-Driven Mask Optimization for Object...  art  \n",
       "3         AIM 2020 Challenge on Video Extreme Super-Reso...  art  \n",
       "4         Burst Super-Resolution with Diffusion Models f...  art  \n",
       "...                                                     ...  ...  \n",
       "24241368  Youth Pedagogical Development in Youth Teachin...  inp  \n",
       "24241369  Youth Pedagogical Development in Youth Teachin...  inp  \n",
       "24241370  Youth Pedagogical Development in Youth Teachin...  inp  \n",
       "24241371  Youth Pedagogical Development in Youth Teachin...  inp  \n",
       "24241372  Measuring Electrodermal Activity to Capture En...  inp  \n",
       "\n",
       "[24241373 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_df[\"Type\"]=\"art\"\n",
    "inp_df[\"Type\"]=\"inp\"\n",
    "ego_df=pd.concat([art_df,inp_df], axis=0, ignore_index=True)\n",
    "ego_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7e84aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ego_df[\"name\"]=np.where(len(ego_df[\"ego\"].str.split())>1, ego_df[\"ego\"].str.split(n=1).str[0], None)\n",
    "def is_valid_firstname(word):\n",
    "    if not isinstance(word, str):  # skip NaN/None\n",
    "        return False\n",
    "    if len(word) == 1:  # single letter\n",
    "        return False\n",
    "    if word.isupper():  # all caps (acronyms)\n",
    "        return False\n",
    "    if not re.match(r'^[A-Za-z-]+$', word):  # contains only letters or hyphens\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "ego_df[\"name\"] = ego_df[\"name\"].apply(lambda x: x if is_valid_firstname(x) else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99995cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.13447670641427775)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ego_df[\"name\"]=ego_df[\"ego\"].str.lstrip().str.split(\" \").str[0].str.lower()\n",
    "(ego_df[\"ego\"]==\"\").sum()/len(ego_df)*100 #0.13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5bdac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "names=names.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "810db5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with fs.open(\"s3://lab/main_df.parquet\", 'wb') as f:\n",
    "    ego_df.to_parquet(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df5bc00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_df.to_parquet(\"ego_df.parquet\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "779e4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fs.open(\"s3://lab/name_gender_dataset.csv\") as f:\n",
    "    g1 = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/wgnd_2_0_name-gender-langcode.csv\") as f:\n",
    "    g2 = pd.read_csv(f)\n",
    "\n",
    "g1=g1[[\"Name\",\"Gender\"]]\n",
    "g2[[\"Name\",\"Gender\"]]=g2[[\"name\",\"gender\"]]\n",
    "g2=g2[[\"Name\",\"Gender\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4106024c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>a laura</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>a lelia</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>a lelia</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>a lerah</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>a lerah</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>a lex ander</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>a lex ander</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>a lie</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>a lisa</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>a lisa</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>a liza</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>a liza</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>a lmos</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>a luan</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>a mang</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>a me</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>a men</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>a mer</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>a mer</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>a merie</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>a merie</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>a mou</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>a nai</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>a nak la</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>a nak la</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>a nao</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>a neng</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>a nette</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>a niang</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>a niyah</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>a niyah</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>a nv</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>a ou</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>a pan</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>a pao</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>a pi</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>a pu</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>a qie</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>a qiong</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>a que</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>a ran</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>a rang</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>a rao</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>a re</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>a ri</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>a rin</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>a rin</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>a ron</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>a ron</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>a s m</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name Gender\n",
       "100      a laura      F\n",
       "101      a lelia      F\n",
       "102      a lelia      F\n",
       "103      a lerah      F\n",
       "104      a lerah      F\n",
       "105  a lex ander      M\n",
       "106  a lex ander      M\n",
       "107        a lie      M\n",
       "108       a lisa      F\n",
       "109       a lisa      F\n",
       "110       a liza      F\n",
       "111       a liza      F\n",
       "112       a lmos      M\n",
       "113       a luan      M\n",
       "114       a mang      F\n",
       "115         a me      F\n",
       "116        a men      M\n",
       "117        a mer      M\n",
       "118        a mer      M\n",
       "119      a merie      F\n",
       "120      a merie      F\n",
       "121        a mou      M\n",
       "122        a nai      F\n",
       "123     a nak la      M\n",
       "124     a nak la      M\n",
       "125        a nao      F\n",
       "126       a neng      M\n",
       "127      a nette      F\n",
       "128      a niang      F\n",
       "129      a niyah      F\n",
       "130      a niyah      F\n",
       "131         a nv      F\n",
       "132         a ou      M\n",
       "133        a pan      F\n",
       "134        a pao      M\n",
       "135         a pi      M\n",
       "136         a pu      F\n",
       "137        a qie      M\n",
       "138      a qiong      F\n",
       "139        a que      M\n",
       "140        a ran      M\n",
       "141       a rang      M\n",
       "142        a rao      F\n",
       "143         a re      F\n",
       "144         a ri      M\n",
       "145        a rin      F\n",
       "146        a rin      F\n",
       "147        a ron      M\n",
       "148        a ron      M\n",
       "149        a s m      M"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "add36b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>William</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978307</th>\n",
       "      <td>히카리</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978308</th>\n",
       "      <td>히토미</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978309</th>\n",
       "      <td>힘찬</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978310</th>\n",
       "      <td>凉峰</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978311</th>\n",
       "      <td>凉翼</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21978312 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name Gender\n",
       "0           James      M\n",
       "1            John      M\n",
       "2          Robert      M\n",
       "3         Michael      M\n",
       "4         William      M\n",
       "...           ...    ...\n",
       "21978307      히카리      F\n",
       "21978308      히토미      F\n",
       "21978309       힘찬      M\n",
       "21978310       凉峰      M\n",
       "21978311       凉翼      M\n",
       "\n",
       "[21978312 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([g1,g2],axis=0,ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
