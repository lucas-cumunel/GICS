{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af2bfca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /opt/python/lib/python3.13/site-packages (6.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lxml\n",
    "import os\n",
    "import s3fs\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = 'BDUCSQ8RE22Q2LMTUY75'\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = 'Y7jUkgRo+sBR2Ctfzr+djyg3a71kTOd0pSgynrYd'\n",
    "os.environ[\"AWS_SESSION_TOKEN\"] = 'eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NLZXkiOiJCRFVDU1E4UkUyMlEyTE1UVVk3NSIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sImF1ZCI6WyJtaW5pby1kYXRhbm9kZSIsIm9ueXhpYSIsImFjY291bnQiXSwiYXV0aF90aW1lIjoxNzU5MDQ2Njc3LCJhenAiOiJvbnl4aWEiLCJlbWFpbCI6Imx1Y2FzLmN1bXVuZWxAZW5zYWUuZnIiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZXhwIjoxNzYwNTI3MTYzLCJmYW1pbHlfbmFtZSI6IkN1bXVuZWwiLCJnaXZlbl9uYW1lIjoiTHVjYXMiLCJncm91cHMiOlsiVVNFUl9PTllYSUEiLCJzdGF0YXBwLXNlZ21lZGljIl0sImlhdCI6MTc1OTkyMjM2MywiaXNzIjoiaHR0cHM6Ly9hdXRoLmxhYi5zc3BjbG91ZC5mci9hdXRoL3JlYWxtcy9zc3BjbG91ZCIsImp0aSI6Im9ucnRydDpjODJkYzBkYS03MGM3LTI4ZGUtYjIzMS1jNWQ3MTdlNzRjMmEiLCJuYW1lIjoiTHVjYXMgQ3VtdW5lbCIsInBvbGljeSI6InN0c29ubHkiLCJwcmVmZXJyZWRfdXNlcm5hbWUiOiJsYWIiLCJyZWFsbV9hY2Nlc3MiOnsicm9sZXMiOlsib2ZmbGluZV9hY2Nlc3MiLCJ1bWFfYXV0aG9yaXphdGlvbiIsImRlZmF1bHQtcm9sZXMtc3NwY2xvdWQiXX0sInJlc291cmNlX2FjY2VzcyI6eyJhY2NvdW50Ijp7InJvbGVzIjpbIm1hbmFnZS1hY2NvdW50IiwibWFuYWdlLWFjY291bnQtbGlua3MiLCJ2aWV3LXByb2ZpbGUiXX19LCJyb2xlcyI6WyJvZmZsaW5lX2FjY2VzcyIsInVtYV9hdXRob3JpemF0aW9uIiwiZGVmYXVsdC1yb2xlcy1zc3BjbG91ZCJdLCJzY29wZSI6Im9wZW5pZCBwcm9maWxlIGdyb3VwcyBlbWFpbCIsInNpZCI6ImFmY2VhMjNmLTM3MGUtNDhjNC1hNGQ5LWIzZDJjMDJkYmNkOCIsInN1YiI6ImUyZDc4NjRjLTcwMzItNDI0ZC04OTA2LWU0ZjhiNDFjYzAwMyIsInR5cCI6IkJlYXJlciJ9.hlce_P59hQ6ibPoCT7wojM-AnVPacHINBdQMTzpWMfcEVPN3MYd80TYaz7Z3gkTjxfKjhueg2WvYiC0-0JN1bQ'\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = 'us-east-1'\n",
    "fs = s3fs.S3FileSystem(\n",
    "    client_kwargs={'endpoint_url': 'https://'+'minio.lab.sspcloud.fr'},\n",
    "    key = os.environ[\"AWS_ACCESS_KEY_ID\"], \n",
    "    secret = os.environ[\"AWS_SECRET_ACCESS_KEY\"], \n",
    "    token = os.environ[\"AWS_SESSION_TOKEN\"])\n",
    "\n",
    "path = \"lab/dblp (1).xml.gz\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e469ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "\n",
    "with fs.open(path, 'rb') as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        #parser = etree.XMLParser(recover=True, resolve_entities=True)\n",
    "        context = etree.iterparse(gz, events=(\"end\",), tag=\"article\", recover=True)\n",
    "        \n",
    "        for event, elem in context:\n",
    "            title = elem.findtext(\"title\")\n",
    "            journal = elem.findtext(\"journal\")\n",
    "            pub_date = elem.findtext(\"year\")\n",
    "\n",
    "            authors = [a.text for a in elem.findall(\".//author\")]\n",
    "            authors_str = \"; \".join([a for a in authors if a])\n",
    "\n",
    "            articles.append({\n",
    "                \"title\": title,\n",
    "                \"journal\": journal,\n",
    "                \"year\": pub_date,\n",
    "                \"authors\": authors_str\n",
    "            })\n",
    "\n",
    "            elem.clear()\n",
    "\n",
    "df = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f95077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpro = []\n",
    "\n",
    "with fs.open(path, 'rb') as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        #parser = etree.XMLParser(recover=True, resolve_entities=True)\n",
    "        context = etree.iterparse(gz, events=(\"end\",), tag=\"inproceedings\", recover=True)\n",
    "        \n",
    "        for event, elem in context:\n",
    "            title = elem.findtext(\"title\")\n",
    "            conf = elem.findtext(\"booktitle\")\n",
    "            pub_date = elem.findtext(\"year\")\n",
    "\n",
    "            authors = [a.text for a in elem.findall(\".//author\")]\n",
    "            authors_str = \"; \".join([a for a in authors if a])\n",
    "\n",
    "            inpro.append({\n",
    "                \"title\": title,\n",
    "                \"conf\": conf,\n",
    "                \"year\": pub_date,\n",
    "                \"authors\": authors_str\n",
    "            })\n",
    "\n",
    "            elem.clear()\n",
    "\n",
    "df = pd.DataFrame(inpro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aafcd72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>conf</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Future of Classic Data Administration: Obj...</td>\n",
       "      <td>SWEE</td>\n",
       "      <td>1998</td>\n",
       "      <td>Arnon Rosenthal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Some Patterns of Convincing Software Engineeri...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>Lutz Prechelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Static Worst-Case Analyses and Their Validatio...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>Peter Wgemann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crossing Disciplinary Borders to Improve Requi...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>Anne Hess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What You See Is What You Get: Practical Effect...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jonathan Immanuel Brachthuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749511</th>\n",
       "      <td>Toward a Modern Geography of Minds, Machines, ...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>Selmer Bringsjord; Naveen Sundar Govindarajulu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749512</th>\n",
       "      <td>Emotional Control-Conditio Sine Qua Non for Ad...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>Claudius Gros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749513</th>\n",
       "      <td>Becoming Digital: Reconciling Theories of Digi...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>Harry Halpin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749514</th>\n",
       "      <td>Generative Artificial Intelligence.</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>Tijn van der Zant; Matthijs Kouw; Lambert Scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749515</th>\n",
       "      <td>Seven Steps to Rendezvous with the Casual User.</td>\n",
       "      <td>IFIP Working Conference Data Base Management</td>\n",
       "      <td>1974</td>\n",
       "      <td>E. F. Codd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3749516 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  \\\n",
       "0        The Future of Classic Data Administration: Obj...   \n",
       "1        Some Patterns of Convincing Software Engineeri...   \n",
       "2        Static Worst-Case Analyses and Their Validatio...   \n",
       "3        Crossing Disciplinary Borders to Improve Requi...   \n",
       "4        What You See Is What You Get: Practical Effect...   \n",
       "...                                                    ...   \n",
       "3749511  Toward a Modern Geography of Minds, Machines, ...   \n",
       "3749512  Emotional Control-Conditio Sine Qua Non for Ad...   \n",
       "3749513  Becoming Digital: Reconciling Theories of Digi...   \n",
       "3749514                Generative Artificial Intelligence.   \n",
       "3749515    Seven Steps to Rendezvous with the Casual User.   \n",
       "\n",
       "                                                 conf  year  \\\n",
       "0                                                SWEE  1998   \n",
       "1                                        Denert Award  2020   \n",
       "2                                        Denert Award  2020   \n",
       "3                                        Denert Award  2020   \n",
       "4                                        Denert Award  2020   \n",
       "...                                               ...   ...   \n",
       "3749511                                         PT-AI  2011   \n",
       "3749512                                         PT-AI  2011   \n",
       "3749513                                         PT-AI  2011   \n",
       "3749514                                         PT-AI  2011   \n",
       "3749515  IFIP Working Conference Data Base Management  1974   \n",
       "\n",
       "                                                   authors  \n",
       "0                                          Arnon Rosenthal  \n",
       "1                                            Lutz Prechelt  \n",
       "2                                            Peter Wgemann  \n",
       "3                                                Anne Hess  \n",
       "4                            Jonathan Immanuel Brachthuser  \n",
       "...                                                    ...  \n",
       "3749511     Selmer Bringsjord; Naveen Sundar Govindarajulu  \n",
       "3749512                                      Claudius Gros  \n",
       "3749513                                       Harry Halpin  \n",
       "3749514  Tijn van der Zant; Matthijs Kouw; Lambert Scho...  \n",
       "3749515                                         E. F. Codd  \n",
       "\n",
       "[3749516 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18043c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['author', 'booktitle', 'cdrom', 'cite', 'crossref', 'editor', 'ee', 'month', 'note', 'number', 'pages', 'publnr', 'stream', 'title', 'url', 'volume', 'year']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import gzip\n",
    "\n",
    "direct_set = set()\n",
    "\n",
    "with fs.open(path, \"rb\") as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        context = etree.iterparse(gz, events=(\"end\",), tag=\"inproceedings\", recover=True)\n",
    "        for event, elem in context:\n",
    "            # collect child tags\n",
    "            for child in elem:\n",
    "                if child.tag is not None:\n",
    "                    direct_set.add(child.tag)\n",
    "\n",
    "            # clear memory: remove element and its previous siblings\n",
    "            elem.clear()\n",
    "            while elem.getprevious() is not None:\n",
    "                del elem.getparent()[0]\n",
    "\n",
    "print(sorted(direct_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f63b4a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "n_chunks = 50\n",
    "chunk_size = len(df) // n_chunks\n",
    "\n",
    "for i in range(n_chunks):\n",
    "    start = i * chunk_size\n",
    "    end = (i + 1) * chunk_size if i < n_chunks - 1 else len(df)  # last chunk includes remainder\n",
    "    \n",
    "    chunk = df.iloc[start:end].copy()\n",
    "    \n",
    "    # Split authors column into multiple columns\n",
    "    #authors_df = chunk['authors'].str.split(';', expand=True)\n",
    "    #authors_df.columns = [f'author{i+1}' for i in range(authors_df.shape[1])]\n",
    "    \n",
    "    # Combine with original chunk\n",
    "    #chunk = pd.concat([chunk.drop(columns=['authors']), authors_df], axis=1)\n",
    "    \n",
    "    chunk.to_parquet(f\"art/articles_chunk_{i}.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a780155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "\n",
    "ego_data = defaultdict(lambda: {\"publications\": []}) #set permet de créer des clefs si absentes et de les actualiser si présentes (en définissant la classe des clefs)\n",
    "\n",
    "chunk_files = glob.glob(\"t/articles_chunk_*.parquet\")\n",
    "\n",
    "for file in chunk_files:\n",
    "    df_chunk = pd.read_parquet(file)\n",
    "    \"\"\"\n",
    "    for _, row in df_chunk.iterrows():\n",
    "        authors = row['authors'].split(';')\n",
    "        for ego in authors:\n",
    "            coauthors = set(authors) - {ego}\n",
    "            #ego_data[ego][\"coauthors\"].update(coauthors)\n",
    "            \n",
    "            ego_data[ego][\"covariates\"].update({\n",
    "                \"coauthors\" : list(coauthors),\n",
    "                \"journal\": row.get(\"journal\"),\n",
    "                \"year\": row.get(\"year\"),\n",
    "                \"title\" : row.get(\"title\")\n",
    "            })\n",
    "    \"\"\"\n",
    "    for _, row in df_chunk.iterrows():\n",
    "        authors = row['authors'].split(';')\n",
    "        for ego in authors:\n",
    "            coauthors = set(authors) - {ego}\n",
    "            \n",
    "            ego_data[ego][\"publications\"].append({\n",
    "                \"coauthors\": list(coauthors),\n",
    "                \"journal\": row.get(\"journal\"),\n",
    "                \"year\": row.get(\"year\"),\n",
    "                \"title\": row.get(\"title\")\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f903d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ego_df = pd.DataFrame([\n",
    "    {'ego': ego, **data[\"publications\"]} #récup paries ego - alter et trie dans l'ordre alphabétique\n",
    "    for ego, data in ego_data.items()\n",
    "])\"\"\"\n",
    "rows = []\n",
    "for ego, data in ego_data.items():\n",
    "    for pub in data[\"publications\"]:\n",
    "        rows.append({\n",
    "            \"ego\": ego,\n",
    "            \"coauthors\": \",\".join(sorted(pub[\"coauthors\"])),\n",
    "            \"journal\": pub.get(\"journal\"),\n",
    "            \"year\": pub.get(\"year\"),\n",
    "            \"title\": pub.get(\"title\")\n",
    "        })\n",
    "\n",
    "ego_df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7e84aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ego</th>\n",
       "      <th>coauthors</th>\n",
       "      <th>journal</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baogang Xu</td>\n",
       "      <td>Haihui Zhang</td>\n",
       "      <td>Discret. Appl. Math.</td>\n",
       "      <td>2007</td>\n",
       "      <td>Every toroidal graph without adjacent triangle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baogang Xu</td>\n",
       "      <td>Lusheng Wang 0001</td>\n",
       "      <td>Discret. Appl. Math.</td>\n",
       "      <td>2005</td>\n",
       "      <td>Decomposing toroidal graphs into circuits and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baogang Xu</td>\n",
       "      <td>Xingxing Yu</td>\n",
       "      <td>Graphs Comb.</td>\n",
       "      <td>2012</td>\n",
       "      <td>Maximum Directed Cuts in Graphs with Degree Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baogang Xu</td>\n",
       "      <td>Xingxing Yu</td>\n",
       "      <td>Comb. Probab. Comput.</td>\n",
       "      <td>2011</td>\n",
       "      <td>Better Bounds for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baogang Xu</td>\n",
       "      <td></td>\n",
       "      <td>Discret. Math. Algorithms Appl.</td>\n",
       "      <td>2009</td>\n",
       "      <td>A Note on 3-colorable Plane Graphs without 5- ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13845993</th>\n",
       "      <td>John Bracken</td>\n",
       "      <td>Arundhuti Ganguly, Bruce Lewis Daniel, Daniel...</td>\n",
       "      <td>Proc. IEEE</td>\n",
       "      <td>2008</td>\n",
       "      <td>Design, Performance, and Applications of a Hyb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13845994</th>\n",
       "      <td>Zhifei Wen</td>\n",
       "      <td>Arundhuti Ganguly, Bruce Lewis Daniel, Daniel...</td>\n",
       "      <td>Proc. IEEE</td>\n",
       "      <td>2008</td>\n",
       "      <td>Design, Performance, and Applications of a Hyb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13845995</th>\n",
       "      <td>Huanzhou Yu</td>\n",
       "      <td>Arundhuti Ganguly, Bruce Lewis Daniel, Daniel...</td>\n",
       "      <td>Proc. IEEE</td>\n",
       "      <td>2008</td>\n",
       "      <td>Design, Performance, and Applications of a Hyb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13845996</th>\n",
       "      <td>Viola Rieke</td>\n",
       "      <td>Arundhuti Ganguly, Bruce Lewis Daniel, Daniel...</td>\n",
       "      <td>Proc. IEEE</td>\n",
       "      <td>2008</td>\n",
       "      <td>Design, Performance, and Applications of a Hyb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13845997</th>\n",
       "      <td>Joan K. Frisoli</td>\n",
       "      <td>Arundhuti Ganguly, Bruce Lewis Daniel, Daniel...</td>\n",
       "      <td>Proc. IEEE</td>\n",
       "      <td>2008</td>\n",
       "      <td>Design, Performance, and Applications of a Hyb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13845998 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ego                                          coauthors  \\\n",
       "0               Baogang Xu                                       Haihui Zhang   \n",
       "1               Baogang Xu                                  Lusheng Wang 0001   \n",
       "2               Baogang Xu                                        Xingxing Yu   \n",
       "3               Baogang Xu                                        Xingxing Yu   \n",
       "4               Baogang Xu                                                      \n",
       "...                    ...                                                ...   \n",
       "13845993      John Bracken   Arundhuti Ganguly, Bruce Lewis Daniel, Daniel...   \n",
       "13845994        Zhifei Wen   Arundhuti Ganguly, Bruce Lewis Daniel, Daniel...   \n",
       "13845995       Huanzhou Yu   Arundhuti Ganguly, Bruce Lewis Daniel, Daniel...   \n",
       "13845996       Viola Rieke   Arundhuti Ganguly, Bruce Lewis Daniel, Daniel...   \n",
       "13845997   Joan K. Frisoli   Arundhuti Ganguly, Bruce Lewis Daniel, Daniel...   \n",
       "\n",
       "                                  journal  year  \\\n",
       "0                    Discret. Appl. Math.  2007   \n",
       "1                    Discret. Appl. Math.  2005   \n",
       "2                            Graphs Comb.  2012   \n",
       "3                   Comb. Probab. Comput.  2011   \n",
       "4         Discret. Math. Algorithms Appl.  2009   \n",
       "...                                   ...   ...   \n",
       "13845993                       Proc. IEEE  2008   \n",
       "13845994                       Proc. IEEE  2008   \n",
       "13845995                       Proc. IEEE  2008   \n",
       "13845996                       Proc. IEEE  2008   \n",
       "13845997                       Proc. IEEE  2008   \n",
       "\n",
       "                                                      title  \n",
       "0         Every toroidal graph without adjacent triangle...  \n",
       "1         Decomposing toroidal graphs into circuits and ...  \n",
       "2         Maximum Directed Cuts in Graphs with Degree Co...  \n",
       "3                                        Better Bounds for   \n",
       "4         A Note on 3-colorable Plane Graphs without 5- ...  \n",
       "...                                                     ...  \n",
       "13845993  Design, Performance, and Applications of a Hyb...  \n",
       "13845994  Design, Performance, and Applications of a Hyb...  \n",
       "13845995  Design, Performance, and Applications of a Hyb...  \n",
       "13845996  Design, Performance, and Applications of a Hyb...  \n",
       "13845997  Design, Performance, and Applications of a Hyb...  \n",
       "\n",
       "[13845998 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ego_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810db5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_df.to_parquet(\"ego_coauthors.parquet\", index=False)\n",
    "s3_path = \"s3://lab/ego_coauthors.parquet\"  # bucket + key\n",
    "\n",
    "# Save directly to MinIO\n",
    "ego_df.to_parquet(s3_path, engine=\"pyarrow\", index=False, filesystem=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df5bc00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_df.to_parquet(\"ego_df.parquet\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "779e4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fs.open(\"s3://lab/name_gender_dataset.csv\") as f:\n",
    "    g1 = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/wgnd_2_0_name-gender-langcode.csv\") as f:\n",
    "    g2 = pd.read_csv(f)\n",
    "\n",
    "g1=g1[[\"Name\",\"Gender\"]]\n",
    "g2[[\"Name\",\"Gender\"]]=g2[[\"name\",\"gender\"]]\n",
    "g2=g2[[\"Name\",\"Gender\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4106024c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>a laura</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>a lelia</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>a lelia</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>a lerah</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>a lerah</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>a lex ander</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>a lex ander</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>a lie</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>a lisa</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>a lisa</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>a liza</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>a liza</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>a lmos</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>a luan</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>a mang</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>a me</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>a men</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>a mer</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>a mer</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>a merie</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>a merie</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>a mou</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>a nai</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>a nak la</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>a nak la</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>a nao</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>a neng</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>a nette</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>a niang</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>a niyah</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>a niyah</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>a nv</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>a ou</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>a pan</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>a pao</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>a pi</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>a pu</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>a qie</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>a qiong</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>a que</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>a ran</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>a rang</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>a rao</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>a re</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>a ri</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>a rin</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>a rin</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>a ron</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>a ron</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>a s m</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name Gender\n",
       "100      a laura      F\n",
       "101      a lelia      F\n",
       "102      a lelia      F\n",
       "103      a lerah      F\n",
       "104      a lerah      F\n",
       "105  a lex ander      M\n",
       "106  a lex ander      M\n",
       "107        a lie      M\n",
       "108       a lisa      F\n",
       "109       a lisa      F\n",
       "110       a liza      F\n",
       "111       a liza      F\n",
       "112       a lmos      M\n",
       "113       a luan      M\n",
       "114       a mang      F\n",
       "115         a me      F\n",
       "116        a men      M\n",
       "117        a mer      M\n",
       "118        a mer      M\n",
       "119      a merie      F\n",
       "120      a merie      F\n",
       "121        a mou      M\n",
       "122        a nai      F\n",
       "123     a nak la      M\n",
       "124     a nak la      M\n",
       "125        a nao      F\n",
       "126       a neng      M\n",
       "127      a nette      F\n",
       "128      a niang      F\n",
       "129      a niyah      F\n",
       "130      a niyah      F\n",
       "131         a nv      F\n",
       "132         a ou      M\n",
       "133        a pan      F\n",
       "134        a pao      M\n",
       "135         a pi      M\n",
       "136         a pu      F\n",
       "137        a qie      M\n",
       "138      a qiong      F\n",
       "139        a que      M\n",
       "140        a ran      M\n",
       "141       a rang      M\n",
       "142        a rao      F\n",
       "143         a re      F\n",
       "144         a ri      M\n",
       "145        a rin      F\n",
       "146        a rin      F\n",
       "147        a ron      M\n",
       "148        a ron      M\n",
       "149        a s m      M"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "add36b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>William</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978307</th>\n",
       "      <td>히카리</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978308</th>\n",
       "      <td>히토미</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978309</th>\n",
       "      <td>힘찬</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978310</th>\n",
       "      <td>凉峰</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978311</th>\n",
       "      <td>凉翼</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21978312 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name Gender\n",
       "0           James      M\n",
       "1            John      M\n",
       "2          Robert      M\n",
       "3         Michael      M\n",
       "4         William      M\n",
       "...           ...    ...\n",
       "21978307      히카리      F\n",
       "21978308      히토미      F\n",
       "21978309       힘찬      M\n",
       "21978310       凉峰      M\n",
       "21978311       凉翼      M\n",
       "\n",
       "[21978312 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([g1,g2],axis=0,ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
