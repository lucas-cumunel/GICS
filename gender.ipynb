{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9df7e31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /opt/python/lib/python3.13/site-packages (1.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install lxml\n",
    "import os\n",
    "import s3fs\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "#from lxml import etree\n",
    "import pandas as pd\n",
    "%pip install unidecode\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = '1J9SZCURG0IZM0VVX37D'\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = '9CKCagFEDjzIKptrZy1sBOI2+C8+94ojH+LONi54'\n",
    "os.environ[\"AWS_SESSION_TOKEN\"] = 'eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NLZXkiOiIxSjlTWkNVUkcwSVpNMFZWWDM3RCIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sImF1ZCI6WyJtaW5pby1kYXRhbm9kZSIsIm9ueXhpYSIsImFjY291bnQiXSwiYXV0aF90aW1lIjoxNzYxNjM5MDM3LCJhenAiOiJvbnl4aWEiLCJlbWFpbCI6Imx1Y2FzLmN1bXVuZWxAZW5zYWUuZnIiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZXhwIjoxNzYyMjQzODYwLCJmYW1pbHlfbmFtZSI6IkN1bXVuZWwiLCJnaXZlbl9uYW1lIjoiTHVjYXMiLCJncm91cHMiOlsiVVNFUl9PTllYSUEiLCJzdGF0YXBwLXNlZ21lZGljIl0sImlhdCI6MTc2MTYzOTA2MCwiaXNzIjoiaHR0cHM6Ly9hdXRoLmxhYi5zc3BjbG91ZC5mci9hdXRoL3JlYWxtcy9zc3BjbG91ZCIsImp0aSI6Im9ucnRydDo4NzNjZTViNy04ZDQ3LWQ0NGItNDk3NC04NWNjNDA3NWJkZWUiLCJuYW1lIjoiTHVjYXMgQ3VtdW5lbCIsInBvbGljeSI6InN0c29ubHkiLCJwcmVmZXJyZWRfdXNlcm5hbWUiOiJsYWIiLCJyZWFsbV9hY2Nlc3MiOnsicm9sZXMiOlsib2ZmbGluZV9hY2Nlc3MiLCJ1bWFfYXV0aG9yaXphdGlvbiIsImRlZmF1bHQtcm9sZXMtc3NwY2xvdWQiXX0sInJlc291cmNlX2FjY2VzcyI6eyJhY2NvdW50Ijp7InJvbGVzIjpbIm1hbmFnZS1hY2NvdW50IiwibWFuYWdlLWFjY291bnQtbGlua3MiLCJ2aWV3LXByb2ZpbGUiXX19LCJyb2xlcyI6WyJvZmZsaW5lX2FjY2VzcyIsInVtYV9hdXRob3JpemF0aW9uIiwiZGVmYXVsdC1yb2xlcy1zc3BjbG91ZCJdLCJzY29wZSI6Im9wZW5pZCBwcm9maWxlIGdyb3VwcyBlbWFpbCIsInNpZCI6IjdlMzg4NmFiLWUxYWEtNDZiNS04MGE2LTRkNDRiYzk0NzJkZiIsInN1YiI6ImUyZDc4NjRjLTcwMzItNDI0ZC04OTA2LWU0ZjhiNDFjYzAwMyIsInR5cCI6IkJlYXJlciJ9.oBZKGdOLRwmoT9SUMM2H5RfIPMoP22e8cotzbdlOdtscV3mC6HL1vp72nuBvp6kMECQOlsOeqVY7rSfNnMm8Jw'\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = 'us-east-1'\n",
    "fs = s3fs.S3FileSystem(\n",
    "    client_kwargs={'endpoint_url': 'https://'+'minio.lab.sspcloud.fr'},\n",
    "    key = os.environ[\"AWS_ACCESS_KEY_ID\"], \n",
    "    secret = os.environ[\"AWS_SECRET_ACCESS_KEY\"], \n",
    "    token = os.environ[\"AWS_SESSION_TOKEN\"])\n",
    "with fs.open(\"s3://lab/kgnd.csv\") as f:\n",
    "    kgnd = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/fuzzed.csv\") as f:\n",
    "    fuzz1 = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/fuzzed2.csv\") as f:\n",
    "    fuzz2 = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/ignd.csv\") as f:\n",
    "    ignd = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/conf_names.csv\") as f:\n",
    "    conf_names = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/wgnd.csv\") as f:\n",
    "    wgnd = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/jap_boys.csv\") as f:\n",
    "    jap1 = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/jap_girls.csv\") as f:\n",
    "    jap2 = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/art_names.csv\") as f:\n",
    "    art_names = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/cgnd.csv\") as f:\n",
    "    cgnd = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/usgnd.csv\") as f: #coulmont\n",
    "    usgnd = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/Indian-Male-Names.csv\") as f: #https://gist.github.com/mbejda/7f86ca901fe41bc14a63\n",
    "    imnd = pd.read_csv(f)\n",
    "#g1=g1[[\"Name\",\"Gender\"]]\n",
    "#wgnd[[\"Name\",\"Gender\"]]=wgnd[[\"name\",\"gender\"]]\n",
    "#wgnd=wgnd[[\"Name\",\"Gender\"]]\n",
    "#g3[[\"Name\",\"Gender\"]]=g3[[\"firstName\",\"GenderString\"]]\n",
    "#g3=g3[[\"Name\",\"Gender\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f03854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /opt/python/lib/python3.13/site-packages (1.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "wgnd[\"Name\"]=wgnd[\"Name\"].str.replace(\"-\", \" \")\n",
    "wgnd[\"Name\"]=wgnd[\"Name\"].fillna(\"\").astype(str).apply(lambda x: unidecode(x))\n",
    "wgnd[\"Name\"]=wgnd[\"Name\"].str.split(\" \").str[0]\n",
    "wgnd[\"Name\"]=wgnd[\"Name\"].str.lower().apply(lambda x: re.sub(r'[^a-z\\s]', '', x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38eeca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgnd[\"Name\"]=cgnd[\"Chinese_Pinyin_name\"]\n",
    "mean_values = cgnd[['pinyin_male_prob_1980-1999', 'pinyin_male_prob_2000-2019']].mean(axis=1)\n",
    "\n",
    "cgnd['Gender'] = None\n",
    "cgnd.loc[mean_values > 0.6, 'Gender'] = 'M'\n",
    "cgnd.loc[mean_values < 0.4, 'Gender'] = 'F'\n",
    "cgnd=cgnd[[\"Name\",\"Gender\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef8b595f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seojun</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>minjun</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doyun</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yejun</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hajun</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55498</th>\n",
       "      <td>sujannayeim</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55499</th>\n",
       "      <td>sujannacaea</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55500</th>\n",
       "      <td>sujannahyeon</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55501</th>\n",
       "      <td>sujanmyeong</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55502</th>\n",
       "      <td>sujanbyeol</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55503 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name Gender\n",
       "0            seojun      M\n",
       "1            minjun      M\n",
       "2             doyun      M\n",
       "3             yejun      M\n",
       "4             hajun      M\n",
       "...             ...    ...\n",
       "55498   sujannayeim      F\n",
       "55499   sujannacaea      F\n",
       "55500  sujannahyeon      F\n",
       "55501   sujanmyeong      F\n",
       "55502    sujanbyeol      F\n",
       "\n",
       "[55503 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kgnd1[\"Name\"]=kgnd1[\"name\"].apply(lambda x: re.sub(r\"[^가-힣\\s]\", \"\", str(x)).strip())\n",
    "kgnd1[\"Name\"]=kgnd1[\"Name\"].fillna(\"\").astype(str).apply(lambda x: unidecode(x))\n",
    "kgnd1=kgnd1[[\"Name\"]]\n",
    "kgnd1[\"Gender\"]=\"M\"\n",
    "kgnd2[\"Name\"]=kgnd2[\"name\"].apply(lambda x: re.sub(r\"[^가-힣\\s]\", \"\", str(x)).strip())\n",
    "kgnd2[\"Name\"]=kgnd2[\"Name\"].fillna(\"\").astype(str).apply(lambda x: unidecode(x))\n",
    "kgnd2=kgnd2[[\"Name\"]]\n",
    "kgnd2[\"Gender\"]=\"F\"\n",
    "kgnd=pd.concat([kgnd1,kgnd2],axis=0,ignore_index=True)\n",
    "kgnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f316001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>shaurya</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aabha</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aabharana</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>aabheer</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21887</th>\n",
       "      <td>zubin</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21888</th>\n",
       "      <td>zuha</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21889</th>\n",
       "      <td>zuhaibnasim</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21890</th>\n",
       "      <td>zuri</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21891</th>\n",
       "      <td>zuveb</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Gender\n",
       "0                       M\n",
       "24         shaurya      M\n",
       "25           aabha      F\n",
       "26       aabharana      F\n",
       "27         aabheer      M\n",
       "...            ...    ...\n",
       "21887        zubin      M\n",
       "21888         zuha      F\n",
       "21889  zuhaibnasim      M\n",
       "21890         zuri      F\n",
       "21891        zuveb      M\n",
       "\n",
       "[15280 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"imnd[\"Name\"]=imnd[\"name\"]\n",
    "imnd[\"Gender\"]=imnd[\"gender\"].str.upper()\n",
    "imnd=imnd.drop(columns=[\"name\",\"gender\",\"race\"])\n",
    "imnd[\"Name\"]=imnd[\"Name\"].fillna(\"\").astype(str).apply(lambda x: unidecode(x)).str.replace(\" \",\"\")\n",
    "imnd[\"Name\"]=imnd[\"Name\"].apply(lambda x: re.sub(r\"[^a-z]\", \"\", str(x)).strip())\n",
    "imnd\n",
    "ignd=pd.merge(ignd,imnd, on=\"Name\",how=\"outer\").drop_duplicates()\n",
    "ignd[\"Gender\"]=ignd[\"Gender_x\"].combine_first(ignd[\"Gender_y\"])\n",
    "ignd=ignd.drop(columns=[\"Gender_x\",\"Gender_y\"])\"\"\"\n",
    "ignd[\"Name\"]=ignd[\"Name\"].apply(lambda x: re.sub(r\"[^a-z]\", \"\", str(x)).strip())\n",
    "ignd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca23e254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aabheer</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aadarsh</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aadesh</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadhir</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175901</th>\n",
       "      <td>zuha</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175902</th>\n",
       "      <td>zuri</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175903</th>\n",
       "      <td>zuha</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175904</th>\n",
       "      <td>zuri</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175905</th>\n",
       "      <td>zuri</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1175906 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name Gender\n",
       "0        aabheer      M\n",
       "1        aadarsh      M\n",
       "2         aadesh      M\n",
       "3         aadhir      M\n",
       "4           aadi      M\n",
       "...          ...    ...\n",
       "1175901     zuha      F\n",
       "1175902     zuri      F\n",
       "1175903     zuha      F\n",
       "1175904     zuri      F\n",
       "1175905     zuri      F\n",
       "\n",
       "[1175906 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignd1[\"Name\"]=ignd1[\"name\"]\n",
    "ignd1=ignd1[[\"Name\"]]\n",
    "ignd1[\"Gender\"]=\"M\"\n",
    "ignd2[\"Name\"]=ignd2[\"name\"]\n",
    "ignd2=ignd2[[\"Name\"]]\n",
    "ignd2[\"Gender\"]=\"F\"\n",
    "ignd=pd.concat([ignd1,ignd2],axis=0,ignore_index=True)\n",
    "ignd[\"Name\"]=ignd[\"Name\"].str.lower()\n",
    "ignd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faf908ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aachi</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aamu</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aasa</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aasu</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aata</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20898</th>\n",
       "      <td>zozo</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20899</th>\n",
       "      <td>zuihou</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20900</th>\n",
       "      <td>zuimaru</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20901</th>\n",
       "      <td>zuimu</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20902</th>\n",
       "      <td>zuimu</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20903 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name Gender\n",
       "0        aachi      F\n",
       "1         aamu      F\n",
       "2         aasa      F\n",
       "3         aasu      M\n",
       "4         aata      M\n",
       "...        ...    ...\n",
       "20898     zozo      M\n",
       "20899   zuihou      M\n",
       "20900  zuimaru      M\n",
       "20901    zuimu      M\n",
       "20902    zuimu      M\n",
       "\n",
       "[20903 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jap1[\"Gender\"]=\"M\"\n",
    "jap1[\"Name\"]=jap1[\"name\"].str.lower()\n",
    "jap1=jap1.drop(columns=[\"letter\",\"page\",\"name\"])\n",
    "jap2[\"Gender\"]=\"F\"\n",
    "jap2[\"Name\"]=jap2[\"name\"].str.lower()\n",
    "jap2=jap2.drop(columns=[\"letter\",\"page\",\"name\"])\n",
    "jgnd=pd.merge(jap1,jap2, on=\"Name\", how=\"outer\")\n",
    "jgnd[\"Gender\"]=jgnd[\"Gender_x\"].apply(lambda x: \"F\" if pd.isna(x) else x) #unisex = M\n",
    "jgnd=jgnd.drop(columns=[\"Gender_x\",\"Gender_y\"])\n",
    "jgnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4771fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_list = fs.glob(\"s3://lab/yob????.txt\")\n",
    "df=pd.DataFrame()\n",
    "for i in us_list :\n",
    "    with fs.open(f\"s3://{i}\") as f:\n",
    "        temp = pd.read_csv(f, header=None, names=['Name', 'Gender', 'Count'])\n",
    "    df=pd.concat([df,temp], axis=0,ignore_index=True)\n",
    "\n",
    "s3_path = \"s3://lab/usgnd.csv\"\n",
    "\n",
    "df.to_csv(s3_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "545eb5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(names) :\n",
    "    names[\"Name\"]=names[\"name\"]\n",
    "    names=names.drop(columns=[\"name\"])\n",
    "    names[\"Name\"]=names[\"Name\"].str.replace(\"-\", \" \")\n",
    "    names[\"Name\"]=names[\"Name\"].str.split(\" \").str[0]\n",
    "    names[\"Name\"]=names[\"Name\"].fillna(\"\").astype(str).apply(lambda x: unidecode(x))\n",
    "    names[\"Name\"]=names[\"Name\"].str.lower().apply(lambda x: re.sub(r'[^a-z\\s]', '', x) if isinstance(x, str) else x)\n",
    "    return names\n",
    "conf_names=prep(conf_names)\n",
    "art_names=prep(art_names)\n",
    "names=pd.concat([art_names,conf_names],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4028e983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kodai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>norimichi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ameya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>george</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kenji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403975</th>\n",
       "      <td>mhanaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403976</th>\n",
       "      <td>johannan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403977</th>\n",
       "      <td>mamfe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403978</th>\n",
       "      <td>nopparat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403979</th>\n",
       "      <td>velayudhan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403980 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name\n",
       "0            kodai\n",
       "1        norimichi\n",
       "2            ameya\n",
       "3           george\n",
       "4            kenji\n",
       "...            ...\n",
       "403975      mhanaj\n",
       "403976    johannan\n",
       "403977       mamfe\n",
       "403978    nopparat\n",
       "403979  velayudhan\n",
       "\n",
       "[403980 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz=pd.concat([fuzz1,fuzz2],axis=0, ignore_index=True)\n",
    "names = names.merge(fuzz, left_on='Name', right_on='Name', how='left')\n",
    "names['Name'] = names['New_name'].combine_first(names['Name'])\n",
    "names=names.drop(columns=[\"New_name\",\"Score\"])\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb9da35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(24.82474132822827)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnd=pd.concat([wgnd,cgnd,kgnd,ignd,jgnd,usgnd],axis=0,ignore_index=True)\n",
    "match_df = names.drop_duplicates().merge(gnd.drop_duplicates(), how=\"left\", on=\"Name\")\n",
    "(match_df[\"Gender\"].isna()).sum()/len(match_df)*100 #26,2%   55,6% art, 50,9% conf, 32% conf 37% art avec chinois 30.6% conf 36% art avec coréen 30.4% 35.9% avec indien 35,8\n",
    "#(match_df[\"Gender\"]==\"F\").sum()/len(match_df)*100 #24,8%    21% conf 20% art F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ae9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install rapidfuzz\n",
    "from rapidfuzz import fuzz\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Threshold for similarity (0-100)\n",
    "SIMILARITY_THRESHOLD = 90  # Adjust as needed\n",
    "\n",
    "# Build dictionary groups by first two letters\n",
    "def build_prefix_dict(df):\n",
    "    prefix_dict = defaultdict(list)\n",
    "    for name in df[\"Name\"]:\n",
    "        if isinstance(name, str):\n",
    "            prefix = name[:2].lower()\n",
    "            prefix_dict[prefix].append(name)\n",
    "    return prefix_dict\n",
    "\n",
    "\n",
    "def match_name_fast(name, prefix_dict, threshold=SIMILARITY_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Returns first acceptable match (>= threshold) in the relevant prefix group.\n",
    "    Stops early once threshold met.\n",
    "    \"\"\"\n",
    "    if not isinstance(name, str) or len(name) < 1:\n",
    "        return None, None\n",
    "\n",
    "    prefix = name[:2].lower()\n",
    "    candidates = prefix_dict.get(prefix, [])\n",
    "\n",
    "    for candidate in candidates:\n",
    "        score = fuzz.ratio(name, candidate)\n",
    "        if score >= threshold:\n",
    "            return candidate, score  # early stop once threshold reached\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# match_df = pd.read_csv(\"to_match.csv\")\n",
    "# gnd = pd.read_csv(\"dictionary.csv\")\n",
    "\n",
    "prefix_dict = build_prefix_dict(gnd)\n",
    "mr = []\n",
    "\n",
    "for name in match_df[match_df[\"Gender\"].isna()][\"Name\"]:\n",
    "    matched_name, score = match_name_fast(name, prefix_dict)\n",
    "    mr.append((name, matched_name, score))\n",
    "\n",
    "# Add results to DataFrame\n",
    "#match_df[\"Matched_Name\"] = [m[1] for m in matched_results]\n",
    "#match_df[\"Score\"] = [m[2] for m in matched_results]\n",
    "\n",
    "print(\"Matching completed!\")\n",
    "\n",
    "# Optional: Save to CSV\n",
    "# match_df.to_csv(\"matched_names.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f2f22a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', None, None),\n",
       " ('shyh', None, None),\n",
       " ('lappui', None, None),\n",
       " ('magns', None, None),\n",
       " ('fabrycio', None, None),\n",
       " ('maykon', None, None),\n",
       " ('zlem', None, None),\n",
       " ('tsachy', None, None),\n",
       " ('christianeike', None, None),\n",
       " ('frankjosef', None, None),\n",
       " ('yuhongze', None, None),\n",
       " ('muasaad', None, None),\n",
       " ('douard', None, None),\n",
       " ('ojoung', None, None),\n",
       " ('phablo', None, None),\n",
       " ('heeseung', None, None),\n",
       " ('ramji', None, None),\n",
       " ('layki', None, None),\n",
       " ('wonpil', None, None),\n",
       " ('kaichieh', None, None),\n",
       " ('odej', None, None),\n",
       " ('aryabartta', None, None),\n",
       " ('hsuvas', None, None),\n",
       " ('henkjan', None, None),\n",
       " ('hsiaoyu', None, None),\n",
       " ('animashree', None, None),\n",
       " ('hayretdin', None, None),\n",
       " ('yungyih', None, None),\n",
       " ('chienchung', None, None),\n",
       " ('yuwing', None, None),\n",
       " ('ericolivier', None, None),\n",
       " ('flvio', None, None),\n",
       " ('vrizlynn', None, None),\n",
       " ('minz', None, None),\n",
       " ('keunwoo', None, None),\n",
       " ('jaehyeok', None, None),\n",
       " ('kyungdon', None, None),\n",
       " ('abyayananda', None, None),\n",
       " ('leanh', None, None),\n",
       " ('liminn', None, None),\n",
       " ('dmtr', None, None),\n",
       " ('quanziang', None, None),\n",
       " ('vuthea', None, None),\n",
       " ('chinazunwa', None, None),\n",
       " ('heechul', None, None),\n",
       " ('ritabrata', None, None),\n",
       " ('joonsik', None, None),\n",
       " ('wonjin', None, None),\n",
       " ('hyeonhoon', None, None),\n",
       " ('glsen', None, None),\n",
       " ('bourahla', None, None),\n",
       " ('agatay', 'agata', 90.9090909090909),\n",
       " ('junghoon', None, None),\n",
       " ('youngduck', None, None),\n",
       " ('chingchang', None, None),\n",
       " ('ngocquang', None, None),\n",
       " ('phengann', None, None),\n",
       " ('yangsibo', None, None),\n",
       " ('vctor', None, None),\n",
       " ('robbertjan', None, None),\n",
       " ('ittay', None, None),\n",
       " ('tosiron', None, None),\n",
       " ('suayb', None, None),\n",
       " ('suriyadeepan', None, None),\n",
       " ('shoffan', None, None),\n",
       " ('sungchul', None, None),\n",
       " ('junehyoung', None, None),\n",
       " ('sainbayar', None, None),\n",
       " ('klausrobert', None, None),\n",
       " ('ngel', None, None),\n",
       " ('mikls', None, None),\n",
       " ('kobbi', None, None),\n",
       " ('kyungtae', None, None),\n",
       " ('seockhwan', None, None),\n",
       " ('dahoon', None, None),\n",
       " ('cenker', None, None),\n",
       " ('sethu', None, None),\n",
       " ('yoonna', None, None),\n",
       " ('taewoo', None, None),\n",
       " ('heuiseok', None, None),\n",
       " ('philalexander', None, None),\n",
       " ('paulandr', None, None),\n",
       " ('yoonhyuk', None, None),\n",
       " ('chongkwon', None, None),\n",
       " ('tsunghui', None, None),\n",
       " ('syamsiah', None, None),\n",
       " ('aybke', None, None),\n",
       " ('jrme', None, None),\n",
       " ('catar', None, None),\n",
       " ('tabiai', None, None),\n",
       " ('stonge', None, None),\n",
       " ('waichoong', None, None),\n",
       " ('octavianeugen', None, None),\n",
       " ('rudrasis', None, None),\n",
       " ('hvard', None, None),\n",
       " ('pl', None, None),\n",
       " ('wajeb', None, None),\n",
       " ('kaiuwe', None, None),\n",
       " ('swaprava', None, None),\n",
       " ('zag', None, None),\n",
       " ('tuantang', None, None),\n",
       " ('trungson', None, None),\n",
       " ('chyiyeu', None, None),\n",
       " ('thaihoang', None, None),\n",
       " ('taminul', None, None),\n",
       " ('choyon', None, None),\n",
       " ('inkit', None, None),\n",
       " ('jongoh', None, None),\n",
       " ('kukjin', None, None),\n",
       " ('iadh', None, None),\n",
       " ('nikifar', None, None),\n",
       " ('toktam', None, None),\n",
       " ('taewoong', None, None),\n",
       " ('jaegul', None, None),\n",
       " ('mohatashem', None, None),\n",
       " ('changwook', None, None),\n",
       " ('ngelo', None, None),\n",
       " ('cc', None, None),\n",
       " ('kyunghyun', None, None),\n",
       " ('ashiqur', None, None),\n",
       " ('zbulon', None, None),\n",
       " ('prarabdh', None, None),\n",
       " ('cdric', None, None),\n",
       " ('dixant', None, None),\n",
       " ('kibeom', None, None),\n",
       " ('angjoo', None, None),\n",
       " ('jeonghoon', None, None),\n",
       " ('byeongjoon', None, None),\n",
       " ('abdulmotaleb', None, None),\n",
       " ('saumajit', None, None),\n",
       " ('wahyudin', None, None),\n",
       " ('serio', 'serito', 90.9090909090909),\n",
       " ('yugin', None, None),\n",
       " ('yichieh', None, None),\n",
       " ('bndicte', None, None),\n",
       " ('quocviet', None, None),\n",
       " ('wonjoo', None, None),\n",
       " ('jewook', None, None),\n",
       " ('jrmy', None, None),\n",
       " ('youngchul', None, None),\n",
       " ('goston', None, None),\n",
       " ('nstor', None, None),\n",
       " ('yaushian', None, None),\n",
       " ('jyunyu', None, None),\n",
       " ('hsiangfu', None, None),\n",
       " ('houjeung', None, None),\n",
       " ('insoo', None, None),\n",
       " ('ebroul', None, None),\n",
       " ('sihah', None, None),\n",
       " ('eepeng', None, None),\n",
       " ('zhouyayan', None, None),\n",
       " ('tuvi', None, None),\n",
       " ('rojanaye', None, None),\n",
       " ('cheolho', None, None),\n",
       " ('anujraaj', None, None),\n",
       " ('kwangting', None, None),\n",
       " ('zgr', None, None),\n",
       " ('zilyu', None, None),\n",
       " ('jeanflorent', None, None),\n",
       " ('wingyue', None, None),\n",
       " ('poompak', None, None),\n",
       " ('ins', None, None),\n",
       " ('chenfanfu', None, None),\n",
       " ('calinadrian', None, None),\n",
       " ('najoung', None, None),\n",
       " ('rynson', None, None),\n",
       " ('papangkorn', None, None),\n",
       " ('pierreyves', None, None),\n",
       " ('cllia', None, None),\n",
       " ('seyedmajid', None, None),\n",
       " ('warut', None, None),\n",
       " ('heekyu', None, None),\n",
       " ('toanvan', None, None),\n",
       " ('beongku', None, None),\n",
       " ('benot', None, None),\n",
       " ('kak', None, None),\n",
       " ('adewole', None, None),\n",
       " ('pter', None, None),\n",
       " ('deepanway', None, None),\n",
       " ('slrn', None, None),\n",
       " ('mobarakol', None, None),\n",
       " ('khyodeno', None, None),\n",
       " ('quangcuong', None, None),\n",
       " ('charlesantoine', None, None),\n",
       " ('paulhenry', None, None),\n",
       " ('w', None, None),\n",
       " ('auroop', None, None),\n",
       " ('boryuh', None, None),\n",
       " ('rdiger', None, None),\n",
       " ('bodhisatwa', None, None),\n",
       " ('shahbozbek', None, None),\n",
       " ('tanghaoran', None, None),\n",
       " ('tih', None, None),\n",
       " ('gaik', None, None),\n",
       " ('sungroh', None, None),\n",
       " ('aldri', None, None),\n",
       " ('xieyuanli', None, None),\n",
       " ('myungjin', None, None),\n",
       " ('yeow', None, None),\n",
       " ('sopam', None, None),\n",
       " ('iigo', None, None),\n",
       " ('jungseock', None, None),\n",
       " ('jenqneng', None, None),\n",
       " ('merc', None, None),\n",
       " ('rocrate', None, None),\n",
       " ('seonwook', None, None),\n",
       " ('rattapoom', None, None),\n",
       " ('shafaatunnur', None, None),\n",
       " ('shohruh', None, None),\n",
       " ('hctor', None, None),\n",
       " ('ripunjoy', None, None),\n",
       " ('liyiming', None, None),\n",
       " ('tapomayukh', None, None),\n",
       " ('marioosvin', None, None),\n",
       " ('saeyoung', None, None),\n",
       " ('xuweiyi', None, None),\n",
       " ('shihfu', None, None),\n",
       " ('chunghyok', None, None),\n",
       " ('tsungyi', None, None),\n",
       " ('yentung', None, None),\n",
       " ('amirbek', None, None),\n",
       " ('kochise', None, None),\n",
       " ('bidipta', None, None),\n",
       " ('pierreandr', None, None),\n",
       " ('ungsik', None, None),\n",
       " ('olechristoffer', None, None),\n",
       " ('prasitthichai', None, None),\n",
       " ('mnacho', None, None),\n",
       " ('wangchiew', None, None),\n",
       " ('loet', None, None),\n",
       " ('kijung', None, None),\n",
       " ('jeanraphal', None, None),\n",
       " ('abhronil', None, None),\n",
       " ('huuphong', None, None),\n",
       " ('tienhuy', None, None),\n",
       " ('huuloc', None, None),\n",
       " ('tinhanh', None, None),\n",
       " ('huythach', None, None),\n",
       " ('quangvinh', None, None),\n",
       " ('zafrir', None, None),\n",
       " ('hyeok', None, None),\n",
       " ('dokjun', None, None),\n",
       " ('darsih', None, None),\n",
       " ('nontawat', None, None),\n",
       " ('jayakorn', None, None),\n",
       " ('nuttapong', None, None),\n",
       " ('germn', None, None),\n",
       " ('bumsub', None, None),\n",
       " ('mihly', None, None),\n",
       " ('adesesan', None, None),\n",
       " ('dipkamal', None, None),\n",
       " ('pritheega', None, None),\n",
       " ('llus', None, None),\n",
       " ('pdraig', None, None),\n",
       " ('seonghoon', None, None),\n",
       " ('sukyung', None, None),\n",
       " ('ccile', None, None),\n",
       " ('hannasophia', None, None),\n",
       " ('herumb', None, None),\n",
       " ('gatan', None, None),\n",
       " ('byungin', None, None),\n",
       " ('seyedmohsen', None, None),\n",
       " ('maverson', None, None),\n",
       " ('joonsuk', None, None),\n",
       " ('eklove', None, None),\n",
       " ('tejeswinee', None, None),\n",
       " ('wasiu', None, None),\n",
       " ('atnafu', None, None),\n",
       " ('abinew', None, None),\n",
       " ('aliceagnes', None, None),\n",
       " ('khanhbinh', None, None),\n",
       " ('hlion', None, None),\n",
       " ('ariharasudhan', None, None),\n",
       " ('hansarno', None, None),\n",
       " ('heungno', None, None),\n",
       " ('fedelucio', None, None),\n",
       " ('arutyun', None, None),\n",
       " ('abdolmahdi', None, None),\n",
       " ('vijja', None, None),\n",
       " ('razib', None, None),\n",
       " ('hsuanyin', None, None),\n",
       " ('niserik', None, None),\n",
       " ('beln', None, None),\n",
       " ('bhavuk', None, None),\n",
       " ('hanlim', None, None),\n",
       " ('youngwoo', None, None),\n",
       " ('giahuy', None, None),\n",
       " ('tovit', None, None),\n",
       " ('namwoo', None, None),\n",
       " ('yunjey', None, None),\n",
       " ('yodsawalai', None, None),\n",
       " ('louisphilippe', None, None),\n",
       " ('theja', None, None),\n",
       " ('chanbyoung', None, None),\n",
       " ('byungju', None, None),\n",
       " ('kwanghoon', None, None),\n",
       " ('cheonbok', None, None),\n",
       " ('pierrealexandre', None, None),\n",
       " ('soumyabrata', None, None),\n",
       " ('saimourya', None, None),\n",
       " ('alingeorgian', None, None),\n",
       " ('ciprianoctavian', None, None),\n",
       " ('jeanpatrick', None, None),\n",
       " ('hayawardh', None, None),\n",
       " ('seekiong', None, None),\n",
       " ('cailleteau', None, None),\n",
       " ('aristarque', None, None),\n",
       " ('doghonay', None, None),\n",
       " ('swakkhar', None, None),\n",
       " ('anwitaman', None, None),\n",
       " ('doyup', None, None),\n",
       " ('chiheon', None, None),\n",
       " ('seunghoon', None, None),\n",
       " ('hlne', None, None),\n",
       " ('favyen', None, None),\n",
       " ('erixhen', None, None),\n",
       " ('ehsaneddin', None, None),\n",
       " ('aboulnasr', None, None),\n",
       " ('kavosh', None, None),\n",
       " ('minsik', None, None),\n",
       " ('jeanfranois', None, None),\n",
       " ('pierrecyrille', None, None),\n",
       " ('arthikkaa', None, None),\n",
       " ('carolabibiane', None, None),\n",
       " ('sungsoo', None, None),\n",
       " ('kakan', None, None),\n",
       " ('kihyuk', None, None),\n",
       " ('taekho', None, None),\n",
       " ('woosung', None, None),\n",
       " ('aminollah', None, None),\n",
       " ('taeeui', None, None),\n",
       " ('josuantonio', None, None),\n",
       " ('seonghyeok', None, None),\n",
       " ('upmanu', None, None),\n",
       " ('lichia', None, None),\n",
       " ('szuyu', None, None),\n",
       " ('weeden', None, None),\n",
       " ('namhyuk', None, None),\n",
       " ('junsoo', None, None),\n",
       " ('chunggi', None, None),\n",
       " ('daesik', None, None),\n",
       " ('lhouari', None, None),\n",
       " ('atilim', None, None),\n",
       " ('jonlark', None, None),\n",
       " ('pramook', None, None),\n",
       " ('supasorn', None, None),\n",
       " ('shanchieh', None, None),\n",
       " ('tavpritesh', None, None),\n",
       " ('yakiyasu', None, None),\n",
       " ('claudionor', None, None),\n",
       " ('hwanhee', None, None),\n",
       " ('cheoneum', None, None),\n",
       " ('kyomin', None, None),\n",
       " ('jeanyves', None, None),\n",
       " ('maimaitiniyazi', None, None),\n",
       " ('tunazzina', None, None),\n",
       " ('ayta', None, None),\n",
       " ('khoat', None, None),\n",
       " ('scar', None, None),\n",
       " ('toufiqul', None, None),\n",
       " ('debmalya', None, None),\n",
       " ('tsetsentsengel', None, None),\n",
       " ('mrouane', None, None),\n",
       " ('mirk', None, None),\n",
       " ('nigamaa', None, None),\n",
       " ('kratarth', None, None),\n",
       " ('rubn', None, None),\n",
       " ('ickjai', None, None),\n",
       " ('shouvanik', None, None),\n",
       " ('gagangeet', None, None),\n",
       " ('lokamruth', None, None),\n",
       " ('byungik', None, None),\n",
       " ('byungmoon', None, None),\n",
       " ('eunyee', None, None),\n",
       " ('yenju', None, None),\n",
       " ('rutav', None, None),\n",
       " ('lopold', None, None),\n",
       " ('grme', None, None),\n",
       " ('edresson', None, None),\n",
       " ('ishu', None, None),\n",
       " ('sakriani', None, None),\n",
       " ('kitsuchart', None, None),\n",
       " ('sissades', None, None),\n",
       " ('minoh', None, None),\n",
       " ('kyoungwha', None, None),\n",
       " ('byoungtak', None, None),\n",
       " ('ludomir', None, None),\n",
       " ('faeze', None, None),\n",
       " ('louahdi', None, None),\n",
       " ('gbor', None, None),\n",
       " ('heeseok', None, None),\n",
       " ('jewon', None, None),\n",
       " ('thatchaphol', None, None),\n",
       " ('agneet', None, None),\n",
       " ('xhani', None, None),\n",
       " ('anomadarshi', None, None),\n",
       " ('ohhyun', None, None),\n",
       " ('kwanliu', None, None),\n",
       " ('gjorgjina', None, None),\n",
       " ('shekoofeh', None, None),\n",
       " ('dusit', None, None),\n",
       " ('siaucheng', None, None),\n",
       " ('huao', None, None),\n",
       " ('oralie', None, None),\n",
       " ('tungchun', None, None),\n",
       " ('wentsuen', None, None),\n",
       " ('tsunghan', None, None),\n",
       " ('jiafong', None, None),\n",
       " ('soumyottam', None, None),\n",
       " ('dongjoon', None, None),\n",
       " ('gisoo', None, None),\n",
       " ('myunghee', None, None),\n",
       " ('suradech', None, None),\n",
       " ('hsinyu', None, None),\n",
       " ('surahit', None, None),\n",
       " ('joonbum', None, None),\n",
       " ('mookund', None, None),\n",
       " ('massihreza', None, None),\n",
       " ('daewoong', None, None),\n",
       " ('chiatung', None, None),\n",
       " ('salekul', None, None),\n",
       " ('younkyung', None, None),\n",
       " ('dinhcuong', None, None),\n",
       " ('tatseng', None, None),\n",
       " ('youngkeun', None, None),\n",
       " ('agnibh', None, None),\n",
       " ('indrayudh', None, None),\n",
       " ('maleerat', None, None),\n",
       " ('jhacson', None, None),\n",
       " ('gwnal', None, None),\n",
       " ('myungjoo', None, None),\n",
       " ('youngseok', None, None),\n",
       " ('kwokyan', None, None),\n",
       " ('ozora', None, None),\n",
       " ('adamos', None, None),\n",
       " ('sitabhra', None, None),\n",
       " ('frdo', None, None),\n",
       " ('sungwook', None, None),\n",
       " ('sylvestrealvise', None, None),\n",
       " ('tranthai', None, None),\n",
       " ('tienlam', None, None),\n",
       " ('hieuchi', None, None),\n",
       " ('hamamache', None, None),\n",
       " ('macduff', None, None),\n",
       " ('hoikwong', None, None),\n",
       " ('kibo', None, None),\n",
       " ('nasanbayar', None, None),\n",
       " ('cndido', None, None),\n",
       " ('soochul', None, None),\n",
       " ('snke', None, None),\n",
       " ('hopein', None, None),\n",
       " ('ydo', None, None),\n",
       " ('behet', None, None),\n",
       " ('namsook', None, None),\n",
       " ('romn', None, None),\n",
       " ('taih', None, None),\n",
       " ('jaebaek', None, None),\n",
       " ('alkida', None, None),\n",
       " ('ssu', None, None),\n",
       " ('hsienkai', None, None),\n",
       " ('koansin', None, None),\n",
       " ('kloze', None, None),\n",
       " ('lzaro', None, None),\n",
       " ('klen', None, None),\n",
       " ('kiheiji', None, None),\n",
       " ('joostpieter', None, None),\n",
       " ('biswa', None, None),\n",
       " ('hyelin', None, None),\n",
       " ('fazlyn', None, None),\n",
       " ('apivich', None, None),\n",
       " ('upal', None, None),\n",
       " ('gke', None, None),\n",
       " ('aatman', None, None),\n",
       " ('wentau', None, None),\n",
       " ('clodric', None, None),\n",
       " ('vietanh', None, None),\n",
       " ('vicen', None, None),\n",
       " ('siewkei', None, None),\n",
       " ('aurojit', None, None),\n",
       " ('snikdho', None, None),\n",
       " ('qahhar', None, None),\n",
       " ('birzo', None, None),\n",
       " ('marienlorenzo', None, None),\n",
       " ('chiuyen', None, None),\n",
       " ('seokseong', None, None),\n",
       " ('vclav', None, None),\n",
       " ('ionutgabriel', None, None),\n",
       " ('tauhidur', None, None),\n",
       " ('hesameddin', None, None),\n",
       " ('seyyedali', None, None),\n",
       " ('dongwoo', None, None),\n",
       " ('thienminh', None, None),\n",
       " ('chungchieh', None, None),\n",
       " ('lindsetmo', None, None),\n",
       " ('duykhang', None, None),\n",
       " ('vantu', None, None),\n",
       " ('minhtriet', None, None),\n",
       " ('chnh', None, None),\n",
       " ('tegawend', None, None),\n",
       " ('holam', None, None),\n",
       " ('seventy', None, None),\n",
       " ('wooseok', None, None),\n",
       " ('carlosemiliano', None, None),\n",
       " ('sanberk', None, None),\n",
       " ('chanwoo', None, None),\n",
       " ('seyedarmin', None, None),\n",
       " ('phiala', None, None),\n",
       " ('somshubra', None, None),\n",
       " ('shugo', 'shuugo', 90.9090909090909),\n",
       " ('hernn', None, None),\n",
       " ('ginar', None, None),\n",
       " ('jeanrmy', None, None),\n",
       " ('louisalexandre', None, None),\n",
       " ('qazwan', None, None),\n",
       " ('noorsaliza', None, None),\n",
       " ('grard', None, None),\n",
       " ('guelareh', None, None),\n",
       " ('chihhsun', None, None),\n",
       " ('minki', 'mineki', 90.9090909090909),\n",
       " ('kripabandhu', None, None),\n",
       " ('jhoirene', None, None),\n",
       " ('ignavier', None, None),\n",
       " ('pinjui', None, None),\n",
       " ('crevel', None, None),\n",
       " ('trongthang', None, None),\n",
       " ('gyrgy', None, None),\n",
       " ('baketah', None, None),\n",
       " ('jaesik', None, None),\n",
       " ('cusuh', None, None),\n",
       " ('congduy', None, None),\n",
       " ('artidoro', None, None),\n",
       " ('byunggon', None, None),\n",
       " ('seongyeub', None, None),\n",
       " ('nyalleng', None, None),\n",
       " ('donghoon', None, None),\n",
       " ('woomyoung', None, None),\n",
       " ('juneho', None, None),\n",
       " ('yuehaw', None, None),\n",
       " ('abeeb', None, None),\n",
       " ('chenyangguang', None, None),\n",
       " ('savaskan', None, None),\n",
       " ('ralvi', None, None),\n",
       " ('yuhsing', None, None),\n",
       " ('willemjan', None, None),\n",
       " ('minhson', None, None),\n",
       " ('tebbi', None, None),\n",
       " ('azzoune', None, None),\n",
       " ('rejwanul', None, None),\n",
       " ('jaisidh', None, None),\n",
       " ('teik', None, None),\n",
       " ('razvanandrei', None, None),\n",
       " ('yenyun', None, None),\n",
       " ('hakkeung', None, None),\n",
       " ('quochuy', None, None),\n",
       " ('pierremarc', None, None),\n",
       " ('pohsuan', None, None),\n",
       " ('hyunchang', None, None),\n",
       " ('kmil', None, None),\n",
       " ('wonhyuk', None, None),\n",
       " ('tronghieu', None, None),\n",
       " ('minhkhoa', None, None),\n",
       " ('duynam', None, None),\n",
       " ('chihchung', None, None),\n",
       " ('yoonsuck', None, None),\n",
       " ('oshando', None, None),\n",
       " ('kamfai', None, None),\n",
       " ('maungmaung', None, None),\n",
       " ('robail', None, None),\n",
       " ('anushkrishna', None, None),\n",
       " ('koffka', None, None),\n",
       " ('jenyin', None, None),\n",
       " ('jhihhuei', None, None),\n",
       " ('thouis', None, None),\n",
       " ('seongwook', None, None),\n",
       " ('kwekumuata', None, None),\n",
       " ('firoj', None, None),\n",
       " ('aishik', 'aishi', 90.9090909090909),\n",
       " ('duccuong', None, None),\n",
       " ('wonkwang', None, None),\n",
       " ('marieisaline', None, None),\n",
       " ('aekta', None, None),\n",
       " ('tshilidzi', None, None),\n",
       " ('khine', None, None),\n",
       " ('youngkyu', None, None),\n",
       " ('youngsoo', None, None),\n",
       " ('kap', None, None),\n",
       " ('janphilipp', None, None),\n",
       " ('ner', None, None),\n",
       " ('seyedhassan', None, None),\n",
       " ('kyeongbo', None, None),\n",
       " ('kyunghun', None, None),\n",
       " ('sukju', None, None),\n",
       " ('wonsuk', None, None),\n",
       " ('chihhsuan', None, None),\n",
       " ('glebys', None, None),\n",
       " ('dnes', None, None),\n",
       " ('shrunali', None, None),\n",
       " ('nikolaospanteleimon', None, None),\n",
       " ('jrmie', None, None),\n",
       " ('bakhrom', None, None),\n",
       " ('hcene', None, None),\n",
       " ('mrten', None, None),\n",
       " ('oranit', None, None),\n",
       " ('curisia', None, None),\n",
       " ('juneseok', None, None),\n",
       " ('blessius', None, None),\n",
       " ('syifa', None, None),\n",
       " ('novanto', None, None),\n",
       " ('nagur', None, None),\n",
       " ('duantengchuan', None, None),\n",
       " ('hueiyung', None, None),\n",
       " ('issarapong', None, None),\n",
       " ('gwnol', None, None),\n",
       " ('minhyoung', None, None),\n",
       " ('hsiangting', None, None),\n",
       " ('almukaddim', None, None),\n",
       " ('bohsiang', None, None),\n",
       " ('sihyun', None, None),\n",
       " ('wicak', None, None),\n",
       " ('ipoom', None, None),\n",
       " ('luks', None, None),\n",
       " ('lcia', None, None),\n",
       " ('rizzi', None, None),\n",
       " ('adugyamfi', None, None),\n",
       " ('roykrong', None, None),\n",
       " ('georgeandrei', None, None),\n",
       " ('andreimarius', None, None),\n",
       " ('cristiangeorge', None, None),\n",
       " ('dumitruclementin', None, None),\n",
       " ('tammuz', None, None),\n",
       " ('junhyung', None, None),\n",
       " ('lins', None, None),\n",
       " ('hyundong', None, None),\n",
       " ('ikboljon', None, None),\n",
       " ('kumangkem', None, None),\n",
       " ('mohammadtaghi', None, None),\n",
       " ('kiryung', None, None),\n",
       " ('rmer', None, None),\n",
       " ('dvij', None, None),\n",
       " ('mooryong', None, None),\n",
       " ('yihfarn', None, None),\n",
       " ('mariepaule', None, None),\n",
       " ('yuilam', None, None),\n",
       " ('hokyun', None, None),\n",
       " ('thuyduong', None, None),\n",
       " ('doyen', None, None),\n",
       " ('jongmyon', None, None),\n",
       " ('mehzooz', None, None),\n",
       " ('hsuanchih', None, None),\n",
       " ('bunyod', None, None),\n",
       " ('myounggyu', None, None),\n",
       " ('vietquoc', None, None),\n",
       " ('saumyadipta', None, None),\n",
       " ('amiangshu', None, None),\n",
       " ('varich', None, None),\n",
       " ('seungyoon', None, None),\n",
       " ('kajkolja', None, None),\n",
       " ('gambhire', None, None),\n",
       " ('kilic', None, None),\n",
       " ('aziida', None, None),\n",
       " ('odemir', None, None),\n",
       " ('noeloikeau', None, None),\n",
       " ('foutse', None, None),\n",
       " ('halyun', None, None),\n",
       " ('affum', None, None),\n",
       " ('duks', None, None),\n",
       " ('ameerahmuhsina', None, None),\n",
       " ('vt', None, None),\n",
       " ('komei', 'koumei', 90.9090909090909),\n",
       " ('supasate', None, None),\n",
       " ('chalermek', None, None),\n",
       " ('souvic', None, None),\n",
       " ('wathiq', None, None),\n",
       " ('jeandaniel', None, None),\n",
       " ('vwani', None, None),\n",
       " ('fuseini', None, None),\n",
       " ('themos', None, None),\n",
       " ('hsuehi', None, None),\n",
       " ('houcemeddine', None, None),\n",
       " ('ehecatl', None, None),\n",
       " ('zhenisbek', None, None),\n",
       " ('amartansh', None, None),\n",
       " ('akchunya', None, None),\n",
       " ('pierreantoine', None, None),\n",
       " ('salembilal', None, None),\n",
       " ('marcalexandre', None, None),\n",
       " ('fiodar', None, None),\n",
       " ('zulkefli', None, None),\n",
       " ('wonje', None, None),\n",
       " ('minsuk', None, None),\n",
       " ('jaaphenk', None, None),\n",
       " ('brighten', None, None),\n",
       " ('inwoo', None, None),\n",
       " ('hyunseok', None, None),\n",
       " ('isuru', None, None),\n",
       " ('youngjune', None, None),\n",
       " ('renaudalexandre', None, None),\n",
       " ('fangchieh', None, None),\n",
       " ('taojiannan', None, None),\n",
       " ('kalyanmoy', None, None),\n",
       " ('janniklas', None, None),\n",
       " ('dariamihaela', None, None),\n",
       " ('csar', None, None),\n",
       " ('seyedomid', None, None),\n",
       " ('roussel', None, None),\n",
       " ('soonhak', None, None),\n",
       " ('youngwoon', None, None),\n",
       " ('tejul', None, None),\n",
       " ('thophraste', None, None),\n",
       " ('senthilnath', None, None),\n",
       " ('tsungying', None, None),\n",
       " ('hsuhsun', None, None),\n",
       " ('hsini', None, None),\n",
       " ('chulwook', None, None),\n",
       " ('kyungseo', None, None),\n",
       " ('gunhee', None, None),\n",
       " ('siawlynn', None, None),\n",
       " ('kyubum', None, None),\n",
       " ('kwun', None, None),\n",
       " ('thanhtung', None, None),\n",
       " ('nhatquang', None, None),\n",
       " ('jeangabriel', None, None),\n",
       " ('pavas', None, None),\n",
       " ('wonwoo', None, None),\n",
       " ('kangyeol', None, None),\n",
       " ('saemee', None, None),\n",
       " ('jongryool', None, None),\n",
       " ('ccilia', None, None),\n",
       " ('hlose', None, None),\n",
       " ('yunghsiang', None, None),\n",
       " ('jeansbastien', None, None),\n",
       " ('shawkh', None, None),\n",
       " ('tzuyun', None, None),\n",
       " ('yihsiang', None, None),\n",
       " ('nikolaosioannis', None, None),\n",
       " ('seulip', None, None),\n",
       " ('yoojin', None, None),\n",
       " ('staphord', None, None),\n",
       " ('hmns', None, None),\n",
       " ('hmls', None, None),\n",
       " ('ummpk', None, None),\n",
       " ('islem', None, None),\n",
       " ('yvik', None, None),\n",
       " ('marmik', None, None),\n",
       " ('wangchunshu', None, None),\n",
       " ('jaeok', None, None),\n",
       " ('chompunuch', None, None),\n",
       " ('evripides', None, None),\n",
       " ('carlfredrik', None, None),\n",
       " ('kaikit', 'kaiki', 90.9090909090909),\n",
       " ('ustim', None, None),\n",
       " ('djorkarn', None, None),\n",
       " ('alexandrosapostolos', None, None),\n",
       " ('boonserm', None, None),\n",
       " ('yoonhyung', None, None),\n",
       " ('eldert', None, None),\n",
       " ('anoosheh', None, None),\n",
       " ('hanwool', None, None),\n",
       " ('sverine', None, None),\n",
       " ('lyumanshan', None, None),\n",
       " ('iury', None, None),\n",
       " ('byeonghee', None, None),\n",
       " ('adhiguna', None, None),\n",
       " ('marcolivier', None, None),\n",
       " ('aummul', None, None),\n",
       " ('debarnab', None, None),\n",
       " ('jungyoub', None, None),\n",
       " ('hyunjong', None, None),\n",
       " ('sungzoon', None, None),\n",
       " ('woonseng', None, None),\n",
       " ('ingray', None, None),\n",
       " ('mofreh', None, None),\n",
       " ('sergeolivier', None, None),\n",
       " ('kyungho', None, None),\n",
       " ('byunghoon', None, None),\n",
       " ('karlludwig', None, None),\n",
       " ('ishanu', None, None),\n",
       " ('hsiaodong', None, None),\n",
       " ('lahav', None, None),\n",
       " ('hawshiuan', None, None),\n",
       " ('wonjun', None, None),\n",
       " ('hsiche', None, None),\n",
       " ('dokyun', None, None),\n",
       " ('amornyos', None, None),\n",
       " ('heungwing', None, None),\n",
       " ('clemensalexander', None, None),\n",
       " ('kweijay', None, None),\n",
       " ('akshatkumar', None, None),\n",
       " ('yujhe', None, None),\n",
       " ('andac', None, None),\n",
       " ('kiamal', None, None),\n",
       " ('namyoon', None, None),\n",
       " ('jafreezal', None, None),\n",
       " ('izzatdin', None, None),\n",
       " ('subba', None, None),\n",
       " ('theshani', None, None),\n",
       " ('kyumin', None, None),\n",
       " ('aounon', None, None),\n",
       " ('sewon', None, None),\n",
       " ('thrse', None, None),\n",
       " ('vorapong', None, None),\n",
       " ('vinayshekhar', None, None),\n",
       " ('aghil', None, None),\n",
       " ('youngmoon', None, None),\n",
       " ('hoirin', None, None),\n",
       " ('kyuwon', None, None),\n",
       " ('chulwoo', None, None),\n",
       " ('nagu', None, None),\n",
       " ('phaedonstelios', None, None),\n",
       " ('tamiovesa', None, None),\n",
       " ('yohay', None, None),\n",
       " ('abdkrim', None, None),\n",
       " ('megasthenis', None, None),\n",
       " ('oluwasanmi', None, None),\n",
       " ('abdelmohsen', None, None),\n",
       " ('hsienchin', None, None),\n",
       " ('graud', None, None),\n",
       " ('poulomee', None, None),\n",
       " ('paat', None, None),\n",
       " ('abdelmaseeh', None, None),\n",
       " ('manawaduge', None, None),\n",
       " ('gihyun', None, None),\n",
       " ('emigawaty', None, None),\n",
       " ('walpola', None, None),\n",
       " ('djam', None, None),\n",
       " ('yenyu', None, None),\n",
       " ('tsungyen', None, None),\n",
       " ('optishell', None, None),\n",
       " ('noppadol', None, None),\n",
       " ('supatsara', None, None),\n",
       " ('raula', None, None),\n",
       " ('tegoeh', None, None),\n",
       " ('kheirolah', None, None),\n",
       " ('shihhsuan', None, None),\n",
       " ('himan', None, None),\n",
       " ('rmulo', None, None),\n",
       " ('azarakhsh', None, None),\n",
       " ('seyedzahir', None, None),\n",
       " ('kyungchun', None, None),\n",
       " ('lgia', None, None),\n",
       " ('shre', None, None),\n",
       " ('ngocphuong', None, None),\n",
       " ('trungnghia', None, None),\n",
       " ('brigt', None, None),\n",
       " ('kwangseob', None, None),\n",
       " ('patiphon', None, None),\n",
       " ('sehmimul', None, None),\n",
       " ('mojde', None, None),\n",
       " ('yoonsoo', None, None),\n",
       " ('surochita', None, None),\n",
       " ('myounghoon', None, None),\n",
       " ('hkon', None, None),\n",
       " ('hatm', None, None),\n",
       " ('wooyoung', None, None),\n",
       " ('joonhyang', None, None),\n",
       " ('hoifung', None, None),\n",
       " ('leello', None, None),\n",
       " ('iuthing', None, None),\n",
       " ('odalricambrym', None, None),\n",
       " ('heejong', None, None),\n",
       " ('mariefrancine', None, None),\n",
       " ('wibe', None, None),\n",
       " ('mns', None, None),\n",
       " ('paulgauthier', None, None),\n",
       " ('shoju', None, None),\n",
       " ('kyoungkook', None, None),\n",
       " ('hsinyuan', None, None),\n",
       " ('aunn', None, None),\n",
       " ('koklim', None, None),\n",
       " ('nantheera', None, None),\n",
       " ('thananop', None, None),\n",
       " ('nuntiporn', None, None),\n",
       " ('keonghun', None, None),\n",
       " ('aylton', None, None),\n",
       " ('chiwoo', None, None),\n",
       " ('yotaro', None, None),\n",
       " ('hernisa', None, None),\n",
       " ('allou', None, None),\n",
       " ('chenghanyu', None, None),\n",
       " ('sdjro', None, None),\n",
       " ('saehyung', None, None),\n",
       " ('uiwon', None, None),\n",
       " ('minhngoc', None, None),\n",
       " ('tudordan', None, None),\n",
       " ('rakpong', None, None),\n",
       " ('heungyeung', None, None),\n",
       " ('sungrok', None, None),\n",
       " ('eunbyung', None, None),\n",
       " ('hlafo', None, None),\n",
       " ('benu', None, None),\n",
       " ('juihsin', None, None),\n",
       " ('dilxat', None, None),\n",
       " ('yanglangxing', None, None),\n",
       " ('jossekin', None, None),\n",
       " ('uehwan', None, None),\n",
       " ('kisuk', 'kisuke', 90.9090909090909),\n",
       " ('byungjun', None, None),\n",
       " ('inz', None, None),\n",
       " ('hyungjoon', None, None),\n",
       " ('hyeonwoo', None, None),\n",
       " ('eenjun', None, None),\n",
       " ('keunhyoung', None, None),\n",
       " ('taehyoung', None, None),\n",
       " ('iaki', None, None),\n",
       " ('avirup', None, None),\n",
       " ('khachoang', None, None),\n",
       " ('srinjoy', None, None),\n",
       " ('euijin', None, None),\n",
       " ('chiwun', None, None),\n",
       " ('pierrealain', None, None),\n",
       " ('pramuditha', None, None),\n",
       " ('iflaah', None, None),\n",
       " ('jesuspablo', None, None),\n",
       " ('adithyavairavan', None, None),\n",
       " ('xuanphi', None, None),\n",
       " ('sheak', None, None),\n",
       " ('simonluca', None, None),\n",
       " ('jihie', None, None),\n",
       " ('geewook', None, None),\n",
       " ('yudhanjaya', None, None),\n",
       " ('aukosh', None, None),\n",
       " ('seyedshams', None, None),\n",
       " ('prodromosvasileios', None, None),\n",
       " ('keebong', None, None),\n",
       " ('lerrel', None, None),\n",
       " ('guillaumealexandre', None, None),\n",
       " ('djones', None, None),\n",
       " ('yossiri', None, None),\n",
       " ('kwangsung', None, None),\n",
       " ('byungyeon', None, None),\n",
       " ('tiep', None, None),\n",
       " ('yannmeing', None, None),\n",
       " ('srgio', None, None),\n",
       " ('truongson', None, None),\n",
       " ('thaihoc', None, None),\n",
       " ('jeancharles', None, None),\n",
       " ('khushraj', None, None),\n",
       " ('hwanntzong', None, None),\n",
       " ('leibny', None, None),\n",
       " ('sangwoong', None, None),\n",
       " ('synh', None, None),\n",
       " ('pubudu', None, None),\n",
       " ('ionutcatalin', None, None),\n",
       " ('alinionut', None, None),\n",
       " ('ashikur', None, None),\n",
       " ('nria', None, None),\n",
       " ('chunghsin', None, None),\n",
       " ('hanoona', None, None),\n",
       " ('mariusconstantin', None, None),\n",
       " ('kimkwang', None, None),\n",
       " ('soamar', None, None),\n",
       " ('ranniery', None, None),\n",
       " ('kyatsandra', None, None),\n",
       " ('augustinalexandru', None, None),\n",
       " ('myungjae', None, None),\n",
       " ('sk', None, None),\n",
       " ('daehyeok', None, None),\n",
       " ('syarifah', None, None),\n",
       " ('yurio', 'yurito', 90.9090909090909),\n",
       " ('nofar', None, None),\n",
       " ('mh', None, None),\n",
       " ('birenjith', None, None),\n",
       " ('harryanto', None, None),\n",
       " ('muchriana', None, None),\n",
       " ('mushfiqul', None, None),\n",
       " ('hohsiang', None, None),\n",
       " ('xihaier', None, None),\n",
       " ('dhagash', None, None),\n",
       " ('kibaek', None, None),\n",
       " ('jeanderson', None, None),\n",
       " ('hirley', None, None),\n",
       " ('seyedarian', None, None),\n",
       " ('elyasheev', None, None),\n",
       " ('hsuchun', None, None),\n",
       " ('goeric', None, None),\n",
       " ('hyoungsuk', None, None),\n",
       " ('hyuckjae', None, None),\n",
       " ('zgn', None, None),\n",
       " ('kowe', None, None),\n",
       " ('hengeul', None, None),\n",
       " ('jeanbastien', None, None),\n",
       " ('chidchanok', None, None),\n",
       " ('eunkyung', None, None),\n",
       " ('wonseok', None, None),\n",
       " ('soumi', None, None),\n",
       " ('pohsun', None, None),\n",
       " ('nakyil', None, None),\n",
       " ('fengjunjie', None, None),\n",
       " ('tsendsuren', None, None),\n",
       " ('aavaas', None, None),\n",
       " ('murshedul', None, None),\n",
       " ('yal', None, None),\n",
       " ('windhya', None, None),\n",
       " ('hyesoon', None, None),\n",
       " ('tatjun', None, None),\n",
       " ('khaza', None, None),\n",
       " ('simral', None, None),\n",
       " ('hyuntae', None, None),\n",
       " ('meeyoung', None, None),\n",
       " ('michailantisthenis', None, None),\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db9f00d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>New_name</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>masataro</td>\n",
       "      <td>masatarou</td>\n",
       "      <td>94.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tetsuyou</td>\n",
       "      <td>tetsuou</td>\n",
       "      <td>93.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>heishiro</td>\n",
       "      <td>heishirou</td>\n",
       "      <td>94.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>toyotaro</td>\n",
       "      <td>toyotarou</td>\n",
       "      <td>94.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>reiichiro</td>\n",
       "      <td>reiichirou</td>\n",
       "      <td>94.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79994</th>\n",
       "      <td>ryoshin</td>\n",
       "      <td>ryoushin</td>\n",
       "      <td>93.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>hauren</td>\n",
       "      <td>hakuren</td>\n",
       "      <td>92.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80576</th>\n",
       "      <td>makitaro</td>\n",
       "      <td>makitarou</td>\n",
       "      <td>94.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80619</th>\n",
       "      <td>norizo</td>\n",
       "      <td>norizou</td>\n",
       "      <td>92.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80719</th>\n",
       "      <td>tetsumsa</td>\n",
       "      <td>tetsuma</td>\n",
       "      <td>93.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name    New_name      Score\n",
       "304     masataro   masatarou  94.117647\n",
       "316     tetsuyou     tetsuou  93.333333\n",
       "417     heishiro   heishirou  94.117647\n",
       "589     toyotaro   toyotarou  94.117647\n",
       "748    reiichiro  reiichirou  94.736842\n",
       "...          ...         ...        ...\n",
       "79994    ryoshin    ryoushin  93.333333\n",
       "79995     hauren     hakuren  92.307692\n",
       "80576   makitaro   makitarou  94.117647\n",
       "80619     norizo     norizou  92.307692\n",
       "80719   tetsumsa     tetsuma  93.333333\n",
       "\n",
       "[318 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(t[1]==None for t in mr)\n",
    "df = pd.DataFrame(mr, columns=[\"Name\", \"New_name\", \"Score\"])\n",
    "df[~df[\"Score\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f348cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18                  \n",
       "39              shyh\n",
       "44            lappui\n",
       "132            magns\n",
       "135         fabrycio\n",
       "             ...    \n",
       "248745    koshichiro\n",
       "248748        capron\n",
       "248749        museok\n",
       "248751        mhanaj\n",
       "248753      mamfeter\n",
       "Name: Name, Length: 80545, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_df[match_df[\"Gender\"].isna()][\"Name\"]#gnd[~gnd['Name'].isin(match_df[~match_df.isna()][\"Name\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53c5e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualiser\n",
    "import math\n",
    "import numpy as np\n",
    "feur=match_df[match_df[\"Gender\"].isna()][\"Name\"]\n",
    "n = int(math.sqrt(len(feur)))\n",
    "matrix = np.array(feur[:n*n]).reshape(n, n)\n",
    "pd.DataFrame(matrix).to_csv(\"feur.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eaf789f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aabheer</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aadarsh</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aadesh</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadhir</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174998</th>\n",
       "      <td>zora</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174999</th>\n",
       "      <td>zoya</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175000</th>\n",
       "      <td>zoyel</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175001</th>\n",
       "      <td>zuha</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175002</th>\n",
       "      <td>zuri</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7515 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name Gender\n",
       "0        aabheer      M\n",
       "1        aadarsh      M\n",
       "2         aadesh      M\n",
       "3         aadhir      M\n",
       "4           aadi      M\n",
       "...          ...    ...\n",
       "1174998     zora      F\n",
       "1174999     zoya      F\n",
       "1175000    zoyel      F\n",
       "1175001     zuha      F\n",
       "1175002     zuri      F\n",
       "\n",
       "[7515 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignd.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eff02e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Scraping page 16...\n",
      "Scraping page 17...\n",
      "Scraping page 18...\n",
      "Scraping page 19...\n",
      "Scraping page 20...\n",
      "Scraping page 21...\n",
      "Scraping page 22...\n",
      "Scraping page 23...\n",
      "Scraping page 24...\n",
      "Scraping page 25...\n",
      "Scraping page 26...\n",
      "Scraping page 27...\n",
      "Scraping page 28...\n",
      "Scraping page 29...\n",
      "Scraping page 30...\n",
      "Scraping page 31...\n",
      "Scraping page 32...\n",
      "Scraping page 33...\n",
      "Scraping page 34...\n",
      "Scraping page 35...\n",
      "Scraping page 36...\n",
      "Scraping page 37...\n",
      "Scraping page 38...\n",
      "Scraping page 39...\n",
      "Scraping page 40...\n",
      "Scraping page 41...\n",
      "Scraping page 42...\n",
      "Scraping page 43...\n",
      "Scraping page 44...\n",
      "Scraping page 45...\n",
      "Scraping page 46...\n",
      "Scraping page 47...\n",
      "Scraping page 48...\n",
      "Scraping page 49...\n",
      "Scraping page 50...\n",
      "Scraping page 51...\n",
      "Scraping page 52...\n",
      "Scraping page 53...\n",
      "Scraping page 54...\n",
      "Scraping page 55...\n",
      "Scraping page 56...\n",
      "Scraping page 57...\n",
      "Scraping page 58...\n",
      "Scraping page 59...\n",
      "Scraping page 60...\n",
      "Scraping page 61...\n",
      "Scraping page 62...\n",
      "Scraping page 63...\n",
      "Scraping page 64...\n",
      "Scraping page 65...\n",
      "Scraping page 66...\n",
      "Scraping page 67...\n",
      "Scraping page 68...\n",
      "Scraping page 69...\n",
      "Scraping page 70...\n",
      "Scraping page 71...\n",
      "Scraping page 72...\n",
      "Scraping page 73...\n",
      "Scraping page 74...\n",
      "Scraping page 75...\n",
      "Scraping page 76...\n",
      "Scraping page 77...\n",
      "Scraping page 78...\n",
      "Scraping page 79...\n",
      "Scraping page 80...\n",
      "Scraping page 81...\n",
      "Scraping page 82...\n",
      "Scraping page 83...\n",
      "Scraping page 84...\n",
      "Scraping page 85...\n",
      "Scraping page 86...\n",
      "Scraping page 87...\n",
      "Scraping page 88...\n",
      "Scraping page 89...\n",
      "Scraping page 90...\n",
      "Scraping page 91...\n",
      "Scraping page 92...\n",
      "Scraping page 93...\n",
      "Scraping page 94...\n",
      "Scraping page 95...\n",
      "Scraping page 96...\n",
      "Scraping page 97...\n",
      "Scraping page 98...\n",
      "Scraping page 99...\n",
      "Scraping page 100...\n",
      "Scraping page 101...\n",
      "Scraping page 102...\n",
      "Scraping page 103...\n",
      "Scraping page 104...\n",
      "Scraping page 105...\n",
      "Scraping page 106...\n",
      "Scraping page 107...\n",
      "Scraping page 108...\n",
      "Scraping page 109...\n",
      "Scraping page 110...\n",
      "Scraping page 111...\n",
      "Scraping page 112...\n",
      "Scraping page 113...\n",
      "Scraping page 114...\n",
      "Scraping page 115...\n",
      "Scraping page 116...\n",
      "Scraping page 117...\n",
      "Scraping page 118...\n",
      "Scraping page 119...\n",
      "Scraping page 120...\n",
      "Scraping page 121...\n",
      "Scraping page 122...\n",
      "Scraping page 123...\n",
      "Scraping page 124...\n",
      "Scraping page 125...\n",
      "Scraping page 126...\n",
      "Scraping page 127...\n",
      "Scraping page 128...\n",
      "Scraping page 129...\n",
      "Scraping page 130...\n",
      "Scraping page 131...\n",
      "Scraping page 132...\n",
      "Scraping page 133...\n",
      "Scraping page 134...\n",
      "Scraping page 135...\n",
      "Scraping page 136...\n",
      "Scraping page 137...\n",
      "Scraping page 138...\n",
      "Scraping page 139...\n",
      "Scraping page 140...\n",
      "Scraping page 141...\n",
      "Scraping page 142...\n",
      "Scraping page 143...\n",
      "Scraping page 144...\n",
      "Scraping page 145...\n",
      "Scraping page 146...\n",
      "Scraping page 147...\n",
      "Scraping page 148...\n",
      "Scraping page 149...\n",
      "Scraping page 150...\n",
      "Scraping page 151...\n",
      "Scraping page 152...\n",
      "Scraping page 153...\n",
      "Scraping page 154...\n",
      "Scraping page 155...\n",
      "Scraping page 156...\n",
      "Scraping page 157...\n",
      "Scraping page 158...\n",
      "Scraping page 159...\n",
      "Scraping page 160...\n",
      "Scraping page 161...\n",
      "Scraping page 162...\n",
      "Scraping page 163...\n",
      "Scraping page 164...\n",
      "Scraping page 165...\n",
      "Scraping page 166...\n",
      "Scraping page 167...\n",
      "Scraping page 168...\n",
      "Scraping page 169...\n",
      "Scraping page 170...\n",
      "Scraping page 171...\n",
      "Scraping page 172...\n",
      "Scraping page 173...\n",
      "Scraping page 174...\n",
      "Scraping page 175...\n",
      "Scraping page 176...\n",
      "Scraping page 177...\n",
      "Scraping page 178...\n",
      "Scraping page 179...\n",
      "Scraping page 180...\n",
      "Scraping page 181...\n",
      "Scraping page 182...\n",
      "Scraping page 183...\n",
      "Scraping page 184...\n",
      "Scraping page 185...\n",
      "Scraping page 186...\n",
      "Scraping page 187...\n",
      "Scraping page 188...\n",
      "Scraping page 189...\n",
      "Scraping page 190...\n",
      "Scraping page 191...\n",
      "Scraping page 192...\n",
      "Scraping page 193...\n",
      "Scraping page 194...\n",
      "Scraping page 195...\n",
      "Scraping page 196...\n",
      "Scraping page 197...\n",
      "Scraping page 198...\n",
      "Scraping page 199...\n",
      "Scraping page 200...\n",
      "Scraping page 201...\n",
      "Scraping page 202...\n",
      "Scraping page 203...\n",
      "Scraping page 204...\n",
      "Scraping page 205...\n",
      "Scraping page 206...\n",
      "Scraping page 207...\n",
      "Scraping page 208...\n",
      "Scraping page 209...\n",
      "Scraping page 210...\n",
      "Scraping page 211...\n",
      "Scraping page 212...\n",
      "Scraping page 213...\n",
      "Scraping page 214...\n",
      "Scraping page 215...\n",
      "Scraping page 216...\n",
      "Scraping page 217...\n",
      "Scraping page 218...\n",
      "Scraping page 219...\n",
      "Scraping page 220...\n",
      "Scraping page 221...\n",
      "Scraping page 222...\n",
      "Scraping page 223...\n",
      "Scraping page 224...\n",
      "Scraping page 225...\n",
      "Scraping page 226...\n",
      "Scraping page 227...\n",
      "Scraping page 228...\n",
      "Scraping page 229...\n",
      "Scraping page 230...\n",
      "Scraping page 231...\n",
      "Scraping page 232...\n",
      "Scraping page 233...\n",
      "Scraping page 234...\n",
      "Scraping page 235...\n",
      "Scraping page 236...\n",
      "Scraping page 237...\n",
      "Scraping page 238...\n",
      "Scraping page 239...\n",
      "Scraping page 240...\n",
      "Scraping page 241...\n",
      "Scraping page 242...\n",
      "Scraping page 243...\n",
      "Scraping page 244...\n",
      "Scraping page 245...\n",
      "Scraping page 246...\n",
      "Scraping page 247...\n",
      "Scraping page 248...\n",
      "Scraping page 249...\n",
      "Scraping page 250...\n",
      "Scraping page 251...\n",
      "Scraping page 252...\n",
      "Scraping page 253...\n",
      "Scraping page 254...\n",
      "Scraping page 255...\n",
      "Scraping page 256...\n",
      "Scraping page 257...\n",
      "Scraping page 258...\n",
      "Scraping page 259...\n",
      "Scraping page 260...\n",
      "Scraping page 261...\n",
      "Scraping page 262...\n",
      "Scraping page 263...\n",
      "Scraping page 264...\n",
      "Scraping page 265...\n",
      "Scraping page 266...\n",
      "Scraping page 267...\n",
      "Scraping page 268...\n",
      "Scraping page 269...\n",
      "Scraping page 270...\n",
      "Scraping page 271...\n",
      "Scraping page 272...\n",
      "Scraping page 273...\n",
      "Scraping page 274...\n",
      "Scraping page 275...\n",
      "Scraping page 276...\n",
      "Scraping page 277...\n",
      "Scraping page 278...\n",
      "Scraping page 279...\n",
      "Boys DF:\n",
      "        rank      name\n",
      "0  1(32,158)  서준Seojun\n",
      "1  2(31,872)  민준Minjun\n",
      "2  3(27,922)   도윤Doyun\n",
      "3  4(25,300)   예준Yejun\n",
      "4  5(25,172)   하준Hajun\n",
      "\n",
      "Girls DF:\n",
      "        rank        name\n",
      "0  1(31,956)    서윤Seoyun\n",
      "1  2(30,752)   서연Seoyeon\n",
      "2  3(27,732)       지우Jiu\n",
      "3  4(26,771)     하윤Hayun\n",
      "4  5(25,127)  서현Seohyeon\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Friendly scraper\"}\n",
    "\n",
    "def scrape_page(page_number):\n",
    "    url = f\"https://korean-name.com/en/ranking/{page_number}\"\n",
    "    r = requests.get(url, headers=HEADERS, timeout=10)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    # Scrape boy table\n",
    "    boy_table = soup.select_one(\n",
    "        \"div.real-wrapper > div.wrapper > div.section > div.baby--normal-flex-container > div.half-table > table#tbl-rank-boy\"\n",
    "    )\n",
    "    boy_data = []\n",
    "    if boy_table:\n",
    "        for row in boy_table.select(\"tr\"):\n",
    "            cols = row.select(\"td\")\n",
    "            if len(cols) >= 2:\n",
    "                rank = cols[0].get_text(strip=True)\n",
    "                name = cols[1].get_text(strip=True)\n",
    "                boy_data.append({\"rank\": rank, \"name\": name})\n",
    "\n",
    "    # Scrape girl table\n",
    "    girl_table = soup.select_one(\n",
    "        \"div.real-wrapper > div.wrapper > div.section > div.baby--normal-flex-container > div.half-table > table#tbl-rank-girl\"\n",
    "    )\n",
    "    girl_data = []\n",
    "    if girl_table:\n",
    "        for row in girl_table.select(\"tr\"):\n",
    "            cols = row.select(\"td\")\n",
    "            if len(cols) >= 2:\n",
    "                rank = cols[0].get_text(strip=True)\n",
    "                name = cols[1].get_text(strip=True)\n",
    "                girl_data.append({\"rank\": rank, \"name\": name})\n",
    "\n",
    "    return boy_data, girl_data\n",
    "\n",
    "# Example: scrape pages 1 to 5 with cooldown\n",
    "all_boy_data = []\n",
    "all_girl_data = []\n",
    "\n",
    "for page_num in range(1, 280):  # adjust page range as needed\n",
    "    print(f\"Scraping page {page_num}...\")\n",
    "    boy_data, girl_data = scrape_page(page_num)\n",
    "    all_boy_data.extend(boy_data)\n",
    "    all_girl_data.extend(girl_data)\n",
    "    \n",
    "    time.sleep(random.uniform(1, 3))  # cooldown\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_boys = pd.DataFrame(all_boy_data)\n",
    "df_girls = pd.DataFrame(all_girl_data)\n",
    "\n",
    "print(\"Boys DF:\")\n",
    "print(df_boys.head())\n",
    "print(\"\\nGirls DF:\")\n",
    "print(df_girls.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ca24ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-a.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-b.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-c.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-d.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-e.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-f.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-g.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-h.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-i.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-j.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-k.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-l.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-m.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-n.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-o.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-p.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-q.htm ...\n",
      "❌ Failed to fetch https://indianhindunames.com/indian-hindu-girl-name-q.htm: 404 Client Error: Not Found for url: https://indianhindunames.com/indian-hindu-girl-name-q.htm\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-r.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-s.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-t.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-u.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-v.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-w.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-x.htm ...\n",
      "❌ Failed to fetch https://indianhindunames.com/indian-hindu-girl-name-x.htm: 404 Client Error: Not Found for url: https://indianhindunames.com/indian-hindu-girl-name-x.htm\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-y.htm ...\n",
      "Scraping https://indianhindunames.com/indian-hindu-girl-name-z.htm ...\n",
      "\n",
      "✅ Scraping complete! Total names collected: 437273\n",
      "         name letter\n",
      "0       Aabha      a\n",
      "1   Aabharana      a\n",
      "2  Aadarshini      a\n",
      "3      Aadhya      a\n",
      "4      Aadita      a\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import string  # for letters a–z\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Friendly scraper\"}\n",
    "\n",
    "base_url = \"https://indianhindunames.com/indian-hindu-girl-name-{}.htm\"\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for letter in string.ascii_lowercase:  # 'a' to 'z'\n",
    "    url = base_url.format(letter)\n",
    "    print(f\"Scraping {url} ...\")\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        r.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to fetch {url}: {e}\")\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    name_lists = soup.select(\"ul.list-group.namelist\")\n",
    "\n",
    "    for ul in name_lists:\n",
    "        items = ul.select(\"li\")\n",
    "        for li in items:\n",
    "            raw_text = li.get_text(\" \", strip=True)\n",
    "\n",
    "            # Extract names before \"=\"\n",
    "            names = re.findall(r\"([^\\s=]+)\\s*=\", raw_text)\n",
    "            for n in names:\n",
    "                n_clean = n.strip()\n",
    "                if n_clean:\n",
    "                    all_data.append({\"name\": n_clean, \"letter\": letter})\n",
    "\n",
    "    # polite random cooldown (1–3 seconds)\n",
    "    time.sleep(random.uniform(1, 3))\n",
    "\n",
    "# Convert all scraped data into one DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "print(f\"\\n✅ Scraping complete! Total names collected: {len(df)}\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe815198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female names:          name\n",
      "0      Eun-ju\n",
      "1    Bo-yeong\n",
      "2  Chae-yeong\n",
      "3     Chun-ja\n",
      "4       Eun-a\n",
      "Male names:          name\n",
      "0      Eun-ju\n",
      "1    Bo-yeong\n",
      "2  Chae-yeong\n",
      "3     Chun-ja\n",
      "4       Eun-a\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.wikidata.org/wiki/Wikidata:WikiProject_Names/lists/Korean_names'\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.raise_for_status()\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "content = soup.find('div', class_='mw-parser-output')\n",
    "\n",
    "def extract_names(gender_keyword):\n",
    "    \"\"\"Extract names table following a header containing gender_keyword\"\"\"\n",
    "    for h2 in content.find_all('h2'):\n",
    "        if gender_keyword in h2.get_text(strip=True).lower():\n",
    "            table = h2.find_next('table', class_='wikitable sortable')\n",
    "            if table:\n",
    "                names = [row.find_all('td')[0].get_text(strip=True) \n",
    "                         for row in table.find_all('tr')[1:]  # skip header\n",
    "                         if row.find_all('td')]\n",
    "                return pd.DataFrame({'name': names})\n",
    "    return pd.DataFrame({'name': []})\n",
    "\n",
    "df_female = extract_names('female given name')\n",
    "df_male = extract_names('male given name')\n",
    "\n",
    "print(\"Female names:\", df_female.head())\n",
    "print(\"Male names:\", df_male.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29762d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_female[\"Gender\"]=\"F\"\n",
    "df_male[\"Gender\"]=\"M\"\n",
    "df=pd.concat([df_female,df_male],axis=0,ignore_index=True)\n",
    "df[\"Name\"]=df[\"name\"].str.lower()\n",
    "df=df[[\"Name\",\"Gender\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "171d8c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eunju</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boyeong</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chaeyeong</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chunja</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>euna</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>yangsun</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>daseul</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>seungsin</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>sunsil</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>nansun</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name Gender\n",
       "0        eunju      F\n",
       "1      boyeong      F\n",
       "2    chaeyeong      F\n",
       "3       chunja      F\n",
       "4         euna      F\n",
       "..         ...    ...\n",
       "923    yangsun      M\n",
       "924     daseul      M\n",
       "925   seungsin      M\n",
       "926     sunsil      M\n",
       "927     nansun      M\n",
       "\n",
       "[928 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Name'] = df['Name'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4770e10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seojun</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>minjun</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doyun</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yejun</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hajun</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51629</th>\n",
       "      <td>yangsun</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51630</th>\n",
       "      <td>daseul</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51631</th>\n",
       "      <td>seungsin</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51632</th>\n",
       "      <td>sunsil</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51633</th>\n",
       "      <td>nansun</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51634 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name Gender\n",
       "0        seojun      M\n",
       "1        minjun      M\n",
       "2         doyun      M\n",
       "3         yejun      M\n",
       "4         hajun      M\n",
       "...         ...    ...\n",
       "51629   yangsun      M\n",
       "51630    daseul      M\n",
       "51631  seungsin      M\n",
       "51632    sunsil      M\n",
       "51633    nansun      M\n",
       "\n",
       "[51634 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop_duplicates()\n",
    "kgnd=kgnd.drop_duplicates()\n",
    "kgnd=pd.concat([kgnd,df],axis=0,ignore_index=True)\n",
    "kgnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import string\n",
    "import pandas as pd\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "BASE_URL = \"https://japanese-names.info/first-names/gender/{gender}-name/start-with-{letter}\"\n",
    "GIRL = \"girl\"\n",
    "BOY = \"boy\"\n",
    "\n",
    "async def scrape_page(page, url):\n",
    "    \"\"\"Scrape one page and return list of names\"\"\"\n",
    "    await page.goto(url, timeout=0)\n",
    "    # Wait for names to load\n",
    "    try:\n",
    "        await page.wait_for_selector(\"ul.name-list li h3\", timeout=5000)\n",
    "    except:\n",
    "        return []  # no names on this page\n",
    "\n",
    "    # Scroll to ensure dynamic content loads\n",
    "    previous_height = await page.evaluate(\"document.body.scrollHeight\")\n",
    "    while True:\n",
    "        await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        await page.wait_for_timeout(1000)\n",
    "        current_height = await page.evaluate(\"document.body.scrollHeight\")\n",
    "        if current_height == previous_height:\n",
    "            break\n",
    "        previous_height = current_height\n",
    "\n",
    "    # Extract names\n",
    "    name_elements = await page.query_selector_all(\"ul.name-list li h3\")\n",
    "    names = [await el.evaluate(\"(node) => node.textContent.trim()\") for el in name_elements if await el.evaluate(\"(node) => node.textContent.trim()\")]\n",
    "    return names\n",
    "\n",
    "async def scrape_gender(gender):\n",
    "    all_data = []\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        context = await browser.new_context(\n",
    "            user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                       \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                       \"Chrome/118.0.5993.118 Safari/537.36\"\n",
    "        )\n",
    "        page = await context.new_page()\n",
    "\n",
    "        for letter in string.ascii_lowercase:\n",
    "            page_num = 1\n",
    "            while True:\n",
    "                if gender == GIRL:\n",
    "                    url = f\"{BASE_URL.format(gender=gender, letter=letter)}/page/{page_num}/\"\n",
    "                else:  # boys have no page number on single-page\n",
    "                    url = f\"{BASE_URL.format(gender=gender, letter=letter)}\" if page_num == 1 else f\"{BASE_URL.format(gender=gender, letter=letter)}/page/{page_num}/\"\n",
    "\n",
    "                names = await scrape_page(page, url)\n",
    "                if not names:\n",
    "                    break  # stop if page has no names\n",
    "\n",
    "                # Append data\n",
    "                for name in names:\n",
    "                    all_data.append({\"letter\": letter, \"page\": page_num, \"name\": name})\n",
    "\n",
    "                page_num += 1\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "async def main():\n",
    "    print(\"Scraping girl names...\")\n",
    "    #girls_df = await scrape_gender(GIRL)\n",
    "    #print(f\"Found {len(girls_df)} girl names ✅\")\n",
    "\n",
    "    print(\"Scraping boy names...\")\n",
    "    boys_df = await scrape_gender(BOY)\n",
    "    print(f\"Found {len(boys_df)} boy names ✅\")\n",
    "\n",
    "    # Save to CSV if needed\n",
    "    #girls_df.to_csv(\"japanese_girl_names.csv\", index=False)\n",
    "    #boys_df.to_csv(\"japanese_boy_names.csv\", index=False)\n",
    "\n",
    "    return boys_df#, boys_df\n",
    "\n",
    "# In Jupyter, use:\n",
    "boys_df = await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e397ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#names.to_parquet(\"conf_names.parquet\", index=False)\n",
    "s3_path = \"s3://lab/fuzzed2.csv\"  # bucket + key\n",
    "\n",
    "# Save directly to MinIO\n",
    "df.to_csv(s3_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dbdc5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[\"Gender\"] = (\n",
    "    gdf[\"Gender\"]\n",
    "    .astype(str)         # convert to string\n",
    "    .str.strip()         # remove spaces\n",
    "    .str.lower()         # normalize case\n",
    "    .map({'m': 0, 'f': 1, 'male': 0, 'female': 1})\n",
    ")\n",
    "gdf[\"Name\"]=gdf[\"Name\"].str.lower()\n",
    "gdf=gdf[~gdf[\"Gender\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fecff4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def normalize_name(name):\n",
    "    if not isinstance(name, str):\n",
    "        return \"\"\n",
    "    # Lowercase\n",
    "    name = name.lower().strip()\n",
    "    # Remove accents (é → e, ü → u)\n",
    "    name = ''.join(\n",
    "        c for c in unicodedata.normalize('NFKD', name)\n",
    "        if not unicodedata.combining(c)\n",
    "    )\n",
    "    # Remove punctuation, numbers, multiple spaces\n",
    "    name = re.sub(r'[^a-z\\s]', '', name)\n",
    "    name = re.sub(r\"^(?:[a-z]\\s+)+\", \"\", name)  # start\n",
    "    name = re.sub(r\"(?:\\s+[a-z])+$\", \"\", name)  # end\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name\n",
    "\n",
    "names[\"name\"] = names[\"name\"].apply(normalize_name)\n",
    "gdf[\"Name\"] = gdf[\"Name\"].apply(normalize_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe44038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Name  Gender\n",
      "0           james     0.0\n",
      "1            john     0.0\n",
      "2          robert     0.0\n",
      "3         michael     0.0\n",
      "4         william     0.0\n",
      "...           ...     ...\n",
      "22140406     kaki     1.0\n",
      "22147959  antonei     1.0\n",
      "22177245   millet     1.0\n",
      "22186057    hayou     1.0\n",
      "22188929   akishi     1.0\n",
      "\n",
      "[2737230 rows x 2 columns]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m matches = []\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m match_df[match_df[\u001b[33m\"\u001b[39m\u001b[33mGender\u001b[39m\u001b[33m\"\u001b[39m].isna()][\u001b[33m\"\u001b[39m\u001b[33mName\u001b[39m\u001b[33m\"\u001b[39m] :\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     match, score, _ = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextractOne\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcand\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mName\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfuzz\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWRatio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     matches.append({\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: n, \u001b[33m\"\u001b[39m\u001b[33mmatched_name\u001b[39m\u001b[33m\"\u001b[39m: match, \u001b[33m\"\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m\"\u001b[39m: score})\n\u001b[32m     13\u001b[39m matches_df = pd.DataFrame(matches)\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/rapidfuzz/process_cpp_impl.pyx:844\u001b[39m, in \u001b[36mrapidfuzz.process_cpp_impl.extractOne\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/rapidfuzz/process_cpp_impl.pyx:484\u001b[39m, in \u001b[36mrapidfuzz.process_cpp_impl.extractOne_dict\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/rapidfuzz/process_cpp_impl.pyx:295\u001b[39m, in \u001b[36mrapidfuzz.process_cpp_impl.extractOne_dict_f64\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%pip install rapidfuzz\n",
    "from rapidfuzz import process, fuzz\n",
    "# Get first 2 letters of all names\n",
    "name_prefixes = names['Name'].str[:2].str.lower().unique()\n",
    "\n",
    "# Filter gdf rows that match any of these prefixes\n",
    "cand = gdf[gdf['Name'].str[:2].str.lower().isin(name_prefixes)]\n",
    "print(cand)\n",
    "matches = []\n",
    "for n in match_df[match_df[\"Gender\"].isna()][\"Name\"] :\n",
    "    match, score, _ = process.extractOne(n, cand[\"Name\"], scorer=fuzz.WRatio)\n",
    "    matches.append({\"name\": n, \"matched_name\": match, \"score\": score})\n",
    "matches_df = pd.DataFrame(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124774e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m matches = []\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m match_df[match_df[\u001b[33m\"\u001b[39m\u001b[33mGender\u001b[39m\u001b[33m\"\u001b[39m].isna()][\u001b[33m\"\u001b[39m\u001b[33mName\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# extractOne stops at first match with high enough score\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     res = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextractOne\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcand\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mName\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfuzz\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWRatio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_cutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m95\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# stop if score >= 95\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     21\u001b[39m         matches.append({\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: name, \u001b[33m\"\u001b[39m\u001b[33mmatch\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m})\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/rapidfuzz/process_cpp_impl.pyx:847\u001b[39m, in \u001b[36mrapidfuzz.process_cpp_impl.extractOne\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/rapidfuzz/process_cpp_impl.pyx:717\u001b[39m, in \u001b[36mrapidfuzz.process_cpp_impl.extractOne_list\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/rapidfuzz/process_cpp_impl.pyx:534\u001b[39m, in \u001b[36mrapidfuzz.process_cpp_impl.extractOne_list_f64\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%pip install rapidfuzz\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "\n",
    "name_prefixes = names['Name'].str[:2].str.lower().unique()\n",
    "\n",
    "# Filter gdf rows that match any of these prefixes\n",
    "cand = gdf[gdf['Name'].str[:2].str.lower().isin(name_prefixes)]\n",
    "\n",
    "matches = []\n",
    "\n",
    "for name in match_df[match_df[\"Gender\"].isna()][\"Name\"]:\n",
    "    # extractOne stops at first match with high enough score\n",
    "    res = process.extractOne(\n",
    "        query=name,\n",
    "        choices=cand[\"Name\"].tolist(),\n",
    "        scorer=fuzz.WRatio,\n",
    "        score_cutoff=95  # stop if score >= 95\n",
    "    )\n",
    "    \n",
    "    if res is None:\n",
    "        matches.append({\"name\": name, \"match\": None, \"score\": None})\n",
    "    else:\n",
    "        match, score, _ = res\n",
    "        matches.append({\"name\": name, \"match\": match, \"score\": score})\n",
    "\n",
    "import pandas as pd\n",
    "matches_df = pd.DataFrame(matches)\n",
    "print(matches_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8331274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.14.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
      "Downloading rapidfuzz-3.14.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz\n",
      "Successfully installed rapidfuzz-3.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rapidfuzz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rapidfuzz import fuzz, process\n",
    "import re, unicodedata\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Pre-cleaning function\n",
    "# ---------------------------\n",
    "def clean_name(name):\n",
    "    if not isinstance(name, str):\n",
    "        return \"\"\n",
    "    name = name.lower().strip()\n",
    "    # Remove accents\n",
    "    name = ''.join(c for c in unicodedata.normalize('NFKD', name) if not unicodedata.combining(c))\n",
    "    # Keep only letters and spaces\n",
    "    name = re.sub(r\"[^a-z\\s-]\", \"\", name)\n",
    "    # Normalize spaces\n",
    "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
    "    return name\n",
    "\n",
    "# Example: your datasets\n",
    "names['clean'] = names['Name'].apply(clean_name)\n",
    "gdf['clean'] = gdf['Name'].apply(clean_name)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Blocking by first N letters\n",
    "# ---------------------------\n",
    "BLOCK_N = 2\n",
    "names['prefix'] = names['clean'].str[:BLOCK_N]\n",
    "gdf['prefix'] = gdf['clean'].str[:BLOCK_N]\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Chunked vectorized matching\n",
    "# ---------------------------\n",
    "results = []\n",
    "\n",
    "for prefix, name_group in names.groupby('prefix'):\n",
    "    # Candidates with same prefix\n",
    "    candidates = gdf[gdf['prefix'] == prefix]['clean'].tolist()\n",
    "    if not candidates:\n",
    "        continue\n",
    "    \n",
    "    # Chunk names if group is too large\n",
    "    CHUNK_SIZE = 50000\n",
    "    for i in range(0, len(name_group), CHUNK_SIZE):\n",
    "        chunk = name_group.iloc[i:i+CHUNK_SIZE]\n",
    "        queries = chunk['clean'].tolist()\n",
    "        \n",
    "        # Compute similarity matrix (vectorized)\n",
    "        # Returns best match and score for each query\n",
    "        scores = process.cdist(queries, candidates, scorer=fuzz.WRatio, score_cutoff=92, processor=None, workers=-1)\n",
    "        \n",
    "        for q_idx, row in enumerate(scores):\n",
    "            if np.all(np.isnan(row)):  # no match above cutoff\n",
    "                results.append({\"name\": queries[q_idx], \"match\": None, \"score\": None})\n",
    "            else:\n",
    "                # index of best match\n",
    "                best_idx = np.nanargmax(row)\n",
    "                results.append({\n",
    "                        \"name\": queries[q_idx],\n",
    "                        \"match\": candidates[best_idx],\n",
    "                        \"score\": row[best_idx]\n",
    "                })\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Create DataFrame of results\n",
    "# ---------------------------\n",
    "matches_df = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9de893f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>match</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246948</th>\n",
       "      <td>zygfryd</td>\n",
       "      <td>zygfryd</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246949</th>\n",
       "      <td>zydrune</td>\n",
       "      <td>zyaire</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246950</th>\n",
       "      <td>zz</td>\n",
       "      <td>zzyzx</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246951</th>\n",
       "      <td>zzilia</td>\n",
       "      <td>zzyzx</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246952</th>\n",
       "      <td>zzyv</td>\n",
       "      <td>zzyzx</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246953 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name    match  score\n",
       "0                           0.0\n",
       "1                           0.0\n",
       "2                           0.0\n",
       "3             a        a  100.0\n",
       "4             a        a  100.0\n",
       "...         ...      ...    ...\n",
       "246948  zygfryd  zygfryd  100.0\n",
       "246949  zydrune   zyaire    0.0\n",
       "246950       zz    zzyzx    0.0\n",
       "246951   zzilia    zzyzx    0.0\n",
       "246952     zzyv    zzyzx    0.0\n",
       "\n",
       "[246953 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feur=matches_df[matches_df[\"score\"]!=0]#[~matches_df[\"score\"].isin([0, 100])]\n",
    "matches_df#.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fc5241c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6688/200273274.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gdf[\"clean\"] = gdf[\"clean\"].map(name_map)#.fillna(gdf[\"clean\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>clean</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>james</td>\n",
       "      <td>0.0</td>\n",
       "      <td>james</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>john</td>\n",
       "      <td>0.0</td>\n",
       "      <td>john</td>\n",
       "      <td>jo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>robert</td>\n",
       "      <td>0.0</td>\n",
       "      <td>robert</td>\n",
       "      <td>ro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>michael</td>\n",
       "      <td>0.0</td>\n",
       "      <td>michael</td>\n",
       "      <td>mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>william</td>\n",
       "      <td>0.0</td>\n",
       "      <td>william</td>\n",
       "      <td>wi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22140406</th>\n",
       "      <td>kaki</td>\n",
       "      <td>1.0</td>\n",
       "      <td>kaki</td>\n",
       "      <td>ka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22147959</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22177245</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22186057</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22188929</th>\n",
       "      <td>akishi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>akishi</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2739971 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  Gender    clean prefix\n",
       "0           james     0.0    james     ja\n",
       "1            john     0.0     john     jo\n",
       "2          robert     0.0   robert     ro\n",
       "3         michael     0.0  michael     mi\n",
       "4         william     0.0  william     wi\n",
       "...           ...     ...      ...    ...\n",
       "22140406     kaki     1.0     kaki     ka\n",
       "22147959      NaN     1.0      NaN     an\n",
       "22177245      NaN     1.0      NaN     mi\n",
       "22186057      NaN     1.0      NaN     ha\n",
       "22188929   akishi     1.0   akishi     ak\n",
       "\n",
       "[2739971 rows x 4 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_map = dict(zip(feur[\"name\"], feur[\"match\"]))\n",
    "\n",
    "# Replace in gdf\n",
    "gdf[\"clean\"] = gdf[\"clean\"].map(name_map)#.fillna(gdf[\"clean\"])\n",
    "\"\"\"\n",
    "match_df = names[[\"clean\"]].merge(gdf[[\"clean\",\"Gender\"]], how=\"left\", on=\"clean\")\n",
    "match_df[~match_df[\"Gender\"].isna()]\"\"\"\n",
    "gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "390ed4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "68c6e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "g2['Name'] = g2['Name'].str.lower()\n",
    "g2['Gender'] = g2['Gender'].map({'M': 0, 'F': 1})\n",
    "#g2 = g2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9da51d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = g2['Name']\n",
    "y = g2['Gender']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.fillna(\"\")\n",
    "X_test = X_test.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "870d3f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(2, 3))),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">steps&nbsp;</td>\n",
       "            <td class=\"value\">[(&#x27;vectorizer&#x27;, ...), (&#x27;classifier&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">transform_input&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">memory&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"vectorizer__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">input&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;content&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('encoding',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">encoding&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;utf-8&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decode_error',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decode_error&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;strict&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('strip_accents',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">strip_accents&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('lowercase',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">lowercase&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('preprocessor',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">preprocessor&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tokenizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tokenizer&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('analyzer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">analyzer&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;char&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('stop_words',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">stop_words&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('token_pattern',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">token_pattern&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;(?u)\\\\b\\\\w\\\\w+\\\\b&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ngram_range',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ngram_range&nbsp;</td>\n",
       "            <td class=\"value\">(2, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_df&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_df&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('vocabulary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">vocabulary&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('binary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">binary&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dtype',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dtype&nbsp;</td>\n",
       "            <td class=\"value\">&lt;class &#x27;numpy.float64&#x27;&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('norm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">norm&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('use_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">use_idf&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('smooth_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">smooth_idf&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sublinear_tf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sublinear_tf&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"classifier__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">alpha&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('force_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">force_alpha&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_prior',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_prior&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_prior',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_prior&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='char', ngram_range=(2, 3))),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(analyzer='char', ngram_range=(2, 3))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "44645f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(pipeline.score(X_test,y_test))\n",
    "name = [\"danjian\"]\n",
    "pipeline.predict(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5705c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6894255984098284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ba4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pipeline, \"gender_predictor_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5bbba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "d=g2.copy()\n",
    "d[\"Name\"] = d[\"Name\"].str.replace(r'[^\\w\\s\\u4E00-\\u9FFF\\u3400-\\u4DBF\\u3040-\\u30FF\\uAC00-\\uD7AF]', '', regex=True)\n",
    "kanji_pattern = re.compile(r'[\\u4E00-\\u9FFF\\u3400-\\u4DBF\\u3040-\\u30FF\\uAC00-\\uD7AF]')\n",
    "\n",
    "mask = d[\"Name\"].notna() & d[\"Name\"].apply(lambda x: isinstance(x, str))\n",
    "_kanji = d.loc[mask, \"Name\"].apply(lambda x: bool(kanji_pattern.search(x)))\n",
    "\n",
    "df_latin = d.loc[_kanji.index[~_kanji]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b6e2090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baby</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aisyah</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anela</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anela</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fiyinfoluwa</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21173433</th>\n",
       "      <td>abd alhamid</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21173434</th>\n",
       "      <td>abdullah</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21173435</th>\n",
       "      <td>abdullah</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21173436</th>\n",
       "      <td>abdullah</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21173437</th>\n",
       "      <td>abdullah</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21173410 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name Gender\n",
       "0                baby      F\n",
       "1              aisyah      F\n",
       "2               anela      F\n",
       "3               anela      F\n",
       "4         fiyinfoluwa      F\n",
       "...               ...    ...\n",
       "21173433  abd alhamid      M\n",
       "21173434     abdullah      M\n",
       "21173435     abdullah      M\n",
       "21173436     abdullah      M\n",
       "21173437     abdullah      M\n",
       "\n",
       "[21173410 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_latin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
