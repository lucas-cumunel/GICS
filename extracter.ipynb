{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af2bfca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading lxml-6.0.2-cp313-cp313-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
      "Downloading lxml-6.0.2-cp313-cp313-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "Successfully installed lxml-6.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Download the DTD locally\\nwith fs.open(dtd_path, \"rb\") as f_dtd:\\n    with open(\"dblp.dtd\", \"wb\") as f_local:\\n        f_local.write(f_dtd.read())'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install lxml\n",
    "#%pip install rdflib\n",
    "import os\n",
    "import s3fs\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = 'GMHBU5SUKVUN1A81Y8UY'\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = 'o+beqI9AemFNrUL4c0OSTxDbOhg4llbcwl0ScqEm'\n",
    "os.environ[\"AWS_SESSION_TOKEN\"] = 'eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NLZXkiOiJHTUhCVTVTVUtWVU4xQTgxWThVWSIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sImF1ZCI6WyJtaW5pby1kYXRhbm9kZSIsIm9ueXhpYSIsImFjY291bnQiXSwiYXV0aF90aW1lIjoxNzY5NjEyMTg2LCJhenAiOiJvbnl4aWEiLCJlbWFpbCI6Imx1Y2FzLmN1bXVuZWxAZW5zYWUuZnIiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZXhwIjoxNzcwNzk4MzU4LCJmYW1pbHlfbmFtZSI6IkN1bXVuZWwiLCJnaXZlbl9uYW1lIjoiTHVjYXMiLCJncm91cHMiOlsiVVNFUl9PTllYSUEiLCJzdGF0YXBwLXNlZ21lZGljIl0sImlhdCI6MTc3MDE5MzU1NywiaXNzIjoiaHR0cHM6Ly9hdXRoLmxhYi5zc3BjbG91ZC5mci9hdXRoL3JlYWxtcy9zc3BjbG91ZCIsImp0aSI6Im9ucnRydDplNzAyY2NmOS05N2FjLTNkMDgtNDk0YS1iZWQ1M2EzMzYyMzQiLCJuYW1lIjoiTHVjYXMgQ3VtdW5lbCIsInBvbGljeSI6InN0c29ubHkiLCJwcmVmZXJyZWRfdXNlcm5hbWUiOiJsYWIiLCJyZWFsbV9hY2Nlc3MiOnsicm9sZXMiOlsib2ZmbGluZV9hY2Nlc3MiLCJ1bWFfYXV0aG9yaXphdGlvbiIsImRlZmF1bHQtcm9sZXMtc3NwY2xvdWQiXX0sInJlc291cmNlX2FjY2VzcyI6eyJhY2NvdW50Ijp7InJvbGVzIjpbIm1hbmFnZS1hY2NvdW50IiwibWFuYWdlLWFjY291bnQtbGlua3MiLCJ2aWV3LXByb2ZpbGUiXX19LCJyb2xlcyI6WyJvZmZsaW5lX2FjY2VzcyIsInVtYV9hdXRob3JpemF0aW9uIiwiZGVmYXVsdC1yb2xlcy1zc3BjbG91ZCJdLCJzY29wZSI6Im9wZW5pZCBwcm9maWxlIGdyb3VwcyBlbWFpbCIsInNpZCI6Ijc4ODAyYmFkLTFjZTEtODFkOC1mYjI4LTQwNWY4MWQ0ZGVmNSIsInN1YiI6ImUyZDc4NjRjLTcwMzItNDI0ZC04OTA2LWU0ZjhiNDFjYzAwMyIsInR5cCI6IkJlYXJlciJ9.UhD0r4MQ2qUkefOj6PjF-awWui47amNDnE3PLOZnuc30X6GTsfDb4N9Aqm2acDms4ez0btnYSOi6_to_-wQlsw'\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = 'us-east-1'\n",
    "fs = s3fs.S3FileSystem(\n",
    "    client_kwargs={'endpoint_url': 'https://'+'minio.lab.sspcloud.fr'},\n",
    "    key = os.environ[\"AWS_ACCESS_KEY_ID\"], \n",
    "    secret = os.environ[\"AWS_SECRET_ACCESS_KEY\"], \n",
    "    token = os.environ[\"AWS_SESSION_TOKEN\"])\n",
    "\n",
    "path = \"lab/dblp (1).xml.gz\"\n",
    "dtd_path = \"lab/dblp.dtd\"\n",
    "rdf_path=\"lab/dblp.nt.gz\"\n",
    "\"\"\"\n",
    "# Download the DTD locally\n",
    "with fs.open(dtd_path, \"rb\") as f_dtd:\n",
    "    with open(\"dblp.dtd\", \"wb\") as f_local:\n",
    "        f_local.write(f_dtd.read())\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2651ca40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1,000,000 lines\n",
      "Processed 2,000,000 lines\n",
      "Processed 3,000,000 lines\n",
      "Processed 4,000,000 lines\n",
      "Processed 5,000,000 lines\n",
      "Processed 6,000,000 lines\n",
      "Processed 7,000,000 lines\n",
      "Processed 8,000,000 lines\n",
      "Processed 9,000,000 lines\n",
      "Processed 10,000,000 lines\n",
      "Processed 11,000,000 lines\n",
      "Processed 12,000,000 lines\n",
      "Processed 13,000,000 lines\n",
      "Processed 14,000,000 lines\n",
      "Processed 15,000,000 lines\n",
      "Processed 16,000,000 lines\n",
      "Processed 17,000,000 lines\n",
      "Processed 18,000,000 lines\n",
      "Processed 19,000,000 lines\n",
      "Processed 20,000,000 lines\n",
      "Processed 21,000,000 lines\n",
      "Processed 22,000,000 lines\n",
      "Processed 23,000,000 lines\n",
      "Processed 24,000,000 lines\n",
      "Processed 25,000,000 lines\n",
      "Processed 26,000,000 lines\n",
      "Processed 27,000,000 lines\n",
      "Processed 28,000,000 lines\n",
      "Processed 29,000,000 lines\n",
      "Processed 30,000,000 lines\n",
      "Processed 31,000,000 lines\n",
      "Processed 32,000,000 lines\n",
      "Processed 33,000,000 lines\n",
      "Processed 34,000,000 lines\n",
      "Processed 35,000,000 lines\n",
      "Processed 36,000,000 lines\n",
      "Processed 37,000,000 lines\n",
      "Processed 38,000,000 lines\n",
      "Processed 39,000,000 lines\n",
      "Processed 40,000,000 lines\n",
      "Processed 41,000,000 lines\n",
      "Processed 42,000,000 lines\n",
      "Processed 43,000,000 lines\n",
      "Processed 44,000,000 lines\n",
      "Processed 45,000,000 lines\n",
      "Processed 46,000,000 lines\n",
      "Processed 47,000,000 lines\n",
      "Processed 48,000,000 lines\n",
      "Processed 49,000,000 lines\n",
      "Processed 50,000,000 lines\n",
      "Processed 51,000,000 lines\n",
      "Processed 53,000,000 lines\n",
      "Processed 54,000,000 lines\n",
      "Processed 55,000,000 lines\n",
      "Processed 56,000,000 lines\n",
      "Processed 57,000,000 lines\n",
      "Processed 58,000,000 lines\n",
      "Processed 59,000,000 lines\n",
      "Processed 60,000,000 lines\n",
      "Processed 61,000,000 lines\n",
      "Processed 62,000,000 lines\n",
      "Processed 63,000,000 lines\n",
      "Processed 64,000,000 lines\n",
      "Processed 65,000,000 lines\n",
      "Processed 66,000,000 lines\n",
      "Processed 67,000,000 lines\n",
      "Processed 68,000,000 lines\n",
      "Processed 69,000,000 lines\n",
      "Processed 70,000,000 lines\n",
      "Processed 71,000,000 lines\n",
      "Processed 72,000,000 lines\n",
      "Processed 73,000,000 lines\n",
      "Processed 74,000,000 lines\n",
      "Processed 75,000,000 lines\n",
      "Processed 76,000,000 lines\n",
      "Processed 77,000,000 lines\n",
      "Processed 78,000,000 lines\n",
      "Processed 79,000,000 lines\n",
      "Processed 80,000,000 lines\n",
      "Processed 81,000,000 lines\n",
      "Processed 82,000,000 lines\n",
      "Processed 83,000,000 lines\n",
      "Processed 84,000,000 lines\n",
      "Processed 85,000,000 lines\n",
      "Processed 86,000,000 lines\n",
      "Processed 87,000,000 lines\n",
      "Processed 88,000,000 lines\n",
      "Processed 89,000,000 lines\n",
      "Processed 90,000,000 lines\n",
      "Processed 91,000,000 lines\n",
      "Processed 92,000,000 lines\n",
      "Processed 93,000,000 lines\n",
      "Processed 94,000,000 lines\n",
      "Processed 95,000,000 lines\n",
      "Processed 96,000,000 lines\n",
      "Processed 97,000,000 lines\n",
      "Processed 98,000,000 lines\n",
      "Processed 99,000,000 lines\n",
      "Processed 100,000,000 lines\n",
      "Processed 101,000,000 lines\n",
      "Processed 102,000,000 lines\n",
      "Processed 103,000,000 lines\n",
      "Processed 104,000,000 lines\n",
      "Processed 105,000,000 lines\n",
      "Processed 106,000,000 lines\n",
      "Processed 107,000,000 lines\n",
      "Processed 108,000,000 lines\n",
      "Processed 109,000,000 lines\n",
      "Processed 110,000,000 lines\n",
      "Processed 111,000,000 lines\n",
      "Processed 112,000,000 lines\n",
      "Processed 113,000,000 lines\n",
      "Processed 115,000,000 lines\n",
      "Processed 116,000,000 lines\n",
      "Processed 117,000,000 lines\n",
      "Processed 118,000,000 lines\n",
      "Processed 119,000,000 lines\n",
      "Processed 120,000,000 lines\n",
      "Processed 121,000,000 lines\n",
      "Processed 122,000,000 lines\n",
      "Processed 123,000,000 lines\n",
      "Processed 124,000,000 lines\n",
      "Processed 125,000,000 lines\n",
      "Processed 126,000,000 lines\n",
      "Processed 127,000,000 lines\n",
      "Processed 128,000,000 lines\n",
      "Processed 129,000,000 lines\n",
      "Processed 130,000,000 lines\n",
      "Processed 131,000,000 lines\n",
      "Processed 132,000,000 lines\n",
      "Processed 133,000,000 lines\n",
      "Processed 134,000,000 lines\n",
      "Processed 135,000,000 lines\n",
      "Processed 136,000,000 lines\n",
      "Processed 137,000,000 lines\n",
      "Processed 138,000,000 lines\n",
      "Processed 139,000,000 lines\n",
      "Processed 140,000,000 lines\n",
      "Processed 141,000,000 lines\n",
      "Processed 142,000,000 lines\n",
      "Processed 143,000,000 lines\n",
      "Processed 144,000,000 lines\n",
      "Processed 145,000,000 lines\n",
      "Processed 146,000,000 lines\n",
      "Processed 147,000,000 lines\n",
      "Processed 148,000,000 lines\n",
      "Processed 149,000,000 lines\n",
      "Processed 150,000,000 lines\n",
      "Processed 151,000,000 lines\n",
      "Processed 152,000,000 lines\n",
      "Processed 153,000,000 lines\n",
      "Processed 155,000,000 lines\n",
      "Processed 156,000,000 lines\n",
      "Processed 157,000,000 lines\n",
      "Processed 158,000,000 lines\n",
      "Processed 159,000,000 lines\n",
      "Processed 160,000,000 lines\n",
      "Processed 161,000,000 lines\n",
      "Processed 162,000,000 lines\n",
      "Processed 163,000,000 lines\n",
      "Processed 164,000,000 lines\n",
      "Processed 165,000,000 lines\n",
      "Processed 166,000,000 lines\n",
      "Processed 167,000,000 lines\n",
      "Processed 168,000,000 lines\n",
      "Processed 169,000,000 lines\n",
      "Processed 170,000,000 lines\n",
      "Processed 171,000,000 lines\n",
      "Processed 172,000,000 lines\n",
      "Processed 173,000,000 lines\n",
      "Processed 174,000,000 lines\n",
      "Processed 175,000,000 lines\n",
      "Processed 176,000,000 lines\n",
      "Processed 177,000,000 lines\n",
      "Processed 178,000,000 lines\n",
      "Processed 179,000,000 lines\n",
      "Processed 180,000,000 lines\n",
      "Processed 182,000,000 lines\n",
      "Processed 183,000,000 lines\n",
      "Processed 184,000,000 lines\n",
      "Processed 185,000,000 lines\n",
      "Processed 186,000,000 lines\n",
      "Processed 187,000,000 lines\n",
      "Processed 188,000,000 lines\n",
      "Processed 189,000,000 lines\n",
      "Processed 190,000,000 lines\n",
      "Processed 191,000,000 lines\n",
      "Processed 192,000,000 lines\n",
      "Processed 193,000,000 lines\n",
      "Processed 194,000,000 lines\n",
      "Processed 195,000,000 lines\n",
      "Processed 196,000,000 lines\n",
      "Processed 197,000,000 lines\n",
      "Processed 198,000,000 lines\n",
      "Processed 199,000,000 lines\n",
      "Processed 200,000,000 lines\n",
      "Processed 201,000,000 lines\n",
      "Processed 202,000,000 lines\n",
      "Processed 203,000,000 lines\n",
      "Processed 204,000,000 lines\n",
      "Processed 205,000,000 lines\n",
      "Processed 206,000,000 lines\n",
      "Processed 207,000,000 lines\n",
      "Processed 208,000,000 lines\n",
      "Processed 209,000,000 lines\n",
      "Processed 210,000,000 lines\n",
      "Processed 211,000,000 lines\n",
      "Processed 212,000,000 lines\n",
      "Processed 213,000,000 lines\n",
      "Processed 214,000,000 lines\n",
      "Processed 215,000,000 lines\n",
      "Processed 216,000,000 lines\n",
      "Processed 217,000,000 lines\n",
      "Processed 218,000,000 lines\n",
      "Processed 219,000,000 lines\n",
      "Processed 220,000,000 lines\n",
      "Processed 221,000,000 lines\n",
      "Processed 222,000,000 lines\n",
      "Processed 223,000,000 lines\n",
      "Processed 224,000,000 lines\n",
      "Processed 225,000,000 lines\n",
      "Processed 226,000,000 lines\n",
      "Processed 227,000,000 lines\n",
      "Processed 228,000,000 lines\n",
      "Processed 229,000,000 lines\n",
      "Processed 230,000,000 lines\n",
      "Processed 231,000,000 lines\n",
      "Processed 232,000,000 lines\n",
      "Processed 233,000,000 lines\n",
      "Processed 234,000,000 lines\n",
      "Processed 235,000,000 lines\n",
      "Processed 236,000,000 lines\n",
      "Processed 237,000,000 lines\n",
      "Processed 238,000,000 lines\n",
      "Processed 239,000,000 lines\n",
      "Processed 241,000,000 lines\n",
      "Processed 242,000,000 lines\n",
      "Processed 243,000,000 lines\n",
      "Processed 244,000,000 lines\n",
      "Processed 245,000,000 lines\n",
      "Processed 247,000,000 lines\n",
      "Processed 248,000,000 lines\n",
      "Processed 249,000,000 lines\n",
      "Processed 250,000,000 lines\n",
      "Processed 251,000,000 lines\n",
      "Processed 252,000,000 lines\n",
      "Processed 253,000,000 lines\n",
      "Processed 254,000,000 lines\n",
      "Processed 255,000,000 lines\n",
      "Processed 256,000,000 lines\n",
      "Processed 257,000,000 lines\n",
      "Processed 258,000,000 lines\n",
      "Processed 259,000,000 lines\n",
      "Processed 261,000,000 lines\n",
      "Processed 262,000,000 lines\n",
      "Processed 263,000,000 lines\n",
      "Processed 264,000,000 lines\n",
      "Processed 265,000,000 lines\n",
      "Processed 266,000,000 lines\n",
      "Processed 267,000,000 lines\n",
      "Processed 268,000,000 lines\n",
      "Processed 269,000,000 lines\n",
      "Processed 270,000,000 lines\n",
      "Processed 271,000,000 lines\n",
      "Processed 272,000,000 lines\n",
      "Processed 273,000,000 lines\n",
      "Processed 274,000,000 lines\n",
      "Processed 275,000,000 lines\n",
      "Processed 276,000,000 lines\n",
      "Processed 277,000,000 lines\n",
      "Processed 278,000,000 lines\n",
      "Processed 279,000,000 lines\n",
      "Processed 280,000,000 lines\n",
      "Processed 281,000,000 lines\n",
      "Processed 282,000,000 lines\n",
      "Processed 283,000,000 lines\n",
      "Processed 284,000,000 lines\n",
      "Processed 285,000,000 lines\n",
      "Processed 286,000,000 lines\n",
      "Processed 287,000,000 lines\n",
      "Processed 288,000,000 lines\n",
      "Processed 289,000,000 lines\n",
      "Processed 290,000,000 lines\n",
      "Processed 291,000,000 lines\n",
      "Processed 292,000,000 lines\n",
      "Processed 293,000,000 lines\n",
      "Processed 294,000,000 lines\n",
      "Processed 295,000,000 lines\n",
      "Processed 296,000,000 lines\n",
      "Processed 297,000,000 lines\n",
      "Processed 298,000,000 lines\n",
      "Processed 299,000,000 lines\n",
      "Processed 300,000,000 lines\n",
      "Processed 301,000,000 lines\n",
      "Processed 302,000,000 lines\n",
      "Processed 303,000,000 lines\n",
      "Processed 304,000,000 lines\n",
      "Processed 305,000,000 lines\n",
      "Processed 306,000,000 lines\n",
      "Processed 307,000,000 lines\n",
      "Processed 308,000,000 lines\n",
      "Processed 309,000,000 lines\n",
      "Processed 310,000,000 lines\n",
      "Processed 311,000,000 lines\n",
      "Processed 312,000,000 lines\n",
      "Processed 313,000,000 lines\n",
      "Processed 314,000,000 lines\n",
      "Processed 315,000,000 lines\n",
      "Processed 316,000,000 lines\n",
      "Processed 317,000,000 lines\n",
      "Processed 318,000,000 lines\n",
      "Processed 319,000,000 lines\n",
      "Processed 320,000,000 lines\n",
      "Processed 321,000,000 lines\n",
      "Processed 322,000,000 lines\n",
      "Processed 323,000,000 lines\n",
      "Processed 324,000,000 lines\n",
      "Processed 325,000,000 lines\n",
      "Processed 326,000,000 lines\n",
      "Processed 327,000,000 lines\n",
      "Processed 328,000,000 lines\n",
      "Processed 329,000,000 lines\n",
      "Processed 330,000,000 lines\n",
      "Processed 331,000,000 lines\n",
      "Processed 332,000,000 lines\n",
      "Processed 333,000,000 lines\n",
      "Processed 334,000,000 lines\n",
      "Processed 335,000,000 lines\n",
      "Processed 336,000,000 lines\n",
      "Processed 337,000,000 lines\n",
      "Processed 338,000,000 lines\n",
      "Processed 339,000,000 lines\n",
      "Processed 340,000,000 lines\n",
      "Processed 341,000,000 lines\n",
      "Processed 342,000,000 lines\n",
      "Processed 343,000,000 lines\n",
      "Processed 344,000,000 lines\n",
      "Processed 345,000,000 lines\n",
      "Processed 346,000,000 lines\n",
      "Processed 347,000,000 lines\n",
      "Processed 348,000,000 lines\n",
      "Processed 349,000,000 lines\n",
      "Processed 350,000,000 lines\n",
      "Processed 351,000,000 lines\n",
      "Processed 352,000,000 lines\n",
      "Processed 353,000,000 lines\n",
      "Processed 354,000,000 lines\n",
      "Processed 355,000,000 lines\n",
      "Processed 356,000,000 lines\n",
      "Processed 357,000,000 lines\n",
      "Processed 358,000,000 lines\n",
      "Processed 359,000,000 lines\n",
      "Processed 360,000,000 lines\n",
      "Processed 361,000,000 lines\n",
      "Processed 362,000,000 lines\n",
      "Processed 363,000,000 lines\n",
      "Processed 364,000,000 lines\n",
      "Processed 365,000,000 lines\n",
      "Processed 366,000,000 lines\n",
      "Processed 367,000,000 lines\n",
      "Processed 368,000,000 lines\n",
      "Processed 369,000,000 lines\n",
      "Processed 370,000,000 lines\n",
      "Processed 371,000,000 lines\n",
      "Processed 372,000,000 lines\n",
      "Processed 373,000,000 lines\n",
      "Processed 374,000,000 lines\n",
      "Processed 375,000,000 lines\n",
      "Processed 376,000,000 lines\n",
      "Processed 377,000,000 lines\n",
      "Processed 378,000,000 lines\n",
      "Processed 379,000,000 lines\n",
      "Processed 380,000,000 lines\n",
      "Processed 381,000,000 lines\n",
      "Processed 382,000,000 lines\n",
      "Processed 383,000,000 lines\n",
      "Processed 384,000,000 lines\n",
      "Processed 385,000,000 lines\n",
      "Processed 386,000,000 lines\n",
      "Processed 387,000,000 lines\n",
      "Processed 388,000,000 lines\n",
      "Processed 389,000,000 lines\n",
      "Processed 390,000,000 lines\n",
      "Processed 391,000,000 lines\n",
      "Processed 392,000,000 lines\n",
      "Processed 393,000,000 lines\n",
      "Processed 394,000,000 lines\n",
      "Processed 395,000,000 lines\n",
      "Processed 396,000,000 lines\n",
      "Processed 397,000,000 lines\n",
      "Processed 398,000,000 lines\n",
      "Processed 399,000,000 lines\n",
      "Processed 400,000,000 lines\n",
      "Processed 401,000,000 lines\n",
      "Processed 402,000,000 lines\n",
      "Processed 403,000,000 lines\n",
      "Processed 404,000,000 lines\n",
      "Processed 405,000,000 lines\n",
      "Processed 406,000,000 lines\n",
      "Processed 407,000,000 lines\n",
      "Processed 408,000,000 lines\n",
      "Processed 410,000,000 lines\n",
      "Processed 411,000,000 lines\n",
      "Processed 412,000,000 lines\n",
      "Processed 413,000,000 lines\n",
      "Processed 414,000,000 lines\n",
      "Processed 415,000,000 lines\n",
      "Processed 416,000,000 lines\n",
      "Processed 417,000,000 lines\n",
      "Processed 418,000,000 lines\n",
      "Processed 419,000,000 lines\n",
      "Processed 420,000,000 lines\n",
      "Processed 421,000,000 lines\n",
      "Processed 422,000,000 lines\n",
      "Processed 423,000,000 lines\n",
      "Processed 424,000,000 lines\n",
      "Processed 425,000,000 lines\n",
      "Processed 426,000,000 lines\n",
      "Processed 427,000,000 lines\n",
      "Processed 428,000,000 lines\n",
      "Processed 429,000,000 lines\n",
      "Processed 430,000,000 lines\n",
      "Processed 432,000,000 lines\n",
      "Processed 433,000,000 lines\n",
      "Processed 434,000,000 lines\n",
      "Processed 435,000,000 lines\n",
      "Processed 436,000,000 lines\n",
      "Processed 437,000,000 lines\n",
      "Processed 438,000,000 lines\n",
      "Processed 439,000,000 lines\n",
      "Processed 440,000,000 lines\n",
      "Processed 441,000,000 lines\n",
      "Processed 442,000,000 lines\n",
      "Processed 443,000,000 lines\n",
      "Processed 444,000,000 lines\n",
      "Processed 445,000,000 lines\n",
      "Processed 446,000,000 lines\n",
      "Processed 447,000,000 lines\n",
      "Processed 448,000,000 lines\n",
      "Processed 449,000,000 lines\n",
      "Processed 450,000,000 lines\n",
      "Processed 451,000,000 lines\n",
      "Processed 452,000,000 lines\n",
      "Processed 453,000,000 lines\n",
      "Processed 454,000,000 lines\n",
      "Processed 455,000,000 lines\n",
      "Processed 456,000,000 lines\n",
      "Processed 457,000,000 lines\n",
      "Processed 458,000,000 lines\n",
      "Processed 459,000,000 lines\n",
      "Processed 460,000,000 lines\n",
      "Processed 461,000,000 lines\n",
      "Processed 462,000,000 lines\n",
      "Processed 463,000,000 lines\n",
      "Processed 464,000,000 lines\n",
      "Processed 465,000,000 lines\n",
      "Processed 467,000,000 lines\n",
      "Processed 468,000,000 lines\n",
      "Processed 469,000,000 lines\n",
      "Processed 470,000,000 lines\n",
      "Processed 471,000,000 lines\n",
      "Processed 472,000,000 lines\n",
      "Processed 473,000,000 lines\n",
      "Processed 474,000,000 lines\n",
      "Processed 475,000,000 lines\n",
      "Processed 476,000,000 lines\n",
      "Processed 477,000,000 lines\n",
      "Processed 478,000,000 lines\n",
      "Processed 479,000,000 lines\n",
      "Processed 480,000,000 lines\n",
      "Processed 481,000,000 lines\n",
      "Processed 482,000,000 lines\n",
      "Processed 483,000,000 lines\n",
      "Processed 484,000,000 lines\n",
      "Processed 485,000,000 lines\n",
      "Processed 486,000,000 lines\n",
      "Processed 487,000,000 lines\n",
      "Processed 488,000,000 lines\n",
      "Processed 489,000,000 lines\n",
      "Processed 490,000,000 lines\n",
      "Processed 491,000,000 lines\n",
      "Processed 492,000,000 lines\n",
      "Processed 493,000,000 lines\n",
      "Processed 494,000,000 lines\n",
      "Processed 495,000,000 lines\n",
      "Processed 496,000,000 lines\n",
      "Processed 497,000,000 lines\n",
      "Processed 498,000,000 lines\n",
      "Processed 499,000,000 lines\n",
      "Processed 500,000,000 lines\n",
      "Processed 501,000,000 lines\n",
      "Processed 502,000,000 lines\n",
      "Processed 503,000,000 lines\n",
      "Processed 504,000,000 lines\n",
      "Processed 505,000,000 lines\n",
      "Processed 506,000,000 lines\n",
      "Processed 507,000,000 lines\n",
      "Processed 508,000,000 lines\n",
      "Processed 509,000,000 lines\n",
      "Processed 510,000,000 lines\n",
      "Processed 511,000,000 lines\n",
      "Processed 512,000,000 lines\n",
      "Processed 513,000,000 lines\n",
      "Processed 514,000,000 lines\n",
      "Processed 515,000,000 lines\n",
      "Processed 516,000,000 lines\n",
      "Processed 517,000,000 lines\n",
      "Processed 518,000,000 lines\n",
      "Processed 519,000,000 lines\n",
      "Processed 520,000,000 lines\n",
      "Processed 521,000,000 lines\n",
      "Processed 522,000,000 lines\n",
      "Processed 523,000,000 lines\n",
      "Processed 524,000,000 lines\n",
      "Processed 525,000,000 lines\n",
      "Processed 526,000,000 lines\n",
      "Processed 527,000,000 lines\n",
      "Processed 528,000,000 lines\n",
      "Processed 529,000,000 lines\n",
      "Processed 530,000,000 lines\n",
      "Processed 531,000,000 lines\n",
      "Processed 532,000,000 lines\n",
      "Processed 533,000,000 lines\n",
      "Processed 534,000,000 lines\n",
      "Processed 535,000,000 lines\n",
      "Processed 536,000,000 lines\n",
      "Processed 537,000,000 lines\n",
      "Processed 538,000,000 lines\n",
      "Processed 539,000,000 lines\n",
      "Processed 540,000,000 lines\n",
      "Processed 541,000,000 lines\n",
      "Processed 542,000,000 lines\n",
      "Processed 543,000,000 lines\n",
      "Processed 544,000,000 lines\n",
      "Authors: 3930945\n",
      "DOIs: 6841488\n"
     ]
    }
   ],
   "source": [
    "authors_by_pid = {}\n",
    "dois_by_pub = {}\n",
    "\n",
    "signature_to_pid = {}\n",
    "pub_to_signatures = {}\n",
    "pub_to_pids = {}\n",
    "pid_to_label = {}\n",
    "\n",
    "RDFS_LABEL = \"http://www.w3.org/2000/01/rdf-schema#label\"\n",
    "\n",
    "with fs.open(rdf_path, \"rb\") as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        for i, line in enumerate(gz):\n",
    "\n",
    "            line = line.decode(\"utf-8\", errors=\"ignore\").strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            parts = line.split(\" \", 2)\n",
    "            if len(parts) != 3:\n",
    "                continue\n",
    "\n",
    "            subj, pred, obj = parts\n",
    "            subj = subj.strip(\"<>\")\n",
    "            pred = pred.strip(\"<>\")\n",
    "            obj = obj.strip(\" .\").strip(\"<>\")\n",
    "\n",
    "            # ---------- PID -> label ----------\n",
    "            if pred == RDFS_LABEL:\n",
    "                pid_to_label[subj] = obj.strip('\"')\n",
    "\n",
    "            # ---------- signature -> PID ----------\n",
    "            elif pred.endswith(\"signatureCreator\"):\n",
    "                signature_to_pid[subj] = obj\n",
    "\n",
    "            # ---------- publication -> signature ----------\n",
    "            elif pred.endswith(\"hasSignature\") or pred.endswith(\"authoredBy\"):\n",
    "                pub_to_signatures.setdefault(subj, []).append(obj)\n",
    "\n",
    "            # ---------- DOI ----------\n",
    "            elif pred.endswith(\"doi\"):\n",
    "                dois_by_pub[subj] = obj.strip('\"')\n",
    "\n",
    "            if i % 1_000_000 == 0 and i > 0:\n",
    "                print(f\"Processed {i:,} lines\")\n",
    "\n",
    "# ---------- FINAL MERGE ----------\n",
    "for sig, pid in signature_to_pid.items():\n",
    "    label = pid_to_label.get(pid)\n",
    "    if label:\n",
    "        authors_by_pid[pid] = label\n",
    "\n",
    "for pub, sigs in pub_to_signatures.items():\n",
    "    pids = []\n",
    "\n",
    "    for sig in sigs:\n",
    "        pid = signature_to_pid.get(sig)\n",
    "        if pid:\n",
    "            pids.append(pid)\n",
    "\n",
    "    if pids:\n",
    "        pub_to_pids[pub] = pids\n",
    "\n",
    "pub_to_pids[pub] = list(set(pids))\n",
    "\n",
    "print(\"Authors:\", len(authors_by_pid))\n",
    "print(\"DOIs:\", len(dois_by_pub))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9cfee2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://dblp.org/rec/reference/vision/Singh14</td>\n",
       "      <td>[https://dblp.org/pid/78/459-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://dblp.org/rec/reference/vision/Wong14</td>\n",
       "      <td>[https://dblp.org/pid/69/220]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://dblp.org/rec/reference/vision/Pont14b</td>\n",
       "      <td>[https://dblp.org/pid/99/2633]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://dblp.org/rec/reference/vision/Alexander14</td>\n",
       "      <td>[https://dblp.org/pid/37/6152]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://dblp.org/rec/reference/vision/Fukui14</td>\n",
       "      <td>[https://dblp.org/pid/01/1485]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101479</th>\n",
       "      <td>https://dblp.org/rec/persons/Codd71b</td>\n",
       "      <td>[https://dblp.org/pid/c/EFCodd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101480</th>\n",
       "      <td>https://dblp.org/rec/persons/Codd71</td>\n",
       "      <td>[https://dblp.org/pid/c/EFCodd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101481</th>\n",
       "      <td>https://dblp.org/rec/persons/Hall74</td>\n",
       "      <td>[https://dblp.org/pid/82/5885]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101482</th>\n",
       "      <td>https://dblp.org/rec/persons/Codd69</td>\n",
       "      <td>[https://dblp.org/pid/c/EFCodd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101483</th>\n",
       "      <td>https://dblp.org/rec/persons/Ley95</td>\n",
       "      <td>[https://dblp.org/pid/00/1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8101484 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       pid  \\\n",
       "0            https://dblp.org/rec/reference/vision/Singh14   \n",
       "1             https://dblp.org/rec/reference/vision/Wong14   \n",
       "2            https://dblp.org/rec/reference/vision/Pont14b   \n",
       "3        https://dblp.org/rec/reference/vision/Alexander14   \n",
       "4            https://dblp.org/rec/reference/vision/Fukui14   \n",
       "...                                                    ...   \n",
       "8101479               https://dblp.org/rec/persons/Codd71b   \n",
       "8101480                https://dblp.org/rec/persons/Codd71   \n",
       "8101481                https://dblp.org/rec/persons/Hall74   \n",
       "8101482                https://dblp.org/rec/persons/Codd69   \n",
       "8101483                 https://dblp.org/rec/persons/Ley95   \n",
       "\n",
       "                                    name  \n",
       "0        [https://dblp.org/pid/78/459-1]  \n",
       "1          [https://dblp.org/pid/69/220]  \n",
       "2         [https://dblp.org/pid/99/2633]  \n",
       "3         [https://dblp.org/pid/37/6152]  \n",
       "4         [https://dblp.org/pid/01/1485]  \n",
       "...                                  ...  \n",
       "8101479  [https://dblp.org/pid/c/EFCodd]  \n",
       "8101480  [https://dblp.org/pid/c/EFCodd]  \n",
       "8101481   [https://dblp.org/pid/82/5885]  \n",
       "8101482  [https://dblp.org/pid/c/EFCodd]  \n",
       "8101483      [https://dblp.org/pid/00/1]  \n",
       "\n",
       "[8101484 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pub_to_pids.items(), columns=[\"pid\", \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45bd5203",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fs.open(f\"s3://lab/conf_net.parquet\", \"wb\") as f:\n",
    "            df.to_parquet(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934476ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles=[]\n",
    "\n",
    "with fs.open(path, 'rb') as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        context = etree.iterparse(\n",
    "            gz, events=(\"end\",), tag=\"article\", recover=True\n",
    "        )\n",
    "\n",
    "        for event, elem in context:\n",
    "            title = elem.findtext(\"title\")\n",
    "            journal = elem.findtext(\"journal\")\n",
    "            pub_date = elem.findtext(\"year\")\n",
    "            doi = elem.findtext(\"ee\")\n",
    "\n",
    "            # Article-level DBLP PID\n",
    "            article_pid = elem.get(\"key\")\n",
    "\n",
    "            # Collect authors + IDs\n",
    "            authors = []\n",
    "\n",
    "            for a in elem.findall(\".//author\"):\n",
    "                name = a.text     # DBLP person ID\n",
    "                orcid = a.get(\"orcid\")\n",
    "                if name:\n",
    "                    authors.append({\n",
    "                        \"name\": name,\n",
    "                        \"orcid\": orcid\n",
    "                    })\n",
    "\n",
    "            articles.append({\n",
    "                \"title\": title,\n",
    "                \"journal\": journal,\n",
    "                \"year\": pub_date,\n",
    "                \"authors\": authors,\n",
    "                \"dblp_uri\": article_pid,\n",
    "                \"doi\": doi\n",
    "            })\n",
    "\n",
    "            elem.clear()\n",
    "\n",
    "df = pd.DataFrame(articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261cdaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles=[]\n",
    "\n",
    "with fs.open(path, 'rb') as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        context = etree.iterparse(\n",
    "            gz, events=(\"end\",), tag=\"inproceedings\", recover=True\n",
    "        )\n",
    "\n",
    "        for event, elem in context:\n",
    "            title = elem.findtext(\"title\")\n",
    "            conf = elem.findtext(\"booktitle\")\n",
    "            pub_date = elem.findtext(\"year\")\n",
    "            doi = elem.findtext(\"ee\")\n",
    "\n",
    "            # Article-level DBLP PID\n",
    "            article_pid = elem.get(\"key\")\n",
    "\n",
    "            # Collect authors + IDs\n",
    "            authors = []\n",
    "\n",
    "            for a in elem.findall(\".//author\"):\n",
    "                name = a.text     # DBLP person ID\n",
    "                orcid = a.get(\"orcid\")\n",
    "                if name:\n",
    "                    authors.append({\n",
    "                        \"name\": name,\n",
    "                        \"orcid\": orcid\n",
    "                    })\n",
    "\n",
    "            articles.append({\n",
    "                \"title\": title,\n",
    "                \"conf\": conf,\n",
    "                \"year\": pub_date,\n",
    "                \"authors\": authors,\n",
    "                \"dblp_uri\": article_pid,\n",
    "                \"doi\": doi\n",
    "            })\n",
    "\n",
    "            elem.clear()\n",
    "\n",
    "df = pd.DataFrame(articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd286322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>conf</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>dblp_uri</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Future of Classic Data Administration: Obj...</td>\n",
       "      <td>SWEE</td>\n",
       "      <td>1998</td>\n",
       "      <td>[{'name': 'Arnon Rosenthal', 'orcid': None}]</td>\n",
       "      <td>www/org/mitre/future</td>\n",
       "      <td>http://www.mitre.org/support/swee/rosenthal.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Some Patterns of Convincing Software Engineeri...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>[{'name': 'Lutz Prechelt', 'orcid': None}]</td>\n",
       "      <td>books/sp/22/Prechelt22</td>\n",
       "      <td>https://doi.org/10.1007/978-3-030-83128-8_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Static Worst-Case Analyses and Their Validatio...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>[{'name': 'Peter Wgemann', 'orcid': None}]</td>\n",
       "      <td>books/sp/22/Wagemann22</td>\n",
       "      <td>https://doi.org/10.1007/978-3-030-83128-8_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crossing Disciplinary Borders to Improve Requi...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>[{'name': 'Anne Hess', 'orcid': None}]</td>\n",
       "      <td>books/sp/22/Hess22</td>\n",
       "      <td>https://doi.org/10.1007/978-3-030-83128-8_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What You See Is What You Get: Practical Effect...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>[{'name': 'Jonathan Immanuel Brachthuser', 'or...</td>\n",
       "      <td>books/sp/22/Brachthauser22</td>\n",
       "      <td>https://doi.org/10.1007/978-3-030-83128-8_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749511</th>\n",
       "      <td>Toward a Modern Geography of Minds, Machines, ...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>[{'name': 'Selmer Bringsjord', 'orcid': None},...</td>\n",
       "      <td>series/sapere/BringsjordG13</td>\n",
       "      <td>https://doi.org/10.1007/978-3-642-31674-6_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749512</th>\n",
       "      <td>Emotional Control-Conditio Sine Qua Non for Ad...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>[{'name': 'Claudius Gros', 'orcid': '0000-0002...</td>\n",
       "      <td>series/sapere/Gros13</td>\n",
       "      <td>https://doi.org/10.1007/978-3-642-31674-6_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749513</th>\n",
       "      <td>Becoming Digital: Reconciling Theories of Digi...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>[{'name': 'Harry Halpin', 'orcid': None}]</td>\n",
       "      <td>series/sapere/Halpin13</td>\n",
       "      <td>https://doi.org/10.1007/978-3-642-31674-6_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749514</th>\n",
       "      <td>Generative Artificial Intelligence.</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>[{'name': 'Tijn van der Zant', 'orcid': None},...</td>\n",
       "      <td>series/sapere/ZantKS13</td>\n",
       "      <td>https://doi.org/10.1007/978-3-642-31674-6_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749515</th>\n",
       "      <td>Seven Steps to Rendezvous with the Casual User.</td>\n",
       "      <td>IFIP Working Conference Data Base Management</td>\n",
       "      <td>1974</td>\n",
       "      <td>[{'name': 'E. F. Codd', 'orcid': None}]</td>\n",
       "      <td>persons/Codd74</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3749516 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  \\\n",
       "0        The Future of Classic Data Administration: Obj...   \n",
       "1        Some Patterns of Convincing Software Engineeri...   \n",
       "2        Static Worst-Case Analyses and Their Validatio...   \n",
       "3        Crossing Disciplinary Borders to Improve Requi...   \n",
       "4        What You See Is What You Get: Practical Effect...   \n",
       "...                                                    ...   \n",
       "3749511  Toward a Modern Geography of Minds, Machines, ...   \n",
       "3749512  Emotional Control-Conditio Sine Qua Non for Ad...   \n",
       "3749513  Becoming Digital: Reconciling Theories of Digi...   \n",
       "3749514                Generative Artificial Intelligence.   \n",
       "3749515    Seven Steps to Rendezvous with the Casual User.   \n",
       "\n",
       "                                                 conf  year  \\\n",
       "0                                                SWEE  1998   \n",
       "1                                        Denert Award  2020   \n",
       "2                                        Denert Award  2020   \n",
       "3                                        Denert Award  2020   \n",
       "4                                        Denert Award  2020   \n",
       "...                                               ...   ...   \n",
       "3749511                                         PT-AI  2011   \n",
       "3749512                                         PT-AI  2011   \n",
       "3749513                                         PT-AI  2011   \n",
       "3749514                                         PT-AI  2011   \n",
       "3749515  IFIP Working Conference Data Base Management  1974   \n",
       "\n",
       "                                                   authors  \\\n",
       "0             [{'name': 'Arnon Rosenthal', 'orcid': None}]   \n",
       "1               [{'name': 'Lutz Prechelt', 'orcid': None}]   \n",
       "2               [{'name': 'Peter Wgemann', 'orcid': None}]   \n",
       "3                   [{'name': 'Anne Hess', 'orcid': None}]   \n",
       "4        [{'name': 'Jonathan Immanuel Brachthuser', 'or...   \n",
       "...                                                    ...   \n",
       "3749511  [{'name': 'Selmer Bringsjord', 'orcid': None},...   \n",
       "3749512  [{'name': 'Claudius Gros', 'orcid': '0000-0002...   \n",
       "3749513          [{'name': 'Harry Halpin', 'orcid': None}]   \n",
       "3749514  [{'name': 'Tijn van der Zant', 'orcid': None},...   \n",
       "3749515            [{'name': 'E. F. Codd', 'orcid': None}]   \n",
       "\n",
       "                            dblp_uri  \\\n",
       "0               www/org/mitre/future   \n",
       "1             books/sp/22/Prechelt22   \n",
       "2             books/sp/22/Wagemann22   \n",
       "3                 books/sp/22/Hess22   \n",
       "4         books/sp/22/Brachthauser22   \n",
       "...                              ...   \n",
       "3749511  series/sapere/BringsjordG13   \n",
       "3749512         series/sapere/Gros13   \n",
       "3749513       series/sapere/Halpin13   \n",
       "3749514       series/sapere/ZantKS13   \n",
       "3749515               persons/Codd74   \n",
       "\n",
       "                                                      doi  \n",
       "0        http://www.mitre.org/support/swee/rosenthal.html  \n",
       "1             https://doi.org/10.1007/978-3-030-83128-8_2  \n",
       "2            https://doi.org/10.1007/978-3-030-83128-8_11  \n",
       "3             https://doi.org/10.1007/978-3-030-83128-8_7  \n",
       "4             https://doi.org/10.1007/978-3-030-83128-8_3  \n",
       "...                                                   ...  \n",
       "3749511      https://doi.org/10.1007/978-3-642-31674-6_11  \n",
       "3749512      https://doi.org/10.1007/978-3-642-31674-6_14  \n",
       "3749513      https://doi.org/10.1007/978-3-642-31674-6_15  \n",
       "3749514       https://doi.org/10.1007/978-3-642-31674-6_8  \n",
       "3749515                                              None  \n",
       "\n",
       "[3749516 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aafcd72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>conf</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Future of Classic Data Administration: Obj...</td>\n",
       "      <td>SWEE</td>\n",
       "      <td>1998</td>\n",
       "      <td>Arnon Rosenthal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Some Patterns of Convincing Software Engineeri...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>Lutz Prechelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Static Worst-Case Analyses and Their Validatio...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>Peter Wgemann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crossing Disciplinary Borders to Improve Requi...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>Anne Hess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What You See Is What You Get: Practical Effect...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jonathan Immanuel Brachthuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749504</th>\n",
       "      <td>Machine Intentionality, the Moral Status of Ma...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>David Leech Anderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749509</th>\n",
       "      <td>Practical Introspection as Inspiration for AI.</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>Sam Freed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749510</th>\n",
       "      <td>\"Computational Ontology and Deontology\".</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>Raffaela Giovagnoli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749512</th>\n",
       "      <td>Emotional Control-Conditio Sine Qua Non for Ad...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>Claudius Gros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749513</th>\n",
       "      <td>Becoming Digital: Reconciling Theories of Digi...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>Harry Halpin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284765 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title          conf  \\\n",
       "0        The Future of Classic Data Administration: Obj...          SWEE   \n",
       "1        Some Patterns of Convincing Software Engineeri...  Denert Award   \n",
       "2        Static Worst-Case Analyses and Their Validatio...  Denert Award   \n",
       "3        Crossing Disciplinary Borders to Improve Requi...  Denert Award   \n",
       "4        What You See Is What You Get: Practical Effect...  Denert Award   \n",
       "...                                                    ...           ...   \n",
       "3749504  Machine Intentionality, the Moral Status of Ma...         PT-AI   \n",
       "3749509     Practical Introspection as Inspiration for AI.         PT-AI   \n",
       "3749510           \"Computational Ontology and Deontology\".         PT-AI   \n",
       "3749512  Emotional Control-Conditio Sine Qua Non for Ad...         PT-AI   \n",
       "3749513  Becoming Digital: Reconciling Theories of Digi...         PT-AI   \n",
       "\n",
       "         year                        authors  \n",
       "0        1998                Arnon Rosenthal  \n",
       "1        2020                  Lutz Prechelt  \n",
       "2        2020                  Peter Wgemann  \n",
       "3        2020                      Anne Hess  \n",
       "4        2020  Jonathan Immanuel Brachthuser  \n",
       "...       ...                            ...  \n",
       "3749504  2011           David Leech Anderson  \n",
       "3749509  2011                      Sam Freed  \n",
       "3749510  2011            Raffaela Giovagnoli  \n",
       "3749512  2011                  Claudius Gros  \n",
       "3749513  2011                   Harry Halpin  \n",
       "\n",
       "[284765 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "df[df[\"authors\"].apply(lambda x: bool(re.compile(r\"^[A-Za-z\\s-]+$\").search(str(x))))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18043c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['author', 'booktitle', 'cdrom', 'cite', 'crossref', 'editor', 'ee', 'month', 'note', 'number', 'pages', 'publnr', 'stream', 'title', 'url', 'volume', 'year']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import gzip\n",
    "\n",
    "direct_set = set()\n",
    "\n",
    "with fs.open(path, \"rb\") as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        context = etree.iterparse(gz, events=(\"end\",), tag=\"inproceedings\", recover=True)\n",
    "        for event, elem in context:\n",
    "            # collect child tags\n",
    "            for child in elem:\n",
    "                if child.tag is not None:\n",
    "                    direct_set.add(child.tag)\n",
    "\n",
    "            # clear memory: remove element and its previous siblings\n",
    "            elem.clear()\n",
    "            while elem.getprevious() is not None:\n",
    "                del elem.getparent()[0]\n",
    "\n",
    "print(sorted(direct_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f63b4a20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m chunks = []\n\u001b[32m      2\u001b[39m n_chunks = \u001b[32m50\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m chunk_size = \u001b[38;5;28mlen\u001b[39m(\u001b[43mdf\u001b[49m) // n_chunks\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_chunks):\n\u001b[32m      6\u001b[39m     start = i * chunk_size\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "n_chunks = 50\n",
    "chunk_size = len(df) // n_chunks\n",
    "\n",
    "for i in range(n_chunks):\n",
    "    start = i * chunk_size\n",
    "    end = (i + 1) * chunk_size if i < n_chunks - 1 else len(df)  # last chunk includes remainder\n",
    "    \n",
    "    chunk = df.iloc[start:end].copy()\n",
    "    \n",
    "    # Split authors column into multiple columns\n",
    "    #authors_df = chunk['authors'].str.split(';', expand=True)\n",
    "    #authors_df.columns = [f'author{i+1}' for i in range(authors_df.shape[1])]\n",
    "    \n",
    "    # Combine with original chunk\n",
    "    #chunk = pd.concat([chunk.drop(columns=['authors']), authors_df], axis=1)\n",
    "    \n",
    "    chunk.to_parquet(f\"inpro/inproceedings_chunk_{i}.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a780155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "\n",
    "ego_data = defaultdict(lambda: {\"publications\": []}) #set permet de créer des clefs si absentes et de les actualiser si présentes (en définissant la classe des clefs)\n",
    "\n",
    "chunk_files = glob.glob(\"inpro/inproceedings_chunk_*.parquet\")\n",
    "\n",
    "for file in chunk_files:\n",
    "    df_chunk = pd.read_parquet(file)\n",
    "    for _, row in df_chunk.iterrows():\n",
    "        authors = row['authors'].split(';')\n",
    "        #authors = [a for a in authors if not re.compile(r\"\\d\").search(a)]\n",
    "        for ego in authors:\n",
    "            coauthors = set(authors) - {ego}\n",
    "            \n",
    "            ego_data[ego][\"publications\"].append({\n",
    "                \"coauthors\": list(coauthors),\n",
    "                \"source\": row.get(\"conf\"),\n",
    "                \"year\": row.get(\"year\"),\n",
    "                \"title\": row.get(\"title\"),\n",
    "                \"doi\": row.get(\"doi\")\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f903d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for ego, data in ego_data.items():\n",
    "    for pub in data[\"publications\"]:\n",
    "        rows.append({\n",
    "            \"ego\": ego,\n",
    "            \"coauthors\": \",\".join(sorted(pub[\"coauthors\"])),\n",
    "            \"source\": pub.get(\"source\"),\n",
    "            \"year\": pub.get(\"year\"),\n",
    "            \"title\": pub.get(\"title\"),\n",
    "            \"doi\": pub.get(\"doi\")\n",
    "        })\n",
    "\n",
    "inp_df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07d2b871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ego</th>\n",
       "      <th>coauthors</th>\n",
       "      <th>source</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sanish Rai</td>\n",
       "      <td>Xiaolin Hu 0002</td>\n",
       "      <td>SpringSim (TMS)</td>\n",
       "      <td>2018</td>\n",
       "      <td>Hybrid agent-based and graph-based modeling fo...</td>\n",
       "      <td>http://dl.acm.org/citation.cfm?id=3213189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sanish Rai</td>\n",
       "      <td>Xiaolin Hu 0002</td>\n",
       "      <td>IAT</td>\n",
       "      <td>2013</td>\n",
       "      <td>Behavior Pattern Detection for Data Assimilati...</td>\n",
       "      <td>https://doi.org/10.1109/WI-IAT.2013.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sanish Rai</td>\n",
       "      <td>Minghao Wang, Xiaolin Hu 0002</td>\n",
       "      <td>SpringSim (ADS)</td>\n",
       "      <td>2015</td>\n",
       "      <td>A graph-based agent-oriented model for buildin...</td>\n",
       "      <td>http://dl.acm.org/citation.cfm?id=2872548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sanish Rai</td>\n",
       "      <td>Xiaolin Hu 0002</td>\n",
       "      <td>WSC</td>\n",
       "      <td>2017</td>\n",
       "      <td>Data assimilation with sensor-informed resampl...</td>\n",
       "      <td>https://doi.org/10.1109/WSC.2017.8247862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sanish Rai</td>\n",
       "      <td>Xiaolin Hu 0002</td>\n",
       "      <td>COMPSAC</td>\n",
       "      <td>2016</td>\n",
       "      <td>Graph Based Agent Oriented Model for Tunnel Si...</td>\n",
       "      <td>https://doi.org/10.1109/COMPSAC.2016.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12855429</th>\n",
       "      <td>Juan Gutierrez</td>\n",
       "      <td>Ashley Houston-King, Cliff Freeman, Eli Tucke...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "      <td>https://doi.org/10.1145/3615430.3615444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12855430</th>\n",
       "      <td>Ashley Houston-King</td>\n",
       "      <td>Cliff Freeman, Eli Tucker-Raymond, Katherine ...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "      <td>https://doi.org/10.1145/3615430.3615444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12855431</th>\n",
       "      <td>Cliff Freeman</td>\n",
       "      <td>Ashley Houston-King, Eli Tucker-Raymond, Kath...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "      <td>https://doi.org/10.1145/3615430.3615444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12855432</th>\n",
       "      <td>Katherine K. Frankel</td>\n",
       "      <td>Ashley Houston-King, Cliff Freeman, Eli Tucke...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "      <td>https://doi.org/10.1145/3615430.3615444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12855433</th>\n",
       "      <td>Ryan Cain</td>\n",
       "      <td>Victor R. Lee</td>\n",
       "      <td>FabLearn</td>\n",
       "      <td>2016</td>\n",
       "      <td>Measuring Electrodermal Activity to Capture En...</td>\n",
       "      <td>https://doi.org/10.1145/3003397.3003409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12855434 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ego  \\\n",
       "0                    Sanish Rai   \n",
       "1                    Sanish Rai   \n",
       "2                    Sanish Rai   \n",
       "3                    Sanish Rai   \n",
       "4                    Sanish Rai   \n",
       "...                         ...   \n",
       "12855429         Juan Gutierrez   \n",
       "12855430    Ashley Houston-King   \n",
       "12855431          Cliff Freeman   \n",
       "12855432   Katherine K. Frankel   \n",
       "12855433              Ryan Cain   \n",
       "\n",
       "                                                  coauthors  \\\n",
       "0                                           Xiaolin Hu 0002   \n",
       "1                                           Xiaolin Hu 0002   \n",
       "2                             Minghao Wang, Xiaolin Hu 0002   \n",
       "3                                           Xiaolin Hu 0002   \n",
       "4                                           Xiaolin Hu 0002   \n",
       "...                                                     ...   \n",
       "12855429   Ashley Houston-King, Cliff Freeman, Eli Tucke...   \n",
       "12855430   Cliff Freeman, Eli Tucker-Raymond, Katherine ...   \n",
       "12855431   Ashley Houston-King, Eli Tucker-Raymond, Kath...   \n",
       "12855432   Ashley Houston-King, Cliff Freeman, Eli Tucke...   \n",
       "12855433                                      Victor R. Lee   \n",
       "\n",
       "                            source  year  \\\n",
       "0                  SpringSim (TMS)  2018   \n",
       "1                              IAT  2013   \n",
       "2                  SpringSim (ADS)  2015   \n",
       "3                              WSC  2017   \n",
       "4                          COMPSAC  2016   \n",
       "...                            ...   ...   \n",
       "12855429  FabLearn/Constructionism  2023   \n",
       "12855430  FabLearn/Constructionism  2023   \n",
       "12855431  FabLearn/Constructionism  2023   \n",
       "12855432  FabLearn/Constructionism  2023   \n",
       "12855433                  FabLearn  2016   \n",
       "\n",
       "                                                      title  \\\n",
       "0         Hybrid agent-based and graph-based modeling fo...   \n",
       "1         Behavior Pattern Detection for Data Assimilati...   \n",
       "2         A graph-based agent-oriented model for buildin...   \n",
       "3         Data assimilation with sensor-informed resampl...   \n",
       "4         Graph Based Agent Oriented Model for Tunnel Si...   \n",
       "...                                                     ...   \n",
       "12855429  Youth Pedagogical Development in Youth Teachin...   \n",
       "12855430  Youth Pedagogical Development in Youth Teachin...   \n",
       "12855431  Youth Pedagogical Development in Youth Teachin...   \n",
       "12855432  Youth Pedagogical Development in Youth Teachin...   \n",
       "12855433  Measuring Electrodermal Activity to Capture En...   \n",
       "\n",
       "                                                doi  \n",
       "0         http://dl.acm.org/citation.cfm?id=3213189  \n",
       "1           https://doi.org/10.1109/WI-IAT.2013.106  \n",
       "2         http://dl.acm.org/citation.cfm?id=2872548  \n",
       "3          https://doi.org/10.1109/WSC.2017.8247862  \n",
       "4          https://doi.org/10.1109/COMPSAC.2016.223  \n",
       "...                                             ...  \n",
       "12855429    https://doi.org/10.1145/3615430.3615444  \n",
       "12855430    https://doi.org/10.1145/3615430.3615444  \n",
       "12855431    https://doi.org/10.1145/3615430.3615444  \n",
       "12855432    https://doi.org/10.1145/3615430.3615444  \n",
       "12855433    https://doi.org/10.1145/3003397.3003409  \n",
       "\n",
       "[12855434 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75f29d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ego</th>\n",
       "      <th>coauthors</th>\n",
       "      <th>source</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kodai Shimosato</td>\n",
       "      <td>Norimichi Ukita</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2024</td>\n",
       "      <td>Inpainting-Driven Mask Optimization for Object...</td>\n",
       "      <td>https://doi.org/10.48550/arXiv.2403.15849</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kodai Shimosato</td>\n",
       "      <td>Norimichi Ukita</td>\n",
       "      <td>IEEE Access</td>\n",
       "      <td>2021</td>\n",
       "      <td>Multi-Modal Data Fusion for Land-Subsidence Im...</td>\n",
       "      <td>https://doi.org/10.1109/ACCESS.2021.3120133</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norimichi Ukita</td>\n",
       "      <td>Kodai Shimosato</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2024</td>\n",
       "      <td>Inpainting-Driven Mask Optimization for Object...</td>\n",
       "      <td>https://doi.org/10.48550/arXiv.2403.15849</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norimichi Ukita</td>\n",
       "      <td>Arnau Raventos, Aryan Esfandiari, C. Victor J...</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2020</td>\n",
       "      <td>AIM 2020 Challenge on Video Extreme Super-Reso...</td>\n",
       "      <td>https://arxiv.org/abs/2009.06290</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norimichi Ukita</td>\n",
       "      <td>Kazutoshi Akita,Kyotaro Tokoro</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2024</td>\n",
       "      <td>Burst Super-Resolution with Diffusion Models f...</td>\n",
       "      <td>https://doi.org/10.48550/arXiv.2403.19428</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26701427</th>\n",
       "      <td>Juan Gutierrez</td>\n",
       "      <td>Ashley Houston-King, Cliff Freeman, Eli Tucke...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "      <td>https://doi.org/10.1145/3615430.3615444</td>\n",
       "      <td>inp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26701428</th>\n",
       "      <td>Ashley Houston-King</td>\n",
       "      <td>Cliff Freeman, Eli Tucker-Raymond, Katherine ...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "      <td>https://doi.org/10.1145/3615430.3615444</td>\n",
       "      <td>inp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26701429</th>\n",
       "      <td>Cliff Freeman</td>\n",
       "      <td>Ashley Houston-King, Eli Tucker-Raymond, Kath...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "      <td>https://doi.org/10.1145/3615430.3615444</td>\n",
       "      <td>inp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26701430</th>\n",
       "      <td>Katherine K. Frankel</td>\n",
       "      <td>Ashley Houston-King, Cliff Freeman, Eli Tucke...</td>\n",
       "      <td>FabLearn/Constructionism</td>\n",
       "      <td>2023</td>\n",
       "      <td>Youth Pedagogical Development in Youth Teachin...</td>\n",
       "      <td>https://doi.org/10.1145/3615430.3615444</td>\n",
       "      <td>inp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26701431</th>\n",
       "      <td>Ryan Cain</td>\n",
       "      <td>Victor R. Lee</td>\n",
       "      <td>FabLearn</td>\n",
       "      <td>2016</td>\n",
       "      <td>Measuring Electrodermal Activity to Capture En...</td>\n",
       "      <td>https://doi.org/10.1145/3003397.3003409</td>\n",
       "      <td>inp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26701432 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ego  \\\n",
       "0               Kodai Shimosato   \n",
       "1               Kodai Shimosato   \n",
       "2               Norimichi Ukita   \n",
       "3               Norimichi Ukita   \n",
       "4               Norimichi Ukita   \n",
       "...                         ...   \n",
       "26701427         Juan Gutierrez   \n",
       "26701428    Ashley Houston-King   \n",
       "26701429          Cliff Freeman   \n",
       "26701430   Katherine K. Frankel   \n",
       "26701431              Ryan Cain   \n",
       "\n",
       "                                                  coauthors  \\\n",
       "0                                           Norimichi Ukita   \n",
       "1                                           Norimichi Ukita   \n",
       "2                                           Kodai Shimosato   \n",
       "3          Arnau Raventos, Aryan Esfandiari, C. Victor J...   \n",
       "4                            Kazutoshi Akita,Kyotaro Tokoro   \n",
       "...                                                     ...   \n",
       "26701427   Ashley Houston-King, Cliff Freeman, Eli Tucke...   \n",
       "26701428   Cliff Freeman, Eli Tucker-Raymond, Katherine ...   \n",
       "26701429   Ashley Houston-King, Eli Tucker-Raymond, Kath...   \n",
       "26701430   Ashley Houston-King, Cliff Freeman, Eli Tucke...   \n",
       "26701431                                      Victor R. Lee   \n",
       "\n",
       "                            source  year  \\\n",
       "0                             CoRR  2024   \n",
       "1                      IEEE Access  2021   \n",
       "2                             CoRR  2024   \n",
       "3                             CoRR  2020   \n",
       "4                             CoRR  2024   \n",
       "...                            ...   ...   \n",
       "26701427  FabLearn/Constructionism  2023   \n",
       "26701428  FabLearn/Constructionism  2023   \n",
       "26701429  FabLearn/Constructionism  2023   \n",
       "26701430  FabLearn/Constructionism  2023   \n",
       "26701431                  FabLearn  2016   \n",
       "\n",
       "                                                      title  \\\n",
       "0         Inpainting-Driven Mask Optimization for Object...   \n",
       "1         Multi-Modal Data Fusion for Land-Subsidence Im...   \n",
       "2         Inpainting-Driven Mask Optimization for Object...   \n",
       "3         AIM 2020 Challenge on Video Extreme Super-Reso...   \n",
       "4         Burst Super-Resolution with Diffusion Models f...   \n",
       "...                                                     ...   \n",
       "26701427  Youth Pedagogical Development in Youth Teachin...   \n",
       "26701428  Youth Pedagogical Development in Youth Teachin...   \n",
       "26701429  Youth Pedagogical Development in Youth Teachin...   \n",
       "26701430  Youth Pedagogical Development in Youth Teachin...   \n",
       "26701431  Measuring Electrodermal Activity to Capture En...   \n",
       "\n",
       "                                                  doi Type  \n",
       "0           https://doi.org/10.48550/arXiv.2403.15849  art  \n",
       "1         https://doi.org/10.1109/ACCESS.2021.3120133  art  \n",
       "2           https://doi.org/10.48550/arXiv.2403.15849  art  \n",
       "3                    https://arxiv.org/abs/2009.06290  art  \n",
       "4           https://doi.org/10.48550/arXiv.2403.19428  art  \n",
       "...                                               ...  ...  \n",
       "26701427      https://doi.org/10.1145/3615430.3615444  inp  \n",
       "26701428      https://doi.org/10.1145/3615430.3615444  inp  \n",
       "26701429      https://doi.org/10.1145/3615430.3615444  inp  \n",
       "26701430      https://doi.org/10.1145/3615430.3615444  inp  \n",
       "26701431      https://doi.org/10.1145/3003397.3003409  inp  \n",
       "\n",
       "[26701432 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_df[\"Type\"]=\"art\"\n",
    "inp_df[\"Type\"]=\"inp\"\n",
    "ego_df=pd.concat([art_df,inp_df], axis=0, ignore_index=True)\n",
    "ego_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abaa6385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ego</th>\n",
       "      <th>coauthors</th>\n",
       "      <th>source</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kodai Shimosato</td>\n",
       "      <td>Norimichi Ukita</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2024</td>\n",
       "      <td>Inpainting-Driven Mask Optimization for Object...</td>\n",
       "      <td>https://doi.org/10.48550/arXiv.2403.15849</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kodai Shimosato</td>\n",
       "      <td>Norimichi Ukita</td>\n",
       "      <td>IEEE Access</td>\n",
       "      <td>2021</td>\n",
       "      <td>Multi-Modal Data Fusion for Land-Subsidence Im...</td>\n",
       "      <td>https://doi.org/10.1109/ACCESS.2021.3120133</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norimichi Ukita</td>\n",
       "      <td>Kodai Shimosato</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2024</td>\n",
       "      <td>Inpainting-Driven Mask Optimization for Object...</td>\n",
       "      <td>https://doi.org/10.48550/arXiv.2403.15849</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norimichi Ukita</td>\n",
       "      <td>Arnau Raventos, Aryan Esfandiari, C. Victor J...</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2020</td>\n",
       "      <td>AIM 2020 Challenge on Video Extreme Super-Reso...</td>\n",
       "      <td>https://arxiv.org/abs/2009.06290</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norimichi Ukita</td>\n",
       "      <td>Kazutoshi Akita,Kyotaro Tokoro</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2024</td>\n",
       "      <td>Burst Super-Resolution with Diffusion Models f...</td>\n",
       "      <td>https://doi.org/10.48550/arXiv.2403.19428</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28630100</th>\n",
       "      <td>Geetanjali R. Kamath</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28630101</th>\n",
       "      <td>Shigeaki Matsuoka</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28630102</th>\n",
       "      <td>Martin Koppers</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28630103</th>\n",
       "      <td>Ehren Dohler</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28630104</th>\n",
       "      <td>G. J. ter Maat</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28630105 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ego  \\\n",
       "0              Kodai Shimosato   \n",
       "1              Kodai Shimosato   \n",
       "2              Norimichi Ukita   \n",
       "3              Norimichi Ukita   \n",
       "4              Norimichi Ukita   \n",
       "...                        ...   \n",
       "28630100  Geetanjali R. Kamath   \n",
       "28630101     Shigeaki Matsuoka   \n",
       "28630102        Martin Koppers   \n",
       "28630103          Ehren Dohler   \n",
       "28630104        G. J. ter Maat   \n",
       "\n",
       "                                                  coauthors       source  \\\n",
       "0                                           Norimichi Ukita         CoRR   \n",
       "1                                           Norimichi Ukita  IEEE Access   \n",
       "2                                           Kodai Shimosato         CoRR   \n",
       "3          Arnau Raventos, Aryan Esfandiari, C. Victor J...         CoRR   \n",
       "4                            Kazutoshi Akita,Kyotaro Tokoro         CoRR   \n",
       "...                                                     ...          ...   \n",
       "28630100                                                             NaN   \n",
       "28630101                                                             NaN   \n",
       "28630102                                                             NaN   \n",
       "28630103                                                             NaN   \n",
       "28630104                                                             NaN   \n",
       "\n",
       "          year                                              title  \\\n",
       "0         2024  Inpainting-Driven Mask Optimization for Object...   \n",
       "1         2021  Multi-Modal Data Fusion for Land-Subsidence Im...   \n",
       "2         2024  Inpainting-Driven Mask Optimization for Object...   \n",
       "3         2020  AIM 2020 Challenge on Video Extreme Super-Reso...   \n",
       "4         2024  Burst Super-Resolution with Diffusion Models f...   \n",
       "...        ...                                                ...   \n",
       "28630100   NaN                                                NaN   \n",
       "28630101   NaN                                                NaN   \n",
       "28630102   NaN                                                NaN   \n",
       "28630103   NaN                                                NaN   \n",
       "28630104   NaN                                                NaN   \n",
       "\n",
       "                                                  doi Type  \n",
       "0           https://doi.org/10.48550/arXiv.2403.15849  art  \n",
       "1         https://doi.org/10.1109/ACCESS.2021.3120133  art  \n",
       "2           https://doi.org/10.48550/arXiv.2403.15849  art  \n",
       "3                    https://arxiv.org/abs/2009.06290  art  \n",
       "4           https://doi.org/10.48550/arXiv.2403.19428  art  \n",
       "...                                               ...  ...  \n",
       "28630100                                          NaN  NaN  \n",
       "28630101                                          NaN  NaN  \n",
       "28630102                                          NaN  NaN  \n",
       "28630103                                          NaN  NaN  \n",
       "28630104                                          NaN  NaN  \n",
       "\n",
       "[28630105 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seek coauthors that do not appear as egos\n",
    "\n",
    "ego_set = set(ego_df['ego'])\n",
    "\n",
    "coauthor_set = set()\n",
    "for coauthor_str in ego_df['coauthors']:\n",
    "    if pd.notna(coauthor_str) and coauthor_str != '':\n",
    "        coauthor_set.update([c.strip() for c in coauthor_str.split(',')])\n",
    "\n",
    "missing_egos = coauthor_set - ego_set\n",
    "\n",
    "if missing_egos:\n",
    "    new_rows = pd.DataFrame({\n",
    "        'ego': list(missing_egos),\n",
    "        'coauthors': [''] * len(missing_egos)\n",
    "    })\n",
    "    ego_df = pd.concat([ego_df, new_rows], ignore_index=True)\n",
    "\n",
    "ego_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca2cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ego</th>\n",
       "      <th>coauthors</th>\n",
       "      <th>source</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>Type</th>\n",
       "      <th>ego_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Zheyuan Hu</td>\n",
       "      <td>Ameya D. Jagtap, George Em Karniadakis, Kenji...</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2021</td>\n",
       "      <td>When Do Extended Physics-Informed Neural Netwo...</td>\n",
       "      <td>https://arxiv.org/abs/2109.09444</td>\n",
       "      <td>art</td>\n",
       "      <td>0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Zheyuan Hu</td>\n",
       "      <td>George Em Karniadakis, Kenji Kawaguchi, Khemr...</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2023</td>\n",
       "      <td>Tackling the Curse of Dimensionality with Phys...</td>\n",
       "      <td>https://doi.org/10.48550/arXiv.2307.12306</td>\n",
       "      <td>art</td>\n",
       "      <td>0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Zheyuan Hu</td>\n",
       "      <td>Ameya D. Jagtap, George Em Karniadakis, Kenji...</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2022</td>\n",
       "      <td>Augmented Physics-Informed Neural Networks (AP...</td>\n",
       "      <td>https://doi.org/10.48550/arXiv.2211.08939</td>\n",
       "      <td>art</td>\n",
       "      <td>0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Zheyuan Hu</td>\n",
       "      <td>Ameya D. Jagtap, George Em Karniadakis, Kenji...</td>\n",
       "      <td>SIAM J. Sci. Comput.</td>\n",
       "      <td>2022</td>\n",
       "      <td>When Do Extended Physics-Informed Neural Netwo...</td>\n",
       "      <td>https://doi.org/10.1137/21m1447039</td>\n",
       "      <td>art</td>\n",
       "      <td>0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Zheyuan Hu</td>\n",
       "      <td>George E. Karniadakis, Kenji Kawaguchi, Zhong...</td>\n",
       "      <td>SIAM J. Sci. Comput.</td>\n",
       "      <td>2025</td>\n",
       "      <td>Score-Based Physics-Informed Neural Networks f...</td>\n",
       "      <td>https://doi.org/10.1137/24m1638768</td>\n",
       "      <td>art</td>\n",
       "      <td>0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28629841</th>\n",
       "      <td>Jun Cui</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28629859</th>\n",
       "      <td>Jianfeng Liu</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28629942</th>\n",
       "      <td>Kun Zhao</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28630016</th>\n",
       "      <td>James Chapman</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28630054</th>\n",
       "      <td>Xiao Wang</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2493668 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ego                                          coauthors  \\\n",
       "65           Zheyuan Hu    Ameya D. Jagtap, George Em Karniadakis, Kenji...   \n",
       "66           Zheyuan Hu    George Em Karniadakis, Kenji Kawaguchi, Khemr...   \n",
       "67           Zheyuan Hu    Ameya D. Jagtap, George Em Karniadakis, Kenji...   \n",
       "68           Zheyuan Hu    Ameya D. Jagtap, George Em Karniadakis, Kenji...   \n",
       "69           Zheyuan Hu    George E. Karniadakis, Kenji Kawaguchi, Zhong...   \n",
       "...                  ...                                                ...   \n",
       "28629841        Jun Cui                                                       \n",
       "28629859   Jianfeng Liu                                                       \n",
       "28629942       Kun Zhao                                                       \n",
       "28630016  James Chapman                                                       \n",
       "28630054      Xiao Wang                                                       \n",
       "\n",
       "                        source  year  \\\n",
       "65                        CoRR  2021   \n",
       "66                        CoRR  2023   \n",
       "67                        CoRR  2022   \n",
       "68        SIAM J. Sci. Comput.  2022   \n",
       "69        SIAM J. Sci. Comput.  2025   \n",
       "...                        ...   ...   \n",
       "28629841                   NaN   NaN   \n",
       "28629859                   NaN   NaN   \n",
       "28629942                   NaN   NaN   \n",
       "28630016                   NaN   NaN   \n",
       "28630054                   NaN   NaN   \n",
       "\n",
       "                                                      title  \\\n",
       "65        When Do Extended Physics-Informed Neural Netwo...   \n",
       "66        Tackling the Curse of Dimensionality with Phys...   \n",
       "67        Augmented Physics-Informed Neural Networks (AP...   \n",
       "68        When Do Extended Physics-Informed Neural Netwo...   \n",
       "69        Score-Based Physics-Informed Neural Networks f...   \n",
       "...                                                     ...   \n",
       "28629841                                                NaN   \n",
       "28629859                                                NaN   \n",
       "28629942                                                NaN   \n",
       "28630016                                                NaN   \n",
       "28630054                                                NaN   \n",
       "\n",
       "                                                doi Type ego_number  \n",
       "65                 https://arxiv.org/abs/2109.09444  art       0002  \n",
       "66        https://doi.org/10.48550/arXiv.2307.12306  art       0002  \n",
       "67        https://doi.org/10.48550/arXiv.2211.08939  art       0002  \n",
       "68               https://doi.org/10.1137/21m1447039  art       0002  \n",
       "69               https://doi.org/10.1137/24m1638768  art       0002  \n",
       "...                                             ...  ...        ...  \n",
       "28629841                                        NaN  NaN       0002  \n",
       "28629859                                        NaN  NaN       0003  \n",
       "28629942                                        NaN  NaN       0011  \n",
       "28630016                                        NaN  NaN       0003  \n",
       "28630054                                        NaN  NaN       0027  \n",
       "\n",
       "[2493668 rows x 8 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "ego_df[\"ego_number\"]=ego_df[\"ego\"].apply(lambda x: re.findall(r'\\d+',x))\n",
    "ego_df[\"ego_number\"]=ego_df[\"ego_number\"].str[0]\n",
    "ego_df[\"ego\"]=ego_df[\"ego\"].apply(lambda x: re.sub(r\"\\d\",\"\",x))\n",
    "ego_df[\"name\"]=ego_df[\"ego\"].str.lstrip().str.split(\" \").str[0].str.lower()\n",
    "ego_df[~ego_df[\"ego_number\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "810db5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with fs.open(\"s3://lab/main_df.parquet\", 'wb') as f:\n",
    "    ego_df.to_parquet(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7e84aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ego_df[\"name\"]=np.where(len(ego_df[\"ego\"].str.split())>1, ego_df[\"ego\"].str.split(n=1).str[0], None)\n",
    "def is_valid_firstname(word):\n",
    "    if not isinstance(word, str):  # skip NaN/None\n",
    "        return False\n",
    "    if len(word) == 1:  # single letter\n",
    "        return False\n",
    "    if word.isupper():  # all caps (acronyms)\n",
    "        return False\n",
    "    if not re.match(r'^[A-Za-z-]+$', word):  # contains only letters or hyphens\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "ego_df[\"name\"] = ego_df[\"name\"].apply(lambda x: x if is_valid_firstname(x) else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99995cd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ego_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ego_df[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m]=\u001b[43mego_df\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mego\u001b[39m\u001b[33m\"\u001b[39m].str.lstrip().str.split(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m).str[\u001b[32m0\u001b[39m].str.lower()\n",
      "\u001b[31mNameError\u001b[39m: name 'ego_df' is not defined"
     ]
    }
   ],
   "source": [
    "ego_df[\"name\"]=ego_df[\"ego\"].str.lstrip().str.split(\" \").str[0].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5bdac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "names=names.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df5bc00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_df.to_parquet(\"ego_df.parquet\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "779e4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fs.open(\"s3://lab/name_gender_dataset.csv\") as f:\n",
    "    g1 = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/wgnd_2_0_name-gender-langcode.csv\") as f:\n",
    "    g2 = pd.read_csv(f)\n",
    "\n",
    "g1=g1[[\"Name\",\"Gender\"]]\n",
    "g2[[\"Name\",\"Gender\"]]=g2[[\"name\",\"gender\"]]\n",
    "g2=g2[[\"Name\",\"Gender\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4106024c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>a laura</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>a lelia</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>a lelia</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>a lerah</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>a lerah</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>a lex ander</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>a lex ander</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>a lie</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>a lisa</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>a lisa</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>a liza</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>a liza</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>a lmos</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>a luan</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>a mang</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>a me</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>a men</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>a mer</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>a mer</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>a merie</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>a merie</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>a mou</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>a nai</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>a nak la</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>a nak la</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>a nao</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>a neng</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>a nette</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>a niang</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>a niyah</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>a niyah</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>a nv</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>a ou</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>a pan</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>a pao</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>a pi</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>a pu</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>a qie</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>a qiong</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>a que</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>a ran</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>a rang</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>a rao</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>a re</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>a ri</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>a rin</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>a rin</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>a ron</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>a ron</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>a s m</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name Gender\n",
       "100      a laura      F\n",
       "101      a lelia      F\n",
       "102      a lelia      F\n",
       "103      a lerah      F\n",
       "104      a lerah      F\n",
       "105  a lex ander      M\n",
       "106  a lex ander      M\n",
       "107        a lie      M\n",
       "108       a lisa      F\n",
       "109       a lisa      F\n",
       "110       a liza      F\n",
       "111       a liza      F\n",
       "112       a lmos      M\n",
       "113       a luan      M\n",
       "114       a mang      F\n",
       "115         a me      F\n",
       "116        a men      M\n",
       "117        a mer      M\n",
       "118        a mer      M\n",
       "119      a merie      F\n",
       "120      a merie      F\n",
       "121        a mou      M\n",
       "122        a nai      F\n",
       "123     a nak la      M\n",
       "124     a nak la      M\n",
       "125        a nao      F\n",
       "126       a neng      M\n",
       "127      a nette      F\n",
       "128      a niang      F\n",
       "129      a niyah      F\n",
       "130      a niyah      F\n",
       "131         a nv      F\n",
       "132         a ou      M\n",
       "133        a pan      F\n",
       "134        a pao      M\n",
       "135         a pi      M\n",
       "136         a pu      F\n",
       "137        a qie      M\n",
       "138      a qiong      F\n",
       "139        a que      M\n",
       "140        a ran      M\n",
       "141       a rang      M\n",
       "142        a rao      F\n",
       "143         a re      F\n",
       "144         a ri      M\n",
       "145        a rin      F\n",
       "146        a rin      F\n",
       "147        a ron      M\n",
       "148        a ron      M\n",
       "149        a s m      M"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "add36b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>William</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978307</th>\n",
       "      <td>히카리</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978308</th>\n",
       "      <td>히토미</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978309</th>\n",
       "      <td>힘찬</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978310</th>\n",
       "      <td>凉峰</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978311</th>\n",
       "      <td>凉翼</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21978312 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name Gender\n",
       "0           James      M\n",
       "1            John      M\n",
       "2          Robert      M\n",
       "3         Michael      M\n",
       "4         William      M\n",
       "...           ...    ...\n",
       "21978307      히카리      F\n",
       "21978308      히토미      F\n",
       "21978309       힘찬      M\n",
       "21978310       凉峰      M\n",
       "21978311       凉翼      M\n",
       "\n",
       "[21978312 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([g1,g2],axis=0,ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
