{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af2bfca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /opt/python/lib/python3.13/site-packages (6.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lxml\n",
    "#%pip install rdflib\n",
    "import os\n",
    "import s3fs\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = 'PVZT77T3X1860L6FCJFG'\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = '8Uq1Hnf5y5f5K47efWXkZJ6kdQiyOy9IBa5D9MnN'\n",
    "os.environ[\"AWS_SESSION_TOKEN\"] = 'eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NLZXkiOiJQVlpUNzdUM1gxODYwTDZGQ0pGRyIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sImF1ZCI6WyJtaW5pby1kYXRhbm9kZSIsIm9ueXhpYSIsImFjY291bnQiXSwiYXV0aF90aW1lIjoxNzY5NjEyMTg2LCJhenAiOiJvbnl4aWEiLCJlbWFpbCI6Imx1Y2FzLmN1bXVuZWxAZW5zYWUuZnIiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZXhwIjoxNzcxMzE1NTA1LCJmYW1pbHlfbmFtZSI6IkN1bXVuZWwiLCJnaXZlbl9uYW1lIjoiTHVjYXMiLCJncm91cHMiOlsiVVNFUl9PTllYSUEiLCJzdGF0YXBwLXNlZ21lZGljIl0sImlhdCI6MTc3MDcxMDcwNSwiaXNzIjoiaHR0cHM6Ly9hdXRoLmxhYi5zc3BjbG91ZC5mci9hdXRoL3JlYWxtcy9zc3BjbG91ZCIsImp0aSI6Im9ucnRydDo1ZjM1MWE3MS03NTIwLWYyNjYtNjBjOS1iYWY5NjYzMTEyYjciLCJuYW1lIjoiTHVjYXMgQ3VtdW5lbCIsInBvbGljeSI6InN0c29ubHkiLCJwcmVmZXJyZWRfdXNlcm5hbWUiOiJsYWIiLCJyZWFsbV9hY2Nlc3MiOnsicm9sZXMiOlsib2ZmbGluZV9hY2Nlc3MiLCJ1bWFfYXV0aG9yaXphdGlvbiIsImRlZmF1bHQtcm9sZXMtc3NwY2xvdWQiXX0sInJlc291cmNlX2FjY2VzcyI6eyJhY2NvdW50Ijp7InJvbGVzIjpbIm1hbmFnZS1hY2NvdW50IiwibWFuYWdlLWFjY291bnQtbGlua3MiLCJ2aWV3LXByb2ZpbGUiXX19LCJyb2xlcyI6WyJvZmZsaW5lX2FjY2VzcyIsInVtYV9hdXRob3JpemF0aW9uIiwiZGVmYXVsdC1yb2xlcy1zc3BjbG91ZCJdLCJzY29wZSI6Im9wZW5pZCBwcm9maWxlIGdyb3VwcyBlbWFpbCIsInNpZCI6Ijc4ODAyYmFkLTFjZTEtODFkOC1mYjI4LTQwNWY4MWQ0ZGVmNSIsInN1YiI6ImUyZDc4NjRjLTcwMzItNDI0ZC04OTA2LWU0ZjhiNDFjYzAwMyIsInR5cCI6IkJlYXJlciJ9.Dlw2Tbo6kDKyKT70uHQjFhqBaOTtzYXw5t9pKQu7I-GxTbbL_qo7AMAHIWUfsPj-l4JDZUf6RabEsg-Rx3A39g'\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = 'us-east-1'\n",
    "fs = s3fs.S3FileSystem(\n",
    "    client_kwargs={'endpoint_url': 'https://'+'minio.lab.sspcloud.fr'},\n",
    "    key = os.environ[\"AWS_ACCESS_KEY_ID\"], \n",
    "    secret = os.environ[\"AWS_SECRET_ACCESS_KEY\"], \n",
    "    token = os.environ[\"AWS_SESSION_TOKEN\"])\n",
    "\n",
    "path = \"lab/dblp (1).xml.gz\"\n",
    "dtd_path = \"lab/dblp.dtd\"\n",
    "rdf_path=\"lab/dblp.nt.gz\"\n",
    "\n",
    "with fs.open(\"s3://lab/conf_net_dec.parquet\") as f:\n",
    "    df = pd.read_parquet(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b009560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from lxml import etree\n",
    "import gzip\n",
    "\n",
    "articles = []\n",
    "\n",
    "with fs.open(path, 'rb') as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        # Set up parser to load DTD and resolve entities\n",
    "        # DBLP header encoding\n",
    "    \n",
    "\n",
    "        context = etree.iterparse(\n",
    "            gz,\n",
    "            events=(\"end\",),\n",
    "            tag=\"inproceedings\",       # load external DTD\n",
    "            resolve_entities=False,  # replace named entities like &eacute;\n",
    "            recover=True\n",
    "        )\n",
    "\n",
    "        for event, elem in context:\n",
    "            raw_xml = etree.tostring(elem, encoding=\"unicode\", with_tail=False)\n",
    "\n",
    "            # Extract content between tags manually\n",
    "            def extract_tag(tag):\n",
    "                m = re.search(rf\"<{tag}>(.*?)</{tag}>\", raw_xml, re.DOTALL)\n",
    "                return m.group(1) if m else None\n",
    "\n",
    "            title = extract_tag(\"title\")\n",
    "            conf  = extract_tag(\"booktitle\")\n",
    "            year  = extract_tag(\"year\")\n",
    "            doi   = extract_tag(\"ee\")\n",
    "\n",
    "            authors_raw = re.findall(r\"<author>(.*?)</author>\", raw_xml)\n",
    "            authors = [{\"name\": a, \"orcid\": None} for a in authors_raw]\n",
    "\n",
    "            articles.append({\n",
    "                \"title\": title,\n",
    "                \"conf\": conf,\n",
    "                \"year\": year,\n",
    "                \"authors\": authors,\n",
    "                \"dblp_uri\": elem.get(\"key\"),\n",
    "                \"doi\": doi\n",
    "            })\n",
    "\n",
    "            elem.clear()\n",
    "            while elem.getprevious() is not None:\n",
    "                del elem.getparent()[0]\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89915f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "# Function to decode entities in a string or None\n",
    "def decode_entities(s):\n",
    "    if s is None:\n",
    "        return None\n",
    "    return html.unescape(s)\n",
    "\n",
    "# Apply to your DataFrame\n",
    "for col in [\"title\", \"journal\", \"doi\"]:\n",
    "    df[col] = df[col].apply(decode_entities)\n",
    "\n",
    "# Authors\n",
    "for i, row in df.iterrows():\n",
    "    for a in row[\"authors\"]:\n",
    "        a[\"name\"] = decode_entities(a[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e9702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>conf</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>dblp_uri</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Future of Classic Data Administration: Obj...</td>\n",
       "      <td>SWEE</td>\n",
       "      <td>1998</td>\n",
       "      <td>[{'name': 'Arnon Rosenthal', 'orcid': None}]</td>\n",
       "      <td>www/org/mitre/future</td>\n",
       "      <td>http://www.mitre.org/support/swee/rosenthal.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Some Patterns of Convincing Software Engineeri...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>[{'name': 'Lutz Prechelt', 'orcid': None}]</td>\n",
       "      <td>books/sp/22/Prechelt22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Static Worst-Case Analyses and Their Validatio...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>[{'name': 'Peter W&amp;auml;gemann', 'orcid': None}]</td>\n",
       "      <td>books/sp/22/Wagemann22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crossing Disciplinary Borders to Improve Requi...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>[{'name': 'Anne Hess', 'orcid': None}]</td>\n",
       "      <td>books/sp/22/Hess22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What You See Is What You Get: Practical Effect...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>[]</td>\n",
       "      <td>books/sp/22/Brachthauser22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749511</th>\n",
       "      <td>Toward a Modern Geography of Minds, Machines, ...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>[{'name': 'Selmer Bringsjord', 'orcid': None},...</td>\n",
       "      <td>series/sapere/BringsjordG13</td>\n",
       "      <td>https://doi.org/10.1007/978-3-642-31674-6_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749512</th>\n",
       "      <td>Emotional Control-Conditio Sine Qua Non for Ad...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>[]</td>\n",
       "      <td>series/sapere/Gros13</td>\n",
       "      <td>https://doi.org/10.1007/978-3-642-31674-6_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749513</th>\n",
       "      <td>Becoming Digital: Reconciling Theories of Digi...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>[{'name': 'Harry Halpin', 'orcid': None}]</td>\n",
       "      <td>series/sapere/Halpin13</td>\n",
       "      <td>https://doi.org/10.1007/978-3-642-31674-6_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749514</th>\n",
       "      <td>Generative Artificial Intelligence.</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>[{'name': 'Tijn van der Zant', 'orcid': None},...</td>\n",
       "      <td>series/sapere/ZantKS13</td>\n",
       "      <td>https://doi.org/10.1007/978-3-642-31674-6_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749515</th>\n",
       "      <td>Seven Steps to Rendezvous with the Casual User.</td>\n",
       "      <td>IFIP Working Conference Data Base Management</td>\n",
       "      <td>1974</td>\n",
       "      <td>[{'name': 'E. F. Codd', 'orcid': None}]</td>\n",
       "      <td>persons/Codd74</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3749516 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  \\\n",
       "0        The Future of Classic Data Administration: Obj...   \n",
       "1        Some Patterns of Convincing Software Engineeri...   \n",
       "2        Static Worst-Case Analyses and Their Validatio...   \n",
       "3        Crossing Disciplinary Borders to Improve Requi...   \n",
       "4        What You See Is What You Get: Practical Effect...   \n",
       "...                                                    ...   \n",
       "3749511  Toward a Modern Geography of Minds, Machines, ...   \n",
       "3749512  Emotional Control-Conditio Sine Qua Non for Ad...   \n",
       "3749513  Becoming Digital: Reconciling Theories of Digi...   \n",
       "3749514                Generative Artificial Intelligence.   \n",
       "3749515    Seven Steps to Rendezvous with the Casual User.   \n",
       "\n",
       "                                                 conf  year  \\\n",
       "0                                                SWEE  1998   \n",
       "1                                        Denert Award  2020   \n",
       "2                                        Denert Award  2020   \n",
       "3                                        Denert Award  2020   \n",
       "4                                        Denert Award  2020   \n",
       "...                                               ...   ...   \n",
       "3749511                                         PT-AI  2011   \n",
       "3749512                                         PT-AI  2011   \n",
       "3749513                                         PT-AI  2011   \n",
       "3749514                                         PT-AI  2011   \n",
       "3749515  IFIP Working Conference Data Base Management  1974   \n",
       "\n",
       "                                                   authors  \\\n",
       "0             [{'name': 'Arnon Rosenthal', 'orcid': None}]   \n",
       "1               [{'name': 'Lutz Prechelt', 'orcid': None}]   \n",
       "2         [{'name': 'Peter W&auml;gemann', 'orcid': None}]   \n",
       "3                   [{'name': 'Anne Hess', 'orcid': None}]   \n",
       "4                                                       []   \n",
       "...                                                    ...   \n",
       "3749511  [{'name': 'Selmer Bringsjord', 'orcid': None},...   \n",
       "3749512                                                 []   \n",
       "3749513          [{'name': 'Harry Halpin', 'orcid': None}]   \n",
       "3749514  [{'name': 'Tijn van der Zant', 'orcid': None},...   \n",
       "3749515            [{'name': 'E. F. Codd', 'orcid': None}]   \n",
       "\n",
       "                            dblp_uri  \\\n",
       "0               www/org/mitre/future   \n",
       "1             books/sp/22/Prechelt22   \n",
       "2             books/sp/22/Wagemann22   \n",
       "3                 books/sp/22/Hess22   \n",
       "4         books/sp/22/Brachthauser22   \n",
       "...                              ...   \n",
       "3749511  series/sapere/BringsjordG13   \n",
       "3749512         series/sapere/Gros13   \n",
       "3749513       series/sapere/Halpin13   \n",
       "3749514       series/sapere/ZantKS13   \n",
       "3749515               persons/Codd74   \n",
       "\n",
       "                                                      doi  \n",
       "0        http://www.mitre.org/support/swee/rosenthal.html  \n",
       "1                                                    None  \n",
       "2                                                    None  \n",
       "3                                                    None  \n",
       "4                                                    None  \n",
       "...                                                   ...  \n",
       "3749511      https://doi.org/10.1007/978-3-642-31674-6_11  \n",
       "3749512      https://doi.org/10.1007/978-3-642-31674-6_14  \n",
       "3749513      https://doi.org/10.1007/978-3-642-31674-6_15  \n",
       "3749514       https://doi.org/10.1007/978-3-642-31674-6_8  \n",
       "3749515                                              None  \n",
       "\n",
       "[3749516 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45bd5203",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fs.open(\"s3://lab/art_net_dec.parquet\", \"wb\") as f:\n",
    "            df.to_parquet(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2651ca40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1,000,000 lines\n",
      "Processed 2,000,000 lines\n",
      "Processed 3,000,000 lines\n",
      "Processed 4,000,000 lines\n",
      "Processed 5,000,000 lines\n",
      "Processed 6,000,000 lines\n",
      "Processed 7,000,000 lines\n",
      "Processed 8,000,000 lines\n",
      "Processed 9,000,000 lines\n",
      "Processed 10,000,000 lines\n",
      "Processed 11,000,000 lines\n",
      "Processed 12,000,000 lines\n",
      "Processed 13,000,000 lines\n",
      "Processed 14,000,000 lines\n",
      "Processed 15,000,000 lines\n",
      "Processed 16,000,000 lines\n",
      "Processed 17,000,000 lines\n",
      "Processed 18,000,000 lines\n",
      "Processed 19,000,000 lines\n",
      "Processed 20,000,000 lines\n",
      "Processed 21,000,000 lines\n",
      "Processed 22,000,000 lines\n",
      "Processed 23,000,000 lines\n",
      "Processed 24,000,000 lines\n",
      "Processed 25,000,000 lines\n",
      "Processed 26,000,000 lines\n",
      "Processed 27,000,000 lines\n",
      "Processed 28,000,000 lines\n",
      "Processed 29,000,000 lines\n",
      "Processed 30,000,000 lines\n",
      "Processed 31,000,000 lines\n",
      "Processed 32,000,000 lines\n",
      "Processed 33,000,000 lines\n",
      "Processed 34,000,000 lines\n",
      "Processed 35,000,000 lines\n",
      "Processed 36,000,000 lines\n",
      "Processed 37,000,000 lines\n",
      "Processed 38,000,000 lines\n",
      "Processed 39,000,000 lines\n",
      "Processed 40,000,000 lines\n",
      "Processed 41,000,000 lines\n",
      "Processed 42,000,000 lines\n",
      "Processed 43,000,000 lines\n",
      "Processed 44,000,000 lines\n",
      "Processed 45,000,000 lines\n",
      "Processed 46,000,000 lines\n",
      "Processed 47,000,000 lines\n",
      "Processed 48,000,000 lines\n",
      "Processed 49,000,000 lines\n",
      "Processed 50,000,000 lines\n",
      "Processed 51,000,000 lines\n",
      "Processed 53,000,000 lines\n",
      "Processed 54,000,000 lines\n",
      "Processed 55,000,000 lines\n",
      "Processed 56,000,000 lines\n",
      "Processed 57,000,000 lines\n",
      "Processed 58,000,000 lines\n",
      "Processed 59,000,000 lines\n",
      "Processed 60,000,000 lines\n",
      "Processed 61,000,000 lines\n",
      "Processed 62,000,000 lines\n",
      "Processed 63,000,000 lines\n",
      "Processed 64,000,000 lines\n",
      "Processed 65,000,000 lines\n",
      "Processed 66,000,000 lines\n",
      "Processed 67,000,000 lines\n",
      "Processed 68,000,000 lines\n",
      "Processed 69,000,000 lines\n",
      "Processed 70,000,000 lines\n",
      "Processed 71,000,000 lines\n",
      "Processed 72,000,000 lines\n",
      "Processed 73,000,000 lines\n",
      "Processed 74,000,000 lines\n",
      "Processed 75,000,000 lines\n",
      "Processed 76,000,000 lines\n",
      "Processed 77,000,000 lines\n",
      "Processed 78,000,000 lines\n",
      "Processed 79,000,000 lines\n",
      "Processed 80,000,000 lines\n",
      "Processed 81,000,000 lines\n",
      "Processed 82,000,000 lines\n",
      "Processed 83,000,000 lines\n",
      "Processed 84,000,000 lines\n",
      "Processed 85,000,000 lines\n",
      "Processed 86,000,000 lines\n",
      "Processed 87,000,000 lines\n",
      "Processed 88,000,000 lines\n",
      "Processed 89,000,000 lines\n",
      "Processed 90,000,000 lines\n",
      "Processed 91,000,000 lines\n",
      "Processed 92,000,000 lines\n",
      "Processed 93,000,000 lines\n",
      "Processed 94,000,000 lines\n",
      "Processed 95,000,000 lines\n",
      "Processed 96,000,000 lines\n",
      "Processed 97,000,000 lines\n",
      "Processed 98,000,000 lines\n",
      "Processed 99,000,000 lines\n",
      "Processed 100,000,000 lines\n",
      "Processed 101,000,000 lines\n",
      "Processed 102,000,000 lines\n",
      "Processed 103,000,000 lines\n",
      "Processed 104,000,000 lines\n",
      "Processed 105,000,000 lines\n",
      "Processed 106,000,000 lines\n",
      "Processed 107,000,000 lines\n",
      "Processed 108,000,000 lines\n",
      "Processed 109,000,000 lines\n",
      "Processed 110,000,000 lines\n",
      "Processed 111,000,000 lines\n",
      "Processed 112,000,000 lines\n",
      "Processed 113,000,000 lines\n",
      "Processed 115,000,000 lines\n",
      "Processed 116,000,000 lines\n",
      "Processed 117,000,000 lines\n",
      "Processed 118,000,000 lines\n",
      "Processed 119,000,000 lines\n",
      "Processed 120,000,000 lines\n",
      "Processed 121,000,000 lines\n",
      "Processed 122,000,000 lines\n",
      "Processed 123,000,000 lines\n",
      "Processed 124,000,000 lines\n",
      "Processed 125,000,000 lines\n",
      "Processed 126,000,000 lines\n",
      "Processed 127,000,000 lines\n",
      "Processed 128,000,000 lines\n",
      "Processed 129,000,000 lines\n",
      "Processed 130,000,000 lines\n",
      "Processed 131,000,000 lines\n",
      "Processed 132,000,000 lines\n",
      "Processed 133,000,000 lines\n",
      "Processed 134,000,000 lines\n",
      "Processed 135,000,000 lines\n",
      "Processed 136,000,000 lines\n",
      "Processed 137,000,000 lines\n",
      "Processed 138,000,000 lines\n",
      "Processed 139,000,000 lines\n",
      "Processed 140,000,000 lines\n",
      "Processed 141,000,000 lines\n",
      "Processed 142,000,000 lines\n",
      "Processed 143,000,000 lines\n",
      "Processed 144,000,000 lines\n",
      "Processed 145,000,000 lines\n",
      "Processed 146,000,000 lines\n",
      "Processed 147,000,000 lines\n",
      "Processed 148,000,000 lines\n",
      "Processed 149,000,000 lines\n",
      "Processed 150,000,000 lines\n",
      "Processed 151,000,000 lines\n",
      "Processed 152,000,000 lines\n",
      "Processed 153,000,000 lines\n",
      "Processed 155,000,000 lines\n",
      "Processed 156,000,000 lines\n",
      "Processed 157,000,000 lines\n",
      "Processed 158,000,000 lines\n",
      "Processed 159,000,000 lines\n",
      "Processed 160,000,000 lines\n",
      "Processed 161,000,000 lines\n",
      "Processed 162,000,000 lines\n",
      "Processed 163,000,000 lines\n",
      "Processed 164,000,000 lines\n",
      "Processed 165,000,000 lines\n",
      "Processed 166,000,000 lines\n",
      "Processed 167,000,000 lines\n",
      "Processed 168,000,000 lines\n",
      "Processed 169,000,000 lines\n",
      "Processed 170,000,000 lines\n",
      "Processed 171,000,000 lines\n",
      "Processed 172,000,000 lines\n",
      "Processed 173,000,000 lines\n",
      "Processed 174,000,000 lines\n",
      "Processed 175,000,000 lines\n",
      "Processed 176,000,000 lines\n",
      "Processed 177,000,000 lines\n",
      "Processed 178,000,000 lines\n",
      "Processed 179,000,000 lines\n",
      "Processed 180,000,000 lines\n",
      "Processed 182,000,000 lines\n",
      "Processed 183,000,000 lines\n",
      "Processed 184,000,000 lines\n",
      "Processed 185,000,000 lines\n",
      "Processed 186,000,000 lines\n",
      "Processed 187,000,000 lines\n",
      "Processed 188,000,000 lines\n",
      "Processed 189,000,000 lines\n",
      "Processed 190,000,000 lines\n",
      "Processed 191,000,000 lines\n",
      "Processed 192,000,000 lines\n",
      "Processed 193,000,000 lines\n",
      "Processed 194,000,000 lines\n",
      "Processed 195,000,000 lines\n",
      "Processed 196,000,000 lines\n",
      "Processed 197,000,000 lines\n",
      "Processed 198,000,000 lines\n",
      "Processed 199,000,000 lines\n",
      "Processed 200,000,000 lines\n",
      "Processed 201,000,000 lines\n",
      "Processed 202,000,000 lines\n",
      "Processed 203,000,000 lines\n",
      "Processed 204,000,000 lines\n",
      "Processed 205,000,000 lines\n",
      "Processed 206,000,000 lines\n",
      "Processed 207,000,000 lines\n",
      "Processed 208,000,000 lines\n",
      "Processed 209,000,000 lines\n",
      "Processed 210,000,000 lines\n",
      "Processed 211,000,000 lines\n",
      "Processed 212,000,000 lines\n",
      "Processed 213,000,000 lines\n",
      "Processed 214,000,000 lines\n",
      "Processed 215,000,000 lines\n",
      "Processed 216,000,000 lines\n",
      "Processed 217,000,000 lines\n",
      "Processed 218,000,000 lines\n",
      "Processed 219,000,000 lines\n",
      "Processed 220,000,000 lines\n",
      "Processed 221,000,000 lines\n",
      "Processed 222,000,000 lines\n",
      "Processed 223,000,000 lines\n",
      "Processed 224,000,000 lines\n",
      "Processed 225,000,000 lines\n",
      "Processed 226,000,000 lines\n",
      "Processed 227,000,000 lines\n",
      "Processed 228,000,000 lines\n",
      "Processed 229,000,000 lines\n",
      "Processed 230,000,000 lines\n",
      "Processed 231,000,000 lines\n",
      "Processed 232,000,000 lines\n",
      "Processed 233,000,000 lines\n",
      "Processed 234,000,000 lines\n",
      "Processed 235,000,000 lines\n",
      "Processed 236,000,000 lines\n",
      "Processed 237,000,000 lines\n",
      "Processed 238,000,000 lines\n",
      "Processed 239,000,000 lines\n",
      "Processed 241,000,000 lines\n",
      "Processed 242,000,000 lines\n",
      "Processed 243,000,000 lines\n",
      "Processed 244,000,000 lines\n",
      "Processed 245,000,000 lines\n",
      "Processed 247,000,000 lines\n",
      "Processed 248,000,000 lines\n",
      "Processed 249,000,000 lines\n",
      "Processed 250,000,000 lines\n",
      "Processed 251,000,000 lines\n",
      "Processed 252,000,000 lines\n",
      "Processed 253,000,000 lines\n",
      "Processed 254,000,000 lines\n",
      "Processed 255,000,000 lines\n",
      "Processed 256,000,000 lines\n",
      "Processed 257,000,000 lines\n",
      "Processed 258,000,000 lines\n",
      "Processed 259,000,000 lines\n",
      "Processed 261,000,000 lines\n",
      "Processed 262,000,000 lines\n",
      "Processed 263,000,000 lines\n",
      "Processed 264,000,000 lines\n",
      "Processed 265,000,000 lines\n",
      "Processed 266,000,000 lines\n",
      "Processed 267,000,000 lines\n",
      "Processed 268,000,000 lines\n",
      "Processed 269,000,000 lines\n",
      "Processed 270,000,000 lines\n",
      "Processed 271,000,000 lines\n",
      "Processed 272,000,000 lines\n",
      "Processed 273,000,000 lines\n",
      "Processed 274,000,000 lines\n",
      "Processed 275,000,000 lines\n",
      "Processed 276,000,000 lines\n",
      "Processed 277,000,000 lines\n",
      "Processed 278,000,000 lines\n",
      "Processed 279,000,000 lines\n",
      "Processed 280,000,000 lines\n",
      "Processed 281,000,000 lines\n",
      "Processed 282,000,000 lines\n",
      "Processed 283,000,000 lines\n",
      "Processed 284,000,000 lines\n",
      "Processed 285,000,000 lines\n",
      "Processed 286,000,000 lines\n",
      "Processed 287,000,000 lines\n",
      "Processed 288,000,000 lines\n",
      "Processed 289,000,000 lines\n",
      "Processed 290,000,000 lines\n",
      "Processed 291,000,000 lines\n",
      "Processed 292,000,000 lines\n",
      "Processed 293,000,000 lines\n",
      "Processed 294,000,000 lines\n",
      "Processed 295,000,000 lines\n",
      "Processed 296,000,000 lines\n",
      "Processed 297,000,000 lines\n",
      "Processed 298,000,000 lines\n",
      "Processed 299,000,000 lines\n",
      "Processed 300,000,000 lines\n",
      "Processed 301,000,000 lines\n",
      "Processed 302,000,000 lines\n",
      "Processed 303,000,000 lines\n",
      "Processed 304,000,000 lines\n",
      "Processed 305,000,000 lines\n",
      "Processed 306,000,000 lines\n",
      "Processed 307,000,000 lines\n",
      "Processed 308,000,000 lines\n",
      "Processed 309,000,000 lines\n",
      "Processed 310,000,000 lines\n",
      "Processed 311,000,000 lines\n",
      "Processed 312,000,000 lines\n",
      "Processed 313,000,000 lines\n",
      "Processed 314,000,000 lines\n",
      "Processed 315,000,000 lines\n",
      "Processed 316,000,000 lines\n",
      "Processed 317,000,000 lines\n",
      "Processed 318,000,000 lines\n",
      "Processed 319,000,000 lines\n",
      "Processed 320,000,000 lines\n",
      "Processed 321,000,000 lines\n",
      "Processed 322,000,000 lines\n",
      "Processed 323,000,000 lines\n",
      "Processed 324,000,000 lines\n",
      "Processed 325,000,000 lines\n",
      "Processed 326,000,000 lines\n",
      "Processed 327,000,000 lines\n",
      "Processed 328,000,000 lines\n",
      "Processed 329,000,000 lines\n",
      "Processed 330,000,000 lines\n",
      "Processed 331,000,000 lines\n",
      "Processed 332,000,000 lines\n",
      "Processed 333,000,000 lines\n",
      "Processed 334,000,000 lines\n",
      "Processed 335,000,000 lines\n",
      "Processed 336,000,000 lines\n",
      "Processed 337,000,000 lines\n",
      "Processed 338,000,000 lines\n",
      "Processed 339,000,000 lines\n",
      "Processed 340,000,000 lines\n",
      "Processed 341,000,000 lines\n",
      "Processed 342,000,000 lines\n",
      "Processed 343,000,000 lines\n",
      "Processed 344,000,000 lines\n",
      "Processed 345,000,000 lines\n",
      "Processed 346,000,000 lines\n",
      "Processed 347,000,000 lines\n",
      "Processed 348,000,000 lines\n",
      "Processed 349,000,000 lines\n",
      "Processed 350,000,000 lines\n",
      "Processed 351,000,000 lines\n",
      "Processed 352,000,000 lines\n",
      "Processed 353,000,000 lines\n",
      "Processed 354,000,000 lines\n",
      "Processed 355,000,000 lines\n",
      "Processed 356,000,000 lines\n",
      "Processed 357,000,000 lines\n",
      "Processed 358,000,000 lines\n",
      "Processed 359,000,000 lines\n",
      "Processed 360,000,000 lines\n",
      "Processed 361,000,000 lines\n",
      "Processed 362,000,000 lines\n",
      "Processed 363,000,000 lines\n",
      "Processed 364,000,000 lines\n",
      "Processed 365,000,000 lines\n",
      "Processed 366,000,000 lines\n",
      "Processed 367,000,000 lines\n",
      "Processed 368,000,000 lines\n",
      "Processed 369,000,000 lines\n",
      "Processed 370,000,000 lines\n",
      "Processed 371,000,000 lines\n",
      "Processed 372,000,000 lines\n",
      "Processed 373,000,000 lines\n",
      "Processed 374,000,000 lines\n",
      "Processed 375,000,000 lines\n",
      "Processed 376,000,000 lines\n",
      "Processed 377,000,000 lines\n",
      "Processed 378,000,000 lines\n",
      "Processed 379,000,000 lines\n",
      "Processed 380,000,000 lines\n",
      "Processed 381,000,000 lines\n",
      "Processed 382,000,000 lines\n",
      "Processed 383,000,000 lines\n",
      "Processed 384,000,000 lines\n",
      "Processed 385,000,000 lines\n",
      "Processed 386,000,000 lines\n",
      "Processed 387,000,000 lines\n",
      "Processed 388,000,000 lines\n",
      "Processed 389,000,000 lines\n",
      "Processed 390,000,000 lines\n",
      "Processed 391,000,000 lines\n",
      "Processed 392,000,000 lines\n",
      "Processed 393,000,000 lines\n",
      "Processed 394,000,000 lines\n",
      "Processed 395,000,000 lines\n",
      "Processed 396,000,000 lines\n",
      "Processed 397,000,000 lines\n",
      "Processed 398,000,000 lines\n",
      "Processed 399,000,000 lines\n",
      "Processed 400,000,000 lines\n",
      "Processed 401,000,000 lines\n",
      "Processed 402,000,000 lines\n",
      "Processed 403,000,000 lines\n",
      "Processed 404,000,000 lines\n",
      "Processed 405,000,000 lines\n",
      "Processed 406,000,000 lines\n",
      "Processed 407,000,000 lines\n",
      "Processed 408,000,000 lines\n",
      "Processed 410,000,000 lines\n",
      "Processed 411,000,000 lines\n",
      "Processed 412,000,000 lines\n",
      "Processed 413,000,000 lines\n",
      "Processed 414,000,000 lines\n",
      "Processed 415,000,000 lines\n",
      "Processed 416,000,000 lines\n",
      "Processed 417,000,000 lines\n",
      "Processed 418,000,000 lines\n",
      "Processed 419,000,000 lines\n",
      "Processed 420,000,000 lines\n",
      "Processed 421,000,000 lines\n",
      "Processed 422,000,000 lines\n",
      "Processed 423,000,000 lines\n",
      "Processed 424,000,000 lines\n",
      "Processed 425,000,000 lines\n",
      "Processed 426,000,000 lines\n",
      "Processed 427,000,000 lines\n",
      "Processed 428,000,000 lines\n",
      "Processed 429,000,000 lines\n",
      "Processed 430,000,000 lines\n",
      "Processed 432,000,000 lines\n",
      "Processed 433,000,000 lines\n",
      "Processed 434,000,000 lines\n",
      "Processed 435,000,000 lines\n",
      "Processed 436,000,000 lines\n",
      "Processed 437,000,000 lines\n",
      "Processed 438,000,000 lines\n",
      "Processed 439,000,000 lines\n",
      "Processed 440,000,000 lines\n",
      "Processed 441,000,000 lines\n",
      "Processed 442,000,000 lines\n",
      "Processed 443,000,000 lines\n",
      "Processed 444,000,000 lines\n",
      "Processed 445,000,000 lines\n",
      "Processed 446,000,000 lines\n",
      "Processed 447,000,000 lines\n",
      "Processed 448,000,000 lines\n",
      "Processed 449,000,000 lines\n",
      "Processed 450,000,000 lines\n",
      "Processed 451,000,000 lines\n",
      "Processed 452,000,000 lines\n",
      "Processed 453,000,000 lines\n",
      "Processed 454,000,000 lines\n",
      "Processed 455,000,000 lines\n",
      "Processed 456,000,000 lines\n",
      "Processed 457,000,000 lines\n",
      "Processed 458,000,000 lines\n",
      "Processed 459,000,000 lines\n",
      "Processed 460,000,000 lines\n",
      "Processed 461,000,000 lines\n",
      "Processed 462,000,000 lines\n",
      "Processed 463,000,000 lines\n",
      "Processed 464,000,000 lines\n",
      "Processed 465,000,000 lines\n",
      "Processed 467,000,000 lines\n",
      "Processed 468,000,000 lines\n",
      "Processed 469,000,000 lines\n",
      "Processed 470,000,000 lines\n",
      "Processed 471,000,000 lines\n",
      "Processed 472,000,000 lines\n",
      "Processed 473,000,000 lines\n",
      "Processed 474,000,000 lines\n",
      "Processed 475,000,000 lines\n",
      "Processed 476,000,000 lines\n",
      "Processed 477,000,000 lines\n",
      "Processed 478,000,000 lines\n",
      "Processed 479,000,000 lines\n",
      "Processed 480,000,000 lines\n",
      "Processed 481,000,000 lines\n",
      "Processed 482,000,000 lines\n",
      "Processed 483,000,000 lines\n",
      "Processed 484,000,000 lines\n",
      "Processed 485,000,000 lines\n",
      "Processed 486,000,000 lines\n",
      "Processed 487,000,000 lines\n",
      "Processed 488,000,000 lines\n",
      "Processed 489,000,000 lines\n",
      "Processed 490,000,000 lines\n",
      "Processed 491,000,000 lines\n",
      "Processed 492,000,000 lines\n",
      "Processed 493,000,000 lines\n",
      "Processed 494,000,000 lines\n",
      "Processed 495,000,000 lines\n",
      "Processed 496,000,000 lines\n",
      "Processed 497,000,000 lines\n",
      "Processed 498,000,000 lines\n",
      "Processed 499,000,000 lines\n",
      "Processed 500,000,000 lines\n",
      "Processed 501,000,000 lines\n",
      "Processed 502,000,000 lines\n",
      "Processed 503,000,000 lines\n",
      "Processed 504,000,000 lines\n",
      "Processed 505,000,000 lines\n",
      "Processed 506,000,000 lines\n",
      "Processed 507,000,000 lines\n",
      "Processed 508,000,000 lines\n",
      "Processed 509,000,000 lines\n",
      "Processed 510,000,000 lines\n",
      "Processed 511,000,000 lines\n",
      "Processed 512,000,000 lines\n",
      "Processed 513,000,000 lines\n",
      "Processed 514,000,000 lines\n",
      "Processed 515,000,000 lines\n",
      "Processed 516,000,000 lines\n",
      "Processed 517,000,000 lines\n",
      "Processed 518,000,000 lines\n",
      "Processed 519,000,000 lines\n",
      "Processed 520,000,000 lines\n",
      "Processed 521,000,000 lines\n",
      "Processed 522,000,000 lines\n",
      "Processed 523,000,000 lines\n",
      "Processed 524,000,000 lines\n",
      "Processed 525,000,000 lines\n",
      "Processed 526,000,000 lines\n",
      "Processed 527,000,000 lines\n",
      "Processed 528,000,000 lines\n",
      "Processed 529,000,000 lines\n",
      "Processed 530,000,000 lines\n",
      "Processed 531,000,000 lines\n",
      "Processed 532,000,000 lines\n",
      "Processed 533,000,000 lines\n",
      "Processed 534,000,000 lines\n",
      "Processed 535,000,000 lines\n",
      "Processed 536,000,000 lines\n",
      "Processed 537,000,000 lines\n",
      "Processed 538,000,000 lines\n",
      "Processed 539,000,000 lines\n",
      "Processed 540,000,000 lines\n",
      "Processed 541,000,000 lines\n",
      "Processed 542,000,000 lines\n",
      "Processed 543,000,000 lines\n",
      "Processed 544,000,000 lines\n",
      "Authors: 3930945\n",
      "DOIs: 6841488\n"
     ]
    }
   ],
   "source": [
    "authors_by_pid = {}\n",
    "dois_by_pub = {}\n",
    "\n",
    "signature_to_pid = {}\n",
    "pub_to_signatures = {}\n",
    "pub_to_pids = {}\n",
    "pid_to_label = {}\n",
    "\n",
    "RDFS_LABEL = \"http://www.w3.org/2000/01/rdf-schema#label\"\n",
    "\n",
    "with fs.open(rdf_path, \"rb\") as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        for i, line in enumerate(gz):\n",
    "\n",
    "            line = line.decode(\"utf-8\", errors=\"ignore\").strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            parts = line.split(\" \", 2)\n",
    "            if len(parts) != 3:\n",
    "                continue\n",
    "\n",
    "            subj, pred, obj = parts\n",
    "            subj = subj.strip(\"<>\")\n",
    "            pred = pred.strip(\"<>\")\n",
    "            obj = obj.strip(\" .\").strip(\"<>\")\n",
    "\n",
    "            # ---------- PID -> label ----------\n",
    "            if pred == RDFS_LABEL:\n",
    "                pid_to_label[subj] = obj.strip('\"')\n",
    "\n",
    "            # ---------- signature -> PID ----------\n",
    "            elif pred.endswith(\"signatureCreator\"):\n",
    "                signature_to_pid[subj] = obj\n",
    "\n",
    "            # ---------- publication -> signature ----------\n",
    "            elif pred.endswith(\"hasSignature\") or pred.endswith(\"authoredBy\"):\n",
    "                pub_to_signatures.setdefault(subj, []).append(obj)\n",
    "\n",
    "            # ---------- DOI ----------\n",
    "            elif pred.endswith(\"doi\"):\n",
    "                dois_by_pub[subj] = obj.strip('\"')\n",
    "\n",
    "            if i % 1_000_000 == 0 and i > 0:\n",
    "                print(f\"Processed {i:,} lines\")\n",
    "\n",
    "# ---------- FINAL MERGE ----------\n",
    "for sig, pid in signature_to_pid.items():\n",
    "    label = pid_to_label.get(pid)\n",
    "    if label:\n",
    "        authors_by_pid[pid] = label\n",
    "\n",
    "for pub, sigs in pub_to_signatures.items():\n",
    "    pids = []\n",
    "\n",
    "    for sig in sigs:\n",
    "        pid = signature_to_pid.get(sig)\n",
    "        if pid:\n",
    "            pids.append(pid)\n",
    "\n",
    "    if pids:\n",
    "        pub_to_pids[pub] = pids\n",
    "\n",
    "pub_to_pids[pub] = list(set(pids))\n",
    "\n",
    "print(\"Authors:\", len(authors_by_pid))\n",
    "print(\"DOIs:\", len(dois_by_pub))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9cfee2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://dblp.org/rec/reference/vision/Singh14</td>\n",
       "      <td>[https://dblp.org/pid/78/459-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://dblp.org/rec/reference/vision/Wong14</td>\n",
       "      <td>[https://dblp.org/pid/69/220]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://dblp.org/rec/reference/vision/Pont14b</td>\n",
       "      <td>[https://dblp.org/pid/99/2633]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://dblp.org/rec/reference/vision/Alexander14</td>\n",
       "      <td>[https://dblp.org/pid/37/6152]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://dblp.org/rec/reference/vision/Fukui14</td>\n",
       "      <td>[https://dblp.org/pid/01/1485]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101479</th>\n",
       "      <td>https://dblp.org/rec/persons/Codd71b</td>\n",
       "      <td>[https://dblp.org/pid/c/EFCodd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101480</th>\n",
       "      <td>https://dblp.org/rec/persons/Codd71</td>\n",
       "      <td>[https://dblp.org/pid/c/EFCodd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101481</th>\n",
       "      <td>https://dblp.org/rec/persons/Hall74</td>\n",
       "      <td>[https://dblp.org/pid/82/5885]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101482</th>\n",
       "      <td>https://dblp.org/rec/persons/Codd69</td>\n",
       "      <td>[https://dblp.org/pid/c/EFCodd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101483</th>\n",
       "      <td>https://dblp.org/rec/persons/Ley95</td>\n",
       "      <td>[https://dblp.org/pid/00/1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8101484 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       pid  \\\n",
       "0            https://dblp.org/rec/reference/vision/Singh14   \n",
       "1             https://dblp.org/rec/reference/vision/Wong14   \n",
       "2            https://dblp.org/rec/reference/vision/Pont14b   \n",
       "3        https://dblp.org/rec/reference/vision/Alexander14   \n",
       "4            https://dblp.org/rec/reference/vision/Fukui14   \n",
       "...                                                    ...   \n",
       "8101479               https://dblp.org/rec/persons/Codd71b   \n",
       "8101480                https://dblp.org/rec/persons/Codd71   \n",
       "8101481                https://dblp.org/rec/persons/Hall74   \n",
       "8101482                https://dblp.org/rec/persons/Codd69   \n",
       "8101483                 https://dblp.org/rec/persons/Ley95   \n",
       "\n",
       "                                    name  \n",
       "0        [https://dblp.org/pid/78/459-1]  \n",
       "1          [https://dblp.org/pid/69/220]  \n",
       "2         [https://dblp.org/pid/99/2633]  \n",
       "3         [https://dblp.org/pid/37/6152]  \n",
       "4         [https://dblp.org/pid/01/1485]  \n",
       "...                                  ...  \n",
       "8101479  [https://dblp.org/pid/c/EFCodd]  \n",
       "8101480  [https://dblp.org/pid/c/EFCodd]  \n",
       "8101481   [https://dblp.org/pid/82/5885]  \n",
       "8101482  [https://dblp.org/pid/c/EFCodd]  \n",
       "8101483      [https://dblp.org/pid/00/1]  \n",
       "\n",
       "[8101484 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pub_to_pids.items(), columns=[\"pid\", \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934476ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles=[]\n",
    "\n",
    "with fs.open(path, 'rb') as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        context = etree.iterparse(\n",
    "            gz, events=(\"end\",), tag=\"article\", recover=True\n",
    "        )\n",
    "\n",
    "        for event, elem in context:\n",
    "            title = elem.findtext(\"title\")\n",
    "            journal = elem.findtext(\"journal\")\n",
    "            pub_date = elem.findtext(\"year\")\n",
    "            doi = elem.findtext(\"ee\")\n",
    "\n",
    "            # Article-level DBLP PID\n",
    "            article_pid = elem.get(\"key\")\n",
    "\n",
    "            # Collect authors + IDs\n",
    "            authors = []\n",
    "\n",
    "            for a in elem.findall(\".//author\"):\n",
    "                name = a.text     # DBLP person ID\n",
    "                orcid = a.get(\"orcid\")\n",
    "                if name:\n",
    "                    authors.append({\n",
    "                        \"name\": name,\n",
    "                        \"orcid\": orcid\n",
    "                    })\n",
    "\n",
    "            articles.append({\n",
    "                \"title\": title,\n",
    "                \"journal\": journal,\n",
    "                \"year\": pub_date,\n",
    "                \"authors\": authors,\n",
    "                \"dblp_uri\": article_pid,\n",
    "                \"doi\": doi\n",
    "            })\n",
    "\n",
    "            elem.clear()\n",
    "\n",
    "df = pd.DataFrame(articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261cdaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles=[]\n",
    "\n",
    "with fs.open(path, 'rb') as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        context = etree.iterparse(\n",
    "            gz, events=(\"end\",), tag=\"inproceedings\", recover=True\n",
    "        )\n",
    "\n",
    "        for event, elem in context:\n",
    "            title = elem.findtext(\"title\")\n",
    "            conf = elem.findtext(\"booktitle\")\n",
    "            pub_date = elem.findtext(\"year\")\n",
    "            doi = elem.findtext(\"ee\")\n",
    "\n",
    "            # Article-level DBLP PID\n",
    "            article_pid = elem.get(\"key\")\n",
    "\n",
    "            # Collect authors + IDs\n",
    "            authors = []\n",
    "\n",
    "            for a in elem.findall(\".//author\"):\n",
    "                name = a.text     # DBLP person ID\n",
    "                orcid = a.get(\"orcid\")\n",
    "                if name:\n",
    "                    authors.append({\n",
    "                        \"name\": name,\n",
    "                        \"orcid\": orcid\n",
    "                    })\n",
    "\n",
    "            articles.append({\n",
    "                \"title\": title,\n",
    "                \"conf\": conf,\n",
    "                \"year\": pub_date,\n",
    "                \"authors\": authors,\n",
    "                \"dblp_uri\": article_pid,\n",
    "                \"doi\": doi\n",
    "            })\n",
    "\n",
    "            elem.clear()\n",
    "\n",
    "df = pd.DataFrame(articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd286322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>conf</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>dblp_uri</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Future of Classic Data Administration: Obj...</td>\n",
       "      <td>SWEE</td>\n",
       "      <td>1998</td>\n",
       "      <td>[{'name': 'Arnon Rosenthal', 'orcid': None}]</td>\n",
       "      <td>www/org/mitre/future</td>\n",
       "      <td>http://www.mitre.org/support/swee/rosenthal.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Some Patterns of Convincing Software Engineeri...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>[{'name': 'Lutz Prechelt', 'orcid': None}]</td>\n",
       "      <td>books/sp/22/Prechelt22</td>\n",
       "      <td>https://doi.org/10.1007/978-3-030-83128-8_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Static Worst-Case Analyses and Their Validatio...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>[{'name': 'Peter Wgemann', 'orcid': None}]</td>\n",
       "      <td>books/sp/22/Wagemann22</td>\n",
       "      <td>https://doi.org/10.1007/978-3-030-83128-8_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crossing Disciplinary Borders to Improve Requi...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>[{'name': 'Anne Hess', 'orcid': None}]</td>\n",
       "      <td>books/sp/22/Hess22</td>\n",
       "      <td>https://doi.org/10.1007/978-3-030-83128-8_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What You See Is What You Get: Practical Effect...</td>\n",
       "      <td>Denert Award</td>\n",
       "      <td>2020</td>\n",
       "      <td>[{'name': 'Jonathan Immanuel Brachthuser', 'or...</td>\n",
       "      <td>books/sp/22/Brachthauser22</td>\n",
       "      <td>https://doi.org/10.1007/978-3-030-83128-8_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749511</th>\n",
       "      <td>Toward a Modern Geography of Minds, Machines, ...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>[{'name': 'Selmer Bringsjord', 'orcid': None},...</td>\n",
       "      <td>series/sapere/BringsjordG13</td>\n",
       "      <td>https://doi.org/10.1007/978-3-642-31674-6_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749512</th>\n",
       "      <td>Emotional Control-Conditio Sine Qua Non for Ad...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>[{'name': 'Claudius Gros', 'orcid': '0000-0002...</td>\n",
       "      <td>series/sapere/Gros13</td>\n",
       "      <td>https://doi.org/10.1007/978-3-642-31674-6_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749513</th>\n",
       "      <td>Becoming Digital: Reconciling Theories of Digi...</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>[{'name': 'Harry Halpin', 'orcid': None}]</td>\n",
       "      <td>series/sapere/Halpin13</td>\n",
       "      <td>https://doi.org/10.1007/978-3-642-31674-6_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749514</th>\n",
       "      <td>Generative Artificial Intelligence.</td>\n",
       "      <td>PT-AI</td>\n",
       "      <td>2011</td>\n",
       "      <td>[{'name': 'Tijn van der Zant', 'orcid': None},...</td>\n",
       "      <td>series/sapere/ZantKS13</td>\n",
       "      <td>https://doi.org/10.1007/978-3-642-31674-6_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749515</th>\n",
       "      <td>Seven Steps to Rendezvous with the Casual User.</td>\n",
       "      <td>IFIP Working Conference Data Base Management</td>\n",
       "      <td>1974</td>\n",
       "      <td>[{'name': 'E. F. Codd', 'orcid': None}]</td>\n",
       "      <td>persons/Codd74</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3749516 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  \\\n",
       "0        The Future of Classic Data Administration: Obj...   \n",
       "1        Some Patterns of Convincing Software Engineeri...   \n",
       "2        Static Worst-Case Analyses and Their Validatio...   \n",
       "3        Crossing Disciplinary Borders to Improve Requi...   \n",
       "4        What You See Is What You Get: Practical Effect...   \n",
       "...                                                    ...   \n",
       "3749511  Toward a Modern Geography of Minds, Machines, ...   \n",
       "3749512  Emotional Control-Conditio Sine Qua Non for Ad...   \n",
       "3749513  Becoming Digital: Reconciling Theories of Digi...   \n",
       "3749514                Generative Artificial Intelligence.   \n",
       "3749515    Seven Steps to Rendezvous with the Casual User.   \n",
       "\n",
       "                                                 conf  year  \\\n",
       "0                                                SWEE  1998   \n",
       "1                                        Denert Award  2020   \n",
       "2                                        Denert Award  2020   \n",
       "3                                        Denert Award  2020   \n",
       "4                                        Denert Award  2020   \n",
       "...                                               ...   ...   \n",
       "3749511                                         PT-AI  2011   \n",
       "3749512                                         PT-AI  2011   \n",
       "3749513                                         PT-AI  2011   \n",
       "3749514                                         PT-AI  2011   \n",
       "3749515  IFIP Working Conference Data Base Management  1974   \n",
       "\n",
       "                                                   authors  \\\n",
       "0             [{'name': 'Arnon Rosenthal', 'orcid': None}]   \n",
       "1               [{'name': 'Lutz Prechelt', 'orcid': None}]   \n",
       "2               [{'name': 'Peter Wgemann', 'orcid': None}]   \n",
       "3                   [{'name': 'Anne Hess', 'orcid': None}]   \n",
       "4        [{'name': 'Jonathan Immanuel Brachthuser', 'or...   \n",
       "...                                                    ...   \n",
       "3749511  [{'name': 'Selmer Bringsjord', 'orcid': None},...   \n",
       "3749512  [{'name': 'Claudius Gros', 'orcid': '0000-0002...   \n",
       "3749513          [{'name': 'Harry Halpin', 'orcid': None}]   \n",
       "3749514  [{'name': 'Tijn van der Zant', 'orcid': None},...   \n",
       "3749515            [{'name': 'E. F. Codd', 'orcid': None}]   \n",
       "\n",
       "                            dblp_uri  \\\n",
       "0               www/org/mitre/future   \n",
       "1             books/sp/22/Prechelt22   \n",
       "2             books/sp/22/Wagemann22   \n",
       "3                 books/sp/22/Hess22   \n",
       "4         books/sp/22/Brachthauser22   \n",
       "...                              ...   \n",
       "3749511  series/sapere/BringsjordG13   \n",
       "3749512         series/sapere/Gros13   \n",
       "3749513       series/sapere/Halpin13   \n",
       "3749514       series/sapere/ZantKS13   \n",
       "3749515               persons/Codd74   \n",
       "\n",
       "                                                      doi  \n",
       "0        http://www.mitre.org/support/swee/rosenthal.html  \n",
       "1             https://doi.org/10.1007/978-3-030-83128-8_2  \n",
       "2            https://doi.org/10.1007/978-3-030-83128-8_11  \n",
       "3             https://doi.org/10.1007/978-3-030-83128-8_7  \n",
       "4             https://doi.org/10.1007/978-3-030-83128-8_3  \n",
       "...                                                   ...  \n",
       "3749511      https://doi.org/10.1007/978-3-642-31674-6_11  \n",
       "3749512      https://doi.org/10.1007/978-3-642-31674-6_14  \n",
       "3749513      https://doi.org/10.1007/978-3-642-31674-6_15  \n",
       "3749514       https://doi.org/10.1007/978-3-642-31674-6_8  \n",
       "3749515                                              None  \n",
       "\n",
       "[3749516 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18043c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['author', 'booktitle', 'cdrom', 'cite', 'crossref', 'editor', 'ee', 'month', 'note', 'number', 'pages', 'publnr', 'stream', 'title', 'url', 'volume', 'year']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import gzip\n",
    "\n",
    "direct_set = set()\n",
    "\n",
    "with fs.open(path, \"rb\") as f:\n",
    "    with gzip.GzipFile(fileobj=f) as gz:\n",
    "        context = etree.iterparse(gz, events=(\"end\",), tag=\"inproceedings\", recover=True)\n",
    "        for event, elem in context:\n",
    "            # collect child tags\n",
    "            for child in elem:\n",
    "                if child.tag is not None:\n",
    "                    direct_set.add(child.tag)\n",
    "\n",
    "            # clear memory: remove element and its previous siblings\n",
    "            elem.clear()\n",
    "            while elem.getprevious() is not None:\n",
    "                del elem.getparent()[0]\n",
    "\n",
    "print(sorted(direct_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
