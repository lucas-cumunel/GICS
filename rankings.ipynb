{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad96f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = 'PVZT77T3X1860L6FCJFG'\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = '8Uq1Hnf5y5f5K47efWXkZJ6kdQiyOy9IBa5D9MnN'\n",
    "os.environ[\"AWS_SESSION_TOKEN\"] = 'eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NLZXkiOiJQVlpUNzdUM1gxODYwTDZGQ0pGRyIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sImF1ZCI6WyJtaW5pby1kYXRhbm9kZSIsIm9ueXhpYSIsImFjY291bnQiXSwiYXV0aF90aW1lIjoxNzY5NjEyMTg2LCJhenAiOiJvbnl4aWEiLCJlbWFpbCI6Imx1Y2FzLmN1bXVuZWxAZW5zYWUuZnIiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZXhwIjoxNzcxMzE1NTA1LCJmYW1pbHlfbmFtZSI6IkN1bXVuZWwiLCJnaXZlbl9uYW1lIjoiTHVjYXMiLCJncm91cHMiOlsiVVNFUl9PTllYSUEiLCJzdGF0YXBwLXNlZ21lZGljIl0sImlhdCI6MTc3MDcxMDcwNSwiaXNzIjoiaHR0cHM6Ly9hdXRoLmxhYi5zc3BjbG91ZC5mci9hdXRoL3JlYWxtcy9zc3BjbG91ZCIsImp0aSI6Im9ucnRydDo1ZjM1MWE3MS03NTIwLWYyNjYtNjBjOS1iYWY5NjYzMTEyYjciLCJuYW1lIjoiTHVjYXMgQ3VtdW5lbCIsInBvbGljeSI6InN0c29ubHkiLCJwcmVmZXJyZWRfdXNlcm5hbWUiOiJsYWIiLCJyZWFsbV9hY2Nlc3MiOnsicm9sZXMiOlsib2ZmbGluZV9hY2Nlc3MiLCJ1bWFfYXV0aG9yaXphdGlvbiIsImRlZmF1bHQtcm9sZXMtc3NwY2xvdWQiXX0sInJlc291cmNlX2FjY2VzcyI6eyJhY2NvdW50Ijp7InJvbGVzIjpbIm1hbmFnZS1hY2NvdW50IiwibWFuYWdlLWFjY291bnQtbGlua3MiLCJ2aWV3LXByb2ZpbGUiXX19LCJyb2xlcyI6WyJvZmZsaW5lX2FjY2VzcyIsInVtYV9hdXRob3JpemF0aW9uIiwiZGVmYXVsdC1yb2xlcy1zc3BjbG91ZCJdLCJzY29wZSI6Im9wZW5pZCBwcm9maWxlIGdyb3VwcyBlbWFpbCIsInNpZCI6Ijc4ODAyYmFkLTFjZTEtODFkOC1mYjI4LTQwNWY4MWQ0ZGVmNSIsInN1YiI6ImUyZDc4NjRjLTcwMzItNDI0ZC04OTA2LWU0ZjhiNDFjYzAwMyIsInR5cCI6IkJlYXJlciJ9.Dlw2Tbo6kDKyKT70uHQjFhqBaOTtzYXw5t9pKQu7I-GxTbbL_qo7AMAHIWUfsPj-l4JDZUf6RabEsg-Rx3A39g'\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = 'us-east-1'\n",
    "fs = s3fs.S3FileSystem(\n",
    "    client_kwargs={'endpoint_url': 'https://'+'minio.lab.sspcloud.fr'},\n",
    "    key = os.environ[\"AWS_ACCESS_KEY_ID\"], \n",
    "    secret = os.environ[\"AWS_SECRET_ACCESS_KEY\"], \n",
    "    token = os.environ[\"AWS_SESSION_TOKEN\"])\n",
    "with fs.open(\"s3://lab/CORE.csv\") as f:\n",
    "    cf = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/conf_net.parquet\") as f:\n",
    "    df = pd.read_parquet(f)\n",
    "with fs.open(\"s3://lab/CORE_journals_corr.csv\") as f:\n",
    "    jcf = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/art_net.parquet\") as f:\n",
    "    jdf = pd.read_parquet(f)\n",
    "#with fs.open(\"s3://lab/nomatch.csv\") as f:\n",
    " #   nm = pd.read_csv(f)\n",
    "\"\"\"with fs.open(\"s3://lab/journal_ranking.csv\") as f:\n",
    "    jr1 = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/journal_ranking2.csv\") as f:\n",
    "    jr2 = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/journal_ranking3.csv\") as f:\n",
    "    jr3 = pd.read_csv(f)\n",
    "with fs.open(\"s3://lab/people_ranking.csv\") as f:\n",
    "    pr = pd.read_csv(f)\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1966301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>journal</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>dblp_uri</th>\n",
       "      <th>doi</th>\n",
       "      <th>rank</th>\n",
       "      <th>abrv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auswirkung der Digitalisierung auf die Systeml...</td>\n",
       "      <td>Elektrotech. Informationstechnik</td>\n",
       "      <td>2019</td>\n",
       "      <td>[{'name': 'Kai Schlabitz', 'orcid': None}]</td>\n",
       "      <td>journals/ei/Schlabitz19</td>\n",
       "      <td>https://doi.org/10.1007/s00502-019-0687-y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMF-Personenschutz: Neue Aspekte in der numeri...</td>\n",
       "      <td>Elektrotech. Informationstechnik</td>\n",
       "      <td>2020</td>\n",
       "      <td>[{'name': 'Richard berbacher', 'orcid': None},...</td>\n",
       "      <td>journals/ei/UberbacherC20</td>\n",
       "      <td>https://doi.org/10.1007/s00502-020-00791-z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zur Genesis der Forschungsstelle fr Integriert...</td>\n",
       "      <td>Elektrotech. Informationstechnik</td>\n",
       "      <td>2022</td>\n",
       "      <td>[{'name': 'Herbert Mang', 'orcid': None}]</td>\n",
       "      <td>journals/ei/Mang22</td>\n",
       "      <td>https://doi.org/10.1007/s00502-022-01049-6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100 % erneuerbare Energie fr sterreichs Indust...</td>\n",
       "      <td>Elektrotech. Informationstechnik</td>\n",
       "      <td>2021</td>\n",
       "      <td>[{'name': 'Sophie Knttner', 'orcid': None}, {'...</td>\n",
       "      <td>journals/ei/KnottnerGDD21</td>\n",
       "      <td>https://doi.org/10.1007/s00502-021-00953-7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Application of multilateration for microphone ...</td>\n",
       "      <td>Elektrotech. Informationstechnik</td>\n",
       "      <td>2021</td>\n",
       "      <td>[{'name': 'Peter Wimberger', 'orcid': '0000-00...</td>\n",
       "      <td>journals/ei/WimbergerR21</td>\n",
       "      <td>https://doi.org/10.1007/s00502-021-00885-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010848</th>\n",
       "      <td>Derivability, Redundancy and Consistency of Re...</td>\n",
       "      <td>Research Report / RJ / IBM / San Jose, California</td>\n",
       "      <td>1969</td>\n",
       "      <td>[{'name': 'E. F. Codd', 'orcid': None}]</td>\n",
       "      <td>persons/Codd69</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010849</th>\n",
       "      <td>Normalized Data Base Structure: A Brief Tutorial.</td>\n",
       "      <td>Research Report / RJ / IBM / San Jose, California</td>\n",
       "      <td>1971</td>\n",
       "      <td>[{'name': 'E. F. Codd', 'orcid': None}]</td>\n",
       "      <td>persons/Codd71b</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010850</th>\n",
       "      <td>Analysis of projected hydrological behavior of...</td>\n",
       "      <td>Hydrology and Earth System Sciences</td>\n",
       "      <td>2012</td>\n",
       "      <td>[{'name': 'Markus Casper', 'orcid': '0000-0002...</td>\n",
       "      <td>persons/CasperGGGHLR12</td>\n",
       "      <td>https://doi.org/10.5194/hess-16-409-2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010851</th>\n",
       "      <td>Common Subexpression Identification in General...</td>\n",
       "      <td>Technical Rep. UKSC 0060, IBM United Kingdom S...</td>\n",
       "      <td>1974</td>\n",
       "      <td>[{'name': 'Patrick A. V. Hall', 'orcid': None}]</td>\n",
       "      <td>persons/Hall74</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010852</th>\n",
       "      <td>Interactive Support for Non-Programmers: The R...</td>\n",
       "      <td>Research Report / RJ / IBM / San Jose, California</td>\n",
       "      <td>1974</td>\n",
       "      <td>[{'name': 'E. F. Codd', 'orcid': None}, {'name...</td>\n",
       "      <td>persons/CoddD74</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4010853 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  \\\n",
       "0        Auswirkung der Digitalisierung auf die Systeml...   \n",
       "1        EMF-Personenschutz: Neue Aspekte in der numeri...   \n",
       "2        Zur Genesis der Forschungsstelle fr Integriert...   \n",
       "3        100 % erneuerbare Energie fr sterreichs Indust...   \n",
       "4        Application of multilateration for microphone ...   \n",
       "...                                                    ...   \n",
       "4010848  Derivability, Redundancy and Consistency of Re...   \n",
       "4010849  Normalized Data Base Structure: A Brief Tutorial.   \n",
       "4010850  Analysis of projected hydrological behavior of...   \n",
       "4010851  Common Subexpression Identification in General...   \n",
       "4010852  Interactive Support for Non-Programmers: The R...   \n",
       "\n",
       "                                                   journal  year  \\\n",
       "0                         Elektrotech. Informationstechnik  2019   \n",
       "1                         Elektrotech. Informationstechnik  2020   \n",
       "2                         Elektrotech. Informationstechnik  2022   \n",
       "3                         Elektrotech. Informationstechnik  2021   \n",
       "4                         Elektrotech. Informationstechnik  2021   \n",
       "...                                                    ...   ...   \n",
       "4010848  Research Report / RJ / IBM / San Jose, California  1969   \n",
       "4010849  Research Report / RJ / IBM / San Jose, California  1971   \n",
       "4010850                Hydrology and Earth System Sciences  2012   \n",
       "4010851  Technical Rep. UKSC 0060, IBM United Kingdom S...  1974   \n",
       "4010852  Research Report / RJ / IBM / San Jose, California  1974   \n",
       "\n",
       "                                                   authors  \\\n",
       "0               [{'name': 'Kai Schlabitz', 'orcid': None}]   \n",
       "1        [{'name': 'Richard berbacher', 'orcid': None},...   \n",
       "2                [{'name': 'Herbert Mang', 'orcid': None}]   \n",
       "3        [{'name': 'Sophie Knttner', 'orcid': None}, {'...   \n",
       "4        [{'name': 'Peter Wimberger', 'orcid': '0000-00...   \n",
       "...                                                    ...   \n",
       "4010848            [{'name': 'E. F. Codd', 'orcid': None}]   \n",
       "4010849            [{'name': 'E. F. Codd', 'orcid': None}]   \n",
       "4010850  [{'name': 'Markus Casper', 'orcid': '0000-0002...   \n",
       "4010851    [{'name': 'Patrick A. V. Hall', 'orcid': None}]   \n",
       "4010852  [{'name': 'E. F. Codd', 'orcid': None}, {'name...   \n",
       "\n",
       "                          dblp_uri  \\\n",
       "0          journals/ei/Schlabitz19   \n",
       "1        journals/ei/UberbacherC20   \n",
       "2               journals/ei/Mang22   \n",
       "3        journals/ei/KnottnerGDD21   \n",
       "4         journals/ei/WimbergerR21   \n",
       "...                            ...   \n",
       "4010848             persons/Codd69   \n",
       "4010849            persons/Codd71b   \n",
       "4010850     persons/CasperGGGHLR12   \n",
       "4010851             persons/Hall74   \n",
       "4010852            persons/CoddD74   \n",
       "\n",
       "                                                doi rank abrv  \n",
       "0         https://doi.org/10.1007/s00502-019-0687-y  NaN  NaN  \n",
       "1        https://doi.org/10.1007/s00502-020-00791-z  NaN  NaN  \n",
       "2        https://doi.org/10.1007/s00502-022-01049-6  NaN  NaN  \n",
       "3        https://doi.org/10.1007/s00502-021-00953-7  NaN  NaN  \n",
       "4        https://doi.org/10.1007/s00502-021-00885-2  NaN  NaN  \n",
       "...                                             ...  ...  ...  \n",
       "4010848                                        None  NaN  NaN  \n",
       "4010849                                        None  NaN  NaN  \n",
       "4010850    https://doi.org/10.5194/hess-16-409-2012  NaN  NaN  \n",
       "4010851                                        None  NaN  NaN  \n",
       "4010852                                        None  NaN  NaN  \n",
       "\n",
       "[4010853 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jdf.merge(jcf[[\"rank\",\"abrv\"]], left_on=\"journal\", right_on=\"abrv\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d858e102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abrv</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ACM Trans. Des. Autom. Electron. Syst.</td>\n",
       "      <td>not primarily CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Appl. Ontolology</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Australas. J. Comb.</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Autom. Control Comput. Sci.</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Bus. Process Manag. J.</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Comput. Support. Cooperative Work</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Control Cybern.</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Discrete Event Dyn. Syst.</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Discrete Math.</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Discrete Math. Theor. Comput. Sci.</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Enterp. Model. Inf. Syst. Archit.</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Graph. Model</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>IEEE Trans. Comput. Biol. Bioinform.</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>IEEE Trans. Netw.</td>\n",
       "      <td>A*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Int. J. Inf. Secur.</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Int. J. Model. Identif. Control</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>Int. J. Simul. Process Model.</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>J. Inform. Educ. Res.</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>J. Multimedia</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>J. Simul.</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>J. Softw. Evol. Process</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>Perform. Eval.</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>SIAM J. Discrete Math.</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>Softw. Process Improv. Pract.</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>Wirtsch.</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       abrv              rank\n",
       "12   ACM Trans. Des. Autom. Electron. Syst.  not primarily CS\n",
       "48                         Appl. Ontolology                 C\n",
       "61                      Australas. J. Comb.                 B\n",
       "65              Autom. Control Comput. Sci.                 C\n",
       "74                   Bus. Process Manag. J.                 B\n",
       "104       Comput. Support. Cooperative Work                 B\n",
       "121                         Control Cybern.                 C\n",
       "134               Discrete Event Dyn. Syst.                 C\n",
       "135                          Discrete Math.                 B\n",
       "136      Discrete Math. Theor. Comput. Sci.                 B\n",
       "155       Enterp. Model. Inf. Syst. Archit.                 C\n",
       "169                            Graph. Model                 C\n",
       "179   IEEE Trans. Comput. Biol. Bioinform.                  C\n",
       "180                      IEEE Trans. Netw.                 A*\n",
       "340                     Int. J. Inf. Secur.                 C\n",
       "372         Int. J. Model. Identif. Control                 C\n",
       "385           Int. J. Simul. Process Model.                 C\n",
       "454                   J. Inform. Educ. Res.                 C\n",
       "487                           J. Multimedia                 C\n",
       "499                               J. Simul.                 C\n",
       "503                 J. Softw. Evol. Process                 B\n",
       "573                          Perform. Eval.                 B\n",
       "594                  SIAM J. Discrete Math.                 A\n",
       "602           Softw. Process Improv. Pract.                 C\n",
       "637                                Wirtsch.                 C"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jcf.loc[~jcf[\"abrv\"].str.strip().isin(jdf[\"journal\"].str.strip()), [\"abrv\", \"rank\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "82259fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IEEE/ACM Trans. Netw.', 'CCF Trans. Netw.',\n",
       "       'IEEE Trans. Netw. Sci. Eng.', 'IEEE Trans. Netw. Serv. Manag.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jdf.loc[jdf[\"journal\"].str.contains(\"Trans. Netw.\", na=False)][\"journal\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96899301",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.loc[~cf[\"INFOCOMP\"].isin(df[\"conf\"]), [\"INFOCOMP\", \"Unranked\", \" International Conference on Advanced Communications and Computation\"]].to_csv(\"nomatch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e50eaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_order = [\"A+\", \"A\", \"B\", \"C\"] \n",
    "\n",
    "cfr2[\"Rank\"] = pd.Categorical(cfr2[\"Rank\"], categories=desired_order, ordered=True)\n",
    "\n",
    "classes = cfr2[\"Rank\"].value_counts().sort_index().index.tolist()          # [\"A\",\"B\",\"C\"]\n",
    "sizes   = cfr2[\"Rank\"].value_counts().sort_index().values.tolist()         # [2,2,2]\n",
    "\n",
    "cfr1 = cfr1.sort_values(\"rank\").reset_index(drop=True)\n",
    "\n",
    "new_classes = []\n",
    "start = 0\n",
    "for cls, size in zip(classes, sizes):\n",
    "    new_classes += [cls] * size\n",
    "\n",
    "if len(cfr1) - len(new_classes) > 0:\n",
    "    new_classes += [\"C\"] * (len(cfr1) - len(new_classes))\n",
    "\n",
    "cfr1[\"class_rank\"] = new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea8a9fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install rapidfuzz\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "def fuzzy_compare_classes(cfr1, cfr2, col_class1=\"class_rank\", col_class2=\"Rank\", threshold=85):\n",
    "    # Normalize\n",
    "    cfr1 = cfr1.copy()\n",
    "    cfr2 = cfr2.copy()\n",
    "    cfr1[\"cls\"] = cfr1[col_class1].str.strip().str.lower()\n",
    "    cfr2[\"cls\"] = cfr2[col_class2].str.strip().str.lower()\n",
    "    cfr1[\"conf_norm\"] = cfr1[\"conference_name\"].str.strip().str.lower()\n",
    "    cfr2[\"conf_norm\"] = cfr2[\"Conference\"].str.strip().str.lower()\n",
    "\n",
    "    classes = sorted(set(cfr1[\"cls\"]).union(set(cfr2[\"cls\"])))\n",
    "    results = []\n",
    "\n",
    "    for cls in classes:\n",
    "        conf1 = list(set(cfr1.loc[cfr1[\"cls\"] == cls, \"conf_norm\"]))\n",
    "        conf2 = list(set(cfr2.loc[cfr2[\"cls\"] == cls, \"conf_norm\"]))\n",
    "\n",
    "        matched = 0\n",
    "        unmatched_1 = []\n",
    "        unmatched_2 = conf2.copy()\n",
    "\n",
    "        # fuzzy match conf1 → conf2\n",
    "        for name in conf1:\n",
    "            match, score, idx = process.extractOne(name, conf2, scorer=fuzz.WRatio)\n",
    "            if score >= threshold:\n",
    "                matched += 1\n",
    "                if match in unmatched_2:\n",
    "                    unmatched_2.remove(match)\n",
    "            else:\n",
    "                unmatched_1.append(name)\n",
    "\n",
    "        results.append({\n",
    "            \"class\": cls,\n",
    "            \"size_cfr1\": len(conf1),\n",
    "            \"size_cfr2\": len(conf2),\n",
    "            \"fuzzy_overlap\": matched,\n",
    "            \"unique_to_cfr1\": len(unmatched_1),\n",
    "            \"unique_to_cfr2\": len(unmatched_2),\n",
    "            \"overlap_ratio\": matched / max(len(conf1), len(conf2), 1)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84fe7251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>size_cfr1</th>\n",
       "      <th>size_cfr2</th>\n",
       "      <th>fuzzy_overlap</th>\n",
       "      <th>unique_to_cfr1</th>\n",
       "      <th>unique_to_cfr2</th>\n",
       "      <th>overlap_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>272</td>\n",
       "      <td>270</td>\n",
       "      <td>271</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>0.996324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a+</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>315</td>\n",
       "      <td>314</td>\n",
       "      <td>311</td>\n",
       "      <td>4</td>\n",
       "      <td>231</td>\n",
       "      <td>0.987302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c</td>\n",
       "      <td>444</td>\n",
       "      <td>266</td>\n",
       "      <td>439</td>\n",
       "      <td>5</td>\n",
       "      <td>199</td>\n",
       "      <td>0.988739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  size_cfr1  size_cfr2  fuzzy_overlap  unique_to_cfr1  unique_to_cfr2  \\\n",
       "0     a        272        270            271               1             181   \n",
       "1    a+         65         65             65               0              35   \n",
       "2     b        315        314            311               4             231   \n",
       "3     c        444        266            439               5             199   \n",
       "\n",
       "   overlap_ratio  \n",
       "0       0.996324  \n",
       "1       1.000000  \n",
       "2       0.987302  \n",
       "3       0.988739  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_fuzzy = fuzzy_compare_classes(cfr1, cfr2)\n",
    "df_compare_fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "94636697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "import pandas as pd\n",
    "\n",
    "def fuzzy_match_cross_classes(cfr1, cfr2, col_conf1=\"conference_name\", col_conf2=\"Conference\", threshold=90):\n",
    "    \"\"\"\n",
    "    Fuzzy match conferences across two dataframes, ignoring class labels.\n",
    "    Returns two DataFrames: cfr1 -> cfr2, and cfr2 -> cfr1.\n",
    "    \"\"\"\n",
    "    cfr1 = cfr1.copy()\n",
    "    cfr2 = cfr2.copy()\n",
    "    \n",
    "    # Normalize names\n",
    "    cfr1[\"conf_norm\"] = cfr1[col_conf1].str.strip().str.lower()\n",
    "    cfr2[\"conf_norm\"] = cfr2[col_conf2].str.strip().str.lower()\n",
    "    \n",
    "    out1 = []\n",
    "    out2 = []\n",
    "    \n",
    "    # CFR1 -> CFR2\n",
    "    conf2_norm_list = cfr2[\"conf_norm\"].tolist()\n",
    "    conf2_orig_list = cfr2[col_conf2].tolist()\n",
    "    \n",
    "    for orig_name, name_norm in zip(cfr1[col_conf1], cfr1[\"conf_norm\"]):\n",
    "        if not conf2_norm_list:\n",
    "            out1.append([orig_name, None, 0])\n",
    "            continue\n",
    "        match, score, idx = process.extractOne(name_norm, conf2_norm_list, scorer=fuzz.WRatio)\n",
    "        best_match = conf2_orig_list[idx] if score >= threshold else None\n",
    "        out1.append([orig_name, best_match, score])\n",
    "    \n",
    "    # CFR2 -> CFR1\n",
    "    conf1_norm_list = cfr1[\"conf_norm\"].tolist()\n",
    "    conf1_orig_list = cfr1[col_conf1].tolist()\n",
    "    \n",
    "    for orig_name, name_norm in zip(cfr2[col_conf2], cfr2[\"conf_norm\"]):\n",
    "        if not conf1_norm_list:\n",
    "            out2.append([orig_name, None, 0])\n",
    "            continue\n",
    "        match, score, idx = process.extractOne(name_norm, conf1_norm_list, scorer=fuzz.WRatio)\n",
    "        best_match = conf1_orig_list[idx] if score >= threshold else None\n",
    "        out2.append([orig_name, best_match, score])\n",
    "    \n",
    "    df1 = pd.DataFrame(out1, columns=[col_conf1, f\"best_match_in_{col_conf2}\", \"similarity\"])\n",
    "    df2 = pd.DataFrame(out2, columns=[col_conf2, f\"best_match_in_{col_conf1}\", \"similarity\"])\n",
    "    \n",
    "    return df1, df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2dceafb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1to2, df_2to1 = fuzzy_match_cross_classes(cfr1, cfr2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bdd2e492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conference_name</th>\n",
       "      <th>best_match_in_Conference</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>None</td>\n",
       "      <td>85.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAI Conference on Artificial Intelligence</td>\n",
       "      <td>None</td>\n",
       "      <td>88.987342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ACM Web Conference</td>\n",
       "      <td>None</td>\n",
       "      <td>85.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Conference of the International Speech Communi...</td>\n",
       "      <td>None</td>\n",
       "      <td>85.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Workshop on Applications of Computer Vision</td>\n",
       "      <td>None</td>\n",
       "      <td>85.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>Research in Adaptive and Convergent Systems</td>\n",
       "      <td>None</td>\n",
       "      <td>85.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>Biennial Symposium on Communications</td>\n",
       "      <td>None</td>\n",
       "      <td>85.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>Imaging Systems and Applications</td>\n",
       "      <td>None</td>\n",
       "      <td>85.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>Italian Information Retrieval Workshop</td>\n",
       "      <td>None</td>\n",
       "      <td>85.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>Artificial Intelligence and Computer Engineering</td>\n",
       "      <td>None</td>\n",
       "      <td>85.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>755 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        conference_name  \\\n",
       "3     International Conference on Learning Represent...   \n",
       "4            AAAI Conference on Artificial Intelligence   \n",
       "14                                   ACM Web Conference   \n",
       "15    Conference of the International Speech Communi...   \n",
       "21          Workshop on Applications of Computer Vision   \n",
       "...                                                 ...   \n",
       "1090        Research in Adaptive and Convergent Systems   \n",
       "1091               Biennial Symposium on Communications   \n",
       "1092                   Imaging Systems and Applications   \n",
       "1094             Italian Information Retrieval Workshop   \n",
       "1095   Artificial Intelligence and Computer Engineering   \n",
       "\n",
       "     best_match_in_Conference  similarity  \n",
       "3                        None   85.500000  \n",
       "4                        None   88.987342  \n",
       "14                       None   85.500000  \n",
       "15                       None   85.500000  \n",
       "21                       None   85.500000  \n",
       "...                       ...         ...  \n",
       "1090                     None   85.500000  \n",
       "1091                     None   85.500000  \n",
       "1092                     None   85.500000  \n",
       "1094                     None   85.500000  \n",
       "1095                     None   85.500000  \n",
       "\n",
       "[755 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1to2[df_1to2[\"best_match_in_Conference\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6718fdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1 / 20 ...\n",
      "Scraping page 2 / 20 ...\n",
      "Scraping page 3 / 20 ...\n",
      "Scraping page 4 / 20 ...\n",
      "Scraping page 5 / 20 ...\n",
      "Scraping page 6 / 20 ...\n",
      "Scraping page 7 / 20 ...\n",
      "Scraping page 8 / 20 ...\n",
      "Scraping page 9 / 20 ...\n",
      "Scraping page 10 / 20 ...\n",
      "Scraping page 11 / 20 ...\n",
      "Scraping page 12 / 20 ...\n",
      "Scraping page 13 / 20 ...\n",
      "Scraping page 14 / 20 ...\n",
      "Scraping page 15 / 20 ...\n",
      "Scraping page 16 / 20 ...\n",
      "Scraping page 17 / 20 ...\n",
      "Scraping page 18 / 20 ...\n",
      "Scraping page 19 / 20 ...\n",
      "Scraping page 20 / 20 ...\n",
      "✅ Total scientifiques récupérés : 2000\n",
      "                name  D-Index  Citations\n",
      "0      Yoshua Bengio      223     682159\n",
      "1       Anil K. Jain      214     277338\n",
      "2   Andrew Zisserman      197     391942\n",
      "3  Michael I. Jordan      197     266857\n",
      "4         Jiawei Han      197     231048\n"
     ]
    }
   ],
   "source": [
    "# scientists rankings https://research.com/scientists-rankings/computer-science?page=20\n",
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "BASE_URL = \"https://research.com/scientists-rankings/computer-science\"\n",
    "\n",
    "async def scrape_page(page, url):\n",
    "    await page.goto(url, timeout=0)\n",
    "    await page.wait_for_selector(\"div.rankings-content__items\", timeout=20000)\n",
    "\n",
    "    scientist_cards = await page.query_selector_all(\"div.scientist-item\")\n",
    "    data = []\n",
    "\n",
    "    for card in scientist_cards:\n",
    "        # Nom\n",
    "        name_el = await card.query_selector(\"h4\")\n",
    "        name = await name_el.evaluate(\"(n) => n.textContent.trim()\") if name_el else None\n",
    "\n",
    "        # Infos numériques (D-index, Citations, Publications)\n",
    "        stats_el = await card.query_selector_all(\"span.col.col--5-12.py-0.cols.mx-0.rankings-info\")\n",
    "        stats_text = \"\"\n",
    "        for s in stats_el:\n",
    "            t = await s.evaluate(\"(el) => el.textContent\")\n",
    "            stats_text += t + \"\\n\"\n",
    "\n",
    "        # Nettoyer et transformer en dict\n",
    "        stats_lines = [line.strip() for line in stats_text.split(\"\\n\") if line.strip()]\n",
    "        stats_dict = {}\n",
    "        i = 0\n",
    "        while i < len(stats_lines) - 1:\n",
    "            key = stats_lines[i]\n",
    "            try:\n",
    "                value = int(re.sub(r\"[^\\d]\", \"\", stats_lines[i+1]))\n",
    "            except ValueError:\n",
    "                value = stats_lines[i+1].strip()\n",
    "            stats_dict[key] = value\n",
    "            i += 2\n",
    "\n",
    "        data.append({\n",
    "            \"name\": name,\n",
    "            **stats_dict\n",
    "        })\n",
    "    return data\n",
    "\n",
    "async def scrape_all_pages(base_url, total_pages=20):\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        context = await browser.new_context(\n",
    "            user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                       \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                       \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "        )\n",
    "        page = await context.new_page()\n",
    "        all_data = []\n",
    "\n",
    "        for page_num in range(1, total_pages + 1):\n",
    "            url = f\"{base_url}?page={page_num}\"\n",
    "            print(f\"Scraping page {page_num} / {total_pages} ...\")\n",
    "            page_data = await scrape_page(page, url)\n",
    "            all_data.extend(page_data)\n",
    "\n",
    "        await browser.close()\n",
    "        return all_data\n",
    "\n",
    "async def main():\n",
    "    data = await scrape_all_pages(BASE_URL, total_pages=20)\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"✅ Total scientifiques récupérés : {len(df)}\")\n",
    "    print(df.head())\n",
    "    return df\n",
    "    # Si besoin, enregistrer en CSV\n",
    "    # df.to_csv(\"scientists_computer_science.csv\", index=False)\n",
    "\n",
    "df = await main()\n",
    "df[\"rank\"]=df.index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8192bf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 697 entries\n",
      "                                             Name Rank\n",
      "0                           ACM Computing Surveys   A+\n",
      "1            ACM Transactions on Computer Systems   A+\n",
      "2  ACM Transactions on Computer-Human Interaction   A+\n",
      "3            ACM Transactions on Database Systems   A+\n",
      "4                    ACM Transactions on Graphics   A+\n"
     ]
    }
   ],
   "source": [
    "# CORE 2020 https://cic.tju.edu.cn/faculty/zhileiliu/doc/COREComputerScienceJournalRankings.html\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://cic.tju.edu.cn/faculty/zhileiliu/doc/COREComputerScienceJournalRankings.html\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/138.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Récupérer la page HTML\n",
    "response = requests.get(URL, headers=headers)\n",
    "response.encoding = response.apparent_encoding\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Sélectionner le tableau\n",
    "table = soup.find(\"table\")\n",
    "rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "\n",
    "# Extraire seulement les colonnes Name (1ère) et Rank (2ème)\n",
    "data = []\n",
    "for row in rows:\n",
    "    cols = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        name, rank = cols[0], cols[1]\n",
    "        if name and rank:  # filtrer les lignes vides\n",
    "            data.append([name, rank])\n",
    "\n",
    "# Convertir en DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Name\", \"Rank\"])\n",
    "\n",
    "print(f\"✅ Found {len(df)} entries\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e98940c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 0 journals\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://research.com/journals-rankings/computer-science\"\n",
    "\n",
    "async def scrape_journals(url):\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        context = await browser.new_context(\n",
    "            user_agent=(\n",
    "                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                \"Chrome/118.0.5993.118 Safari/537.36\"\n",
    "            )\n",
    "        )\n",
    "        page = await context.new_page()\n",
    "        await page.goto(url, timeout=0)\n",
    "        \n",
    "        # Attendre que le challenge Cloudflare soit passé et que le contenu soit chargé\n",
    "        await page.wait_for_load_state(\"networkidle\", timeout=30000)\n",
    "        \n",
    "        # Sélectionner tous les éléments journaux\n",
    "        journal_elements = await page.query_selector_all(\n",
    "            \"div.rankings-content div.cols.wrap.justify-center div.ranking-items div.cols.journal-item\"\n",
    "        )\n",
    "        \n",
    "        journals = []\n",
    "        for el in journal_elements:\n",
    "            # Nom du journal\n",
    "            name_el = await el.query_selector(\"div.col.col--5.col--tablet.py-0.info h4\")\n",
    "            name = await name_el.evaluate(\"node => node.innerText.trim()\") if name_el else None\n",
    "            \n",
    "            # Rank\n",
    "            rank_el = await el.query_selector(\"div.col.col--1.col--tablet.cols.mx-0.py-0\")\n",
    "            rank_text = await rank_el.evaluate(\"node => node.innerText.trim()\") if rank_el else None\n",
    "            \n",
    "            if name and rank_text:\n",
    "                journals.append({\n",
    "                    \"name\": name,\n",
    "                    \"rank\": int(rank_text.replace(\".\", \"\").strip())\n",
    "                })\n",
    "        \n",
    "        await browser.close()\n",
    "        return pd.DataFrame(journals)\n",
    "\n",
    "async def main():\n",
    "    df = await scrape_journals(URL)\n",
    "    print(f\"✅ Found {len(df)} journals\")\n",
    "    print(df.head(20))\n",
    "\n",
    "# In a Jupyter cell\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c150dca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IEEE Transactions on Pattern Analysis and Mach...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IEEE Access</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IEEE Transactions on Image Processing</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IEEE Transactions on Industrial Informatics</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>IEEE Transactions on Industrial Cyber-Physical...</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Journal of Telecommunications and Information ...</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>International Journal of Software Innovation</td>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>International Journal of Sensors, Wireless Com...</td>\n",
       "      <td>1118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>International Journal of Mobile and Blended Le...</td>\n",
       "      <td>1119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1219 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Journal  Rank\n",
       "0    IEEE Transactions on Pattern Analysis and Mach...     1\n",
       "1                                          IEEE Access     2\n",
       "2                      IEEE Internet of Things Journal     3\n",
       "3                IEEE Transactions on Image Processing     4\n",
       "4          IEEE Transactions on Industrial Informatics     5\n",
       "..                                                 ...   ...\n",
       "114  IEEE Transactions on Industrial Cyber-Physical...  1115\n",
       "115  Journal of Telecommunications and Information ...  1116\n",
       "116       International Journal of Software Innovation  1117\n",
       "117  International Journal of Sensors, Wireless Com...  1118\n",
       "118  International Journal of Mobile and Blended Le...  1119\n",
       "\n",
       "[1219 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://research.com/journals-rankings/computer-science?page=12 via chatgpt\n",
    "#big_df=pd.concat([df,df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11],axis=0)\n",
    "#big_df[\"Rank\"]=big_df[\"Rank\"].astype(int)\n",
    "#big_df.sort_values(\"Rank\",ascending=True, inplace=True)\n",
    "big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32303e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Index                                            Journal    CA\n",
      "0       1          IEEE Communications Surveys and Tutorials  46.7\n",
      "1       2                              ACM Computing Surveys    28\n",
      "2       3                                   Science Robotics  27.5\n",
      "3       4    International Journal of Information Management    27\n",
      "4       4  Wiley Interdisciplinary Reviews-Computational ...    27\n",
      "..    ...                                                ...   ...\n",
      "763   758                       Iranian Journal of Radiology   0.4\n",
      "764   758                            Fundamenta Informaticae   0.4\n",
      "765   766  Zeitschrift fuer Bibliothekswesen und Bibliogr...   0.2\n",
      "766   767                                       ICGA Journal   0.1\n",
      "767   768                     Informacao & Sociedade-Estudos     0\n",
      "\n",
      "[768 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#https://ooir.org/all-journals.php?field=Computer+Science&metric=jif\n",
    "text=\"\"\"1\tIEEE Communications Surveys and Tutorials\tca. 46.7\n",
    "2\tACM Computing Surveys\tca. 28\n",
    "3\tScience Robotics\tca. 27.\n",
    "-\tApplicable Algebra in Engineering Communication and Computing\tca. 0.6\n",
    "-\tInternational Journa...\n",
    "\"\"\"\n",
    "import re\n",
    "lines = text.strip().split(\"\\n\")\n",
    "data = []\n",
    "last_index = None\n",
    "\n",
    "for line in lines:\n",
    "    # Chercher le motif \"ca. XX\" à la fin\n",
    "    match = re.search(r'\\t?ca\\.\\s*([\\d\\.]+)$', line)\n",
    "    if match:\n",
    "        ca_value = match.group(1)\n",
    "        before_ca = line[:match.start()].strip()\n",
    "        # Extraire l'index et le journal\n",
    "        index_part, journal = before_ca.split(None, 1)\n",
    "        # Si index = \"-\", prendre le dernier numérique\n",
    "        if index_part.strip() == \"-\":\n",
    "            index_part = last_index\n",
    "        else:\n",
    "            last_index = index_part.strip()\n",
    "        data.append([index_part, journal.strip(), ca_value])\n",
    "    else:\n",
    "        data.append([None, None, None])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Index\", \"Journal\", \"CA\"])\n",
    "df=df.drop([\"CA\"],axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9810c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://research.com/conference-rankings/computer-science?page=11 vace le chat\n",
    "big=pd.concat([df,df1,df2,df3,df4,df5,df6,df7,df8,df9,df10],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f2250f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 919 conferences\n",
      "{'Acronym': 'AAAI', 'Conference': 'National Conference of the American Association for Artificial Intelligence', 'Rank': 'A+'}\n",
      "{'Acronym': 'AAMAS', 'Conference': 'International Conference on Autonomous Agents and Multiagent Systems', 'Rank': 'A+'}\n",
      "{'Acronym': 'ACL', 'Conference': 'Association of Computational Linguistics', 'Rank': 'A+'}\n",
      "{'Acronym': 'ACMMM', 'Conference': 'ACM Multimedia Conference', 'Rank': 'A+'}\n",
      "{'Acronym': 'ASPLOS', 'Conference': 'Architectural Support for Programming Languages and Operating Systems', 'Rank': 'A+'}\n",
      "{'Acronym': 'CAV', 'Conference': 'Computer Aided Verification', 'Rank': 'A+'}\n",
      "{'Acronym': 'CCS', 'Conference': 'ACM Conference on Computer and Communications Security', 'Rank': 'A+'}\n",
      "{'Acronym': 'CHI', 'Conference': 'International Conference on Human Factors in Computing Systems', 'Rank': 'A+'}\n",
      "{'Acronym': 'COLT', 'Conference': 'Annual Conference on Computational Learning Theory', 'Rank': 'A+'}\n",
      "{'Acronym': 'CRYPTO', 'Conference': 'Advances in Cryptology', 'Rank': 'A+'}\n",
      "✅ Saved to conference_rank_list.csv\n"
     ]
    }
   ],
   "source": [
    "#https://people.iiti.ac.in/~artiwari/cseconflist.html\n",
    "from playwright.async_api import async_playwright\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://people.iiti.ac.in/~artiwari/cseconflist.html\"\n",
    "\n",
    "async def scrape_conferences(url):\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(url, timeout=0)\n",
    "        \n",
    "        # Attendre un peu si nécessaire\n",
    "        await page.wait_for_timeout(1000)\n",
    "        \n",
    "        rows = await page.query_selector_all(\"table tr\")\n",
    "        conferences = []\n",
    "        \n",
    "        for row in rows:\n",
    "            th = await row.query_selector(\"th\")\n",
    "            if th:\n",
    "                continue\n",
    "            \n",
    "            tds = await row.query_selector_all(\"td\")\n",
    "            if len(tds) >= 3:\n",
    "                acronym = (await tds[0].inner_text()).strip()\n",
    "                full_name = (await tds[1].inner_text()).strip()\n",
    "                rank = (await tds[2].inner_text()).strip()\n",
    "                \n",
    "                conferences.append({\n",
    "                    \"Acronym\": acronym,\n",
    "                    \"Conference\": full_name,\n",
    "                    \"Rank\": rank\n",
    "                })\n",
    "        \n",
    "        await browser.close()\n",
    "        return conferences\n",
    "\n",
    "# Directement await dans ton notebook ou ton env asynchrone\n",
    "confs = await scrape_conferences(URL)\n",
    "print(f\"✅ Found {len(confs)} conferences\")\n",
    "for c in confs[:10]:\n",
    "    print(c)\n",
    "\n",
    "# Sauvegarder en CSV\n",
    "df = pd.DataFrame(confs)\n",
    "#df.to_csv(\"conference_rank_list.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ Saved to conference_rank_list.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280eebd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 0 scientists\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#rip\n",
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "URL = \"https://www.adscientificindex.com/h-index-rankings/?subject=Engineering+%26+Technology+%2F+Computer+Science\"\n",
    "\n",
    "async def scrape_adscientific_names(url):\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(url, timeout=0)\n",
    "\n",
    "        # Scroll step by step to trigger lazy loading\n",
    "        previous_height = await page.evaluate(\"document.body.scrollHeight\")\n",
    "        while True:\n",
    "            await page.evaluate(\"window.scrollBy(0, 1000)\")\n",
    "            await page.wait_for_timeout(1000)  # wait for new items to load\n",
    "            new_height = await page.evaluate(\"document.body.scrollHeight\")\n",
    "            if new_height == previous_height:\n",
    "                break\n",
    "            previous_height = new_height\n",
    "\n",
    "        # Wait a bit to ensure all JS has rendered the divs\n",
    "        await page.wait_for_timeout(3000)\n",
    "\n",
    "        # Select all scientist items\n",
    "        scientist_cards = await page.query_selector_all(\"div.scientist-list-item\")\n",
    "        names = []\n",
    "\n",
    "        for card in scientist_cards:\n",
    "            name_el = await card.query_selector(\n",
    "                \"div.scientist-name a.name\"\n",
    "            )\n",
    "            if name_el:\n",
    "                name = await name_el.evaluate(\"(n) => n.textContent.trim()\")\n",
    "                if name:\n",
    "                    names.append(name)\n",
    "\n",
    "        await browser.close()\n",
    "        return names\n",
    "\n",
    "async def main():\n",
    "    names = await scrape_adscientific_names(URL)\n",
    "    print(f\"✅ Found {len(names)} scientists\")\n",
    "    print(names[:20])  # show first 20 names\n",
    "\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b45e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"s3://lab/people_ranking.csv\", index=False)\n",
    "df.to_csv(\"s3://lab/conf_ranking2.csv\", index=False, storage_options={\n",
    "    \"client_kwargs\": {\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"},\n",
    "    \"key\": os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    \"secret\": os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    \"token\": os.environ.get(\"AWS_SESSION_TOKEN\")  # optionnel\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb008c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mcitations\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdoi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_citation_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnotna\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m time.sleep(\u001b[32m0.3\u001b[39m)\n\u001b[32m     16\u001b[39m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/series.py:4943\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4810\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4815\u001b[39m     **kwargs,\n\u001b[32m   4816\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4817\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4818\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4819\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4934\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4935\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4936\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4937\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4941\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4943\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(d)\u001b[39m\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mcitations\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mdoi\u001b[39m\u001b[33m\"\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m d: \u001b[43mget_citation_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m pd.notna(d) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m     15\u001b[39m time.sleep(\u001b[32m0.3\u001b[39m)\n\u001b[32m     16\u001b[39m df\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mget_citation_count\u001b[39m\u001b[34m(doi)\u001b[39m\n\u001b[32m      5\u001b[39m url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://opencitations.net/index/coci/api/v1/citations/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     r = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m r.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/requests/sessions.py:724\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[32m    722\u001b[39m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[32m    723\u001b[39m     gen = \u001b[38;5;28mself\u001b[39m.resolve_redirects(r, request, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m     history = \u001b[43m[\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    726\u001b[39m     history = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/requests/sessions.py:265\u001b[39m, in \u001b[36mSessionRedirectMixin.resolve_redirects\u001b[39m\u001b[34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m req\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43madapter_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     extract_cookies_to_jar(\u001b[38;5;28mself\u001b[39m.cookies, prepared_request, resp.raw)\n\u001b[32m    278\u001b[39m     \u001b[38;5;66;03m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/urllib3/connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/urllib3/connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1091\u001b[39m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.proxy_is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/urllib3/connection.py:753\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    752\u001b[39m     sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m     server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m    755\u001b[39m     tls_in_tls = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[32m    194\u001b[39m \n\u001b[32m    195\u001b[39m \u001b[33;03m:return: New socket connection.\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/urllib3/util/connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[32m     75\u001b[39m err = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import requests, pandas as pd, time\n",
    "\n",
    "def get_citation_count(doi):\n",
    "    doi = re.sub(\"https://doi.org/\",\"\",doi)\n",
    "    url = f\"https://opencitations.net/index/coci/api/v1/citations/{doi}\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)\n",
    "        if r.status_code == 200:\n",
    "            return len(r.json())\n",
    "    except Exception:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "df[\"citations\"] = df[\"doi\"].apply(lambda d: get_citation_count(d) if pd.notna(d) else 0)\n",
    "time.sleep(0.3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e4d288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, pandas as pd, time\n",
    "import re\n",
    "def get_citation_count(doi):\n",
    "    doi = re.sub(\"https://doi.org/\",\"\",doi)\n",
    "    url = f\"https://opencitations.net/index/coci/api/v1/citations/{doi}\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)\n",
    "        if r.status_code == 200:\n",
    "            return len(r.json())\n",
    "    except Exception:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "get_citation_count(\"10.1109/ACCESS.2021.3120133\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9636a64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cited_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3fb2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 names ✅\n",
      "Akari\n",
      "Ayaka\n",
      "Arisa\n",
      "Asana\n",
      "Akina\n",
      "Aki\n",
      "Aika\n",
      "Airi\n",
      "Ayami\n",
      "Akiri\n",
      "Aoi\n",
      "Ayana\n",
      "Asuka\n",
      "Ayuka\n",
      "Ami\n",
      "Akiho\n",
      "Ayumi\n",
      "Asaka\n",
      "Akie\n",
      "Akiko\n",
      "Akane\n",
      "Ayu\n",
      "Aina\n",
      "Arisu\n",
      "Asami\n",
      "Akika\n",
      "Amika\n",
      "Ayame\n",
      "Ayuna\n",
      "Aya\n",
      "Aria\n",
      "Ai\n",
      "Arika\n",
      "Amiri\n",
      "Aimi\n",
      "Ako\n",
      "Akira\n",
      "Akihi\n",
      "Ayane\n",
      "Asahi\n",
      "Ayako\n",
      "Asune\n",
      "Anna\n",
      "Arina\n",
      "Asako\n",
      "Ayano\n",
      "Asa\n",
      "Asuna\n",
      "Akana\n",
      "Ayuri\n",
      "Aiko\n",
      "Akiha\n",
      "Ayae\n",
      "Ayari\n",
      "Azusa\n",
      "Akino\n",
      "Azumi\n",
      "Amina\n",
      "Akiyo\n",
      "Aisa\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "URL = \"https://japanese-names.info/first-names/gender/girl-name/start-with-a-girl\"\n",
    "\n",
    "async def scrape_names(url):\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        context = await browser.new_context(\n",
    "            user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                       \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                       \"Chrome/118.0.5993.118 Safari/537.36\"\n",
    "        )\n",
    "        page = await context.new_page()\n",
    "        await page.goto(url, timeout=0)\n",
    "\n",
    "        # Wait for at least one name to appear\n",
    "        await page.wait_for_selector(\"ul.name-list li h3\", timeout=10000)\n",
    "\n",
    "        # Scroll to load all names\n",
    "        previous_height = await page.evaluate(\"document.body.scrollHeight\")\n",
    "        while True:\n",
    "            await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            await page.wait_for_timeout(1500)  # wait for new content to load\n",
    "            current_height = await page.evaluate(\"document.body.scrollHeight\")\n",
    "            if current_height == previous_height:\n",
    "                break\n",
    "            previous_height = current_height\n",
    "\n",
    "        # Extract names with proper inner_text evaluation\n",
    "        name_elements = await page.query_selector_all(\"ul.name-list li h3\")\n",
    "        names = []\n",
    "        for el in name_elements:\n",
    "            # Use evaluate to get fully rendered text\n",
    "            text = await el.evaluate(\"(node) => node.textContent.trim()\")\n",
    "            if text:\n",
    "                names.append(text)\n",
    "\n",
    "        await browser.close()\n",
    "        return names\n",
    "\n",
    "async def main():\n",
    "    names = await scrape_names(URL)\n",
    "    print(f\"Found {len(names)} names ✅\")\n",
    "    for name in names:\n",
    "        print(name)\n",
    "\n",
    "# In Jupyter\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4ee7426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping girl names...\n",
      "Found 748 girl names ✅\n",
      "Scraping boy names...\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import string\n",
    "import pandas as pd\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "BASE_URL = \"https://japanese-names.info/first-names/gender/{gender}-name/start-with-{letter}\"\n",
    "GIRL = \"girl\"\n",
    "BOY = \"boy\"\n",
    "\n",
    "async def scrape_page(page, url):\n",
    "    \"\"\"Scrape one page and return list of names\"\"\"\n",
    "    await page.goto(url, timeout=0)\n",
    "    # Wait for names to load\n",
    "    try:\n",
    "        await page.wait_for_selector(\"ul.name-list li h3\", timeout=5000)\n",
    "    except:\n",
    "        return []  # no names on this page\n",
    "\n",
    "    # Scroll to ensure dynamic content loads\n",
    "    previous_height = await page.evaluate(\"document.body.scrollHeight\")\n",
    "    while True:\n",
    "        await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        await page.wait_for_timeout(1000)\n",
    "        current_height = await page.evaluate(\"document.body.scrollHeight\")\n",
    "        if current_height == previous_height:\n",
    "            break\n",
    "        previous_height = current_height\n",
    "\n",
    "    # Extract names\n",
    "    name_elements = await page.query_selector_all(\"ul.name-list li h3\")\n",
    "    names = [await el.evaluate(\"(node) => node.textContent.trim()\") for el in name_elements if await el.evaluate(\"(node) => node.textContent.trim()\")]\n",
    "    return names\n",
    "\n",
    "async def scrape_gender(gender):\n",
    "    all_data = []\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        context = await browser.new_context(\n",
    "            user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                       \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                       \"Chrome/118.0.5993.118 Safari/537.36\"\n",
    "        )\n",
    "        page = await context.new_page()\n",
    "\n",
    "        for letter in [\"a\"] :#string.ascii_lowercase:\n",
    "            page_num = 1\n",
    "            while True:\n",
    "                if gender == GIRL:\n",
    "                    url = f\"{BASE_URL.format(gender=gender, letter=letter)}/page/{page_num}/\"\n",
    "                else:  # boys have no page number on single-page\n",
    "                    url = f\"{BASE_URL.format(gender=gender, letter=letter)}\" if page_num == 1 else f\"{BASE_URL.format(gender=gender, letter=letter)}/page/{page_num}/\"\n",
    "\n",
    "                names = await scrape_page(page, url)\n",
    "                if not names:\n",
    "                    break  # stop if page has no names\n",
    "\n",
    "                # Append data\n",
    "                for name in names:\n",
    "                    all_data.append({\"letter\": letter, \"page\": page_num, \"name\": name})\n",
    "\n",
    "                page_num += 1\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "async def main():\n",
    "    print(\"Scraping girl names...\")\n",
    "    girls_df = await scrape_gender(GIRL)\n",
    "    print(f\"Found {len(girls_df)} girl names ✅\")\n",
    "\n",
    "    print(\"Scraping boy names...\")\n",
    "    #boys_df = await scrape_gender(BOY)\n",
    "    #print(f\"Found {len(boys_df)} boy names ✅\")\n",
    "\n",
    "    # Save to CSV if needed\n",
    "    #girls_df.to_csv(\"japanese_girl_names.csv\", index=False)\n",
    "    #boys_df.to_csv(\"japanese_boy_names.csv\", index=False)\n",
    "\n",
    "    return girls_df#, boys_df\n",
    "\n",
    "# In Jupyter, use:\n",
    "girls_df = await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
